{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 align=\"center\">Statistics</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Contents</b>\n",
    "<br>[Probability Fundamentals](#Probability Fundamentals)\n",
    "<br>[Probability Distributions](#Probability Distributions)\n",
    "<br>[Hypothesis Testing](#Hypothesis Testing)\n",
    "<br>[Confidence Intervals](#Confidence Intervals)\n",
    "<br>[Linear Regression](#Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Probability Fundamentals'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">1. Probability Fundamentals</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>The probability of 'at least once'?</b>\n",
    "\n",
    "p(something happening at least once) = 1 - P(never happening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>What is the probability of anything happening 'at least X times'?</b>\n",
    "\n",
    "Assuming the 'thing' in question either happens or does not happen each time, then this can be answered using the binomial probability formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> The Chain Rule: Aka The probability of lots of things happening one after the other</b>\n",
    "<br><br>\n",
    "* If a,b and c happen, in that order, then total $prob (a,b,c) = p(a) * p(b|a) * p(c|a \\& b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is a probability mass function?</h4>\n",
    "\n",
    "Ans: Same as a probabilty distribution. Can be represented as a chart or as a formula. Also known as the probability function, the frequency function, or probability density function. Sums up to 1.\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<a id='Probability Questions'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Test your knowledge</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Two fair dice are thrown. Let X be the smallest of the two numbers obtained\n",
    "(or the common value if the same number is obtained on both dice). Find the\n",
    "probability mass function (i.e. the distribution) of X. Find $P(X > 3)$.</b>\n",
    "<br>\n",
    "<code>\n",
    "Ans:\n",
    "6x6 = 36 possibilities in total\n",
    "Any two numbers has a 1 /36 chance\n",
    "p(X>3) = p(4,4)+p(4,5)*2+p(5,5)+p(6,4)*2+p(6,5)*2+p(6,6) = 0.25 => 25%</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>On a coral reef, S species of fish are present in proportions $p1, ... , pS$. A\n",
    "biologist wishes to take a sample of the fish, and wants to know how many\n",
    "species of fish she should expect to find in a sample of a given size.<br>\n",
    "<br>(a) Suppose a sample of size $n$ is taken. Let $X_i (i = 1, ... ,S) $ be a random variable taking the value 1 if species i occurs, 0 otherwise. Find an expression for $E(X_i)$. </b>\n",
    "<br>(Assume that, first, the sample is small relative to the population\n",
    "of any fish species, so that taking the sample has a negligible effect on the\n",
    "proportions of fish remaining; second, species are distributed randomly so\n",
    "that successive fish in the sample can be regarded as independent draws\n",
    "from the population).\n",
    "<br><br>\n",
    "<b>(b) Now let Y be the number of fish species present in the sample. Express Y\n",
    "in terms of the $X_i$'s, and deduce that the expected number of species is\n",
    "$$ S-\\sum_{i=1}^{S}(1-p_i)^n$$\n",
    "Are you making any further assumptions in obtaining this result? Check\n",
    "that the formula gives the correct result for a couple of different sample\n",
    "sizes where the answer is \"obvious\".</b>\n",
    "<br><br>\n",
    "<b>Answer:</b><br>\n",
    "S = # of different fish species<br>\n",
    "$p_i$ = proportion of fish i = probability of fish i<br>\n",
    "$X_i$ = {1,0}= fish i occurs, not occurs<br> \n",
    "$E(X_i$) = average value for $X_i$<br>\n",
    "n = sample size<br>\n",
    "<br>\n",
    "a) \n",
    "There are lots of different ways that we can say the sample 'contained at least 1 fish of type i', and we cannot just do $(P_i)^n$ as this is the probability of <i>every</i> fish in the sample being fish $i$.\n",
    "However there is only 1 way it could be 0 (the probability that every fish in the sample does not equal that fish). <br>\n",
    "P(not getting fish i in 1 fish) = $1-p_i$<br>\n",
    "multiplied by total fish sampled = $1-(1-p_i)^n = E[X_i]$\n",
    "<br><i>Note: If we were using \"weight of fish\" rather than a simple binary measure then we'd want to multiply the prob. by the weight to get to the E(weight). </i>\n",
    "<br><br>\n",
    "b) Y = $\\sum E[X_i] = \\sum_{i=1}^S 1-(1-p_i)^n = S - \\sum_{i=1}^S (1-p_i)^n $\n",
    "<br>(If you are not following the last step - just think of the middle terms as being the sum of 1's minus the sum of the probs).<br>\n",
    "<br>Assume uniform distribution of fish in population and S = 10 species. Check result when n= 1 where Y should = 1, and 10000 where Y = S. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let X be a random variable with expectation $\\mu$ Find the expectation of the random variable Y = X-$\\mu$ </b>\n",
    "\n",
    "* Let's start by translating this question into plain english: If yiou roll a die over and over again, and keep taking 3.5 away from whatever number,X that shows up, what is the probability of the result being \n",
    "* Think of this from a Bayesian perspective: X-$\\mu$ is your liklihood function, X is your unknown parameter, Y is your posterior\n",
    "* Therefore p(Y) = $\\int$ (x- $\\mu$)p(x) dx\n",
    "* Multiply the $\\mu$ with the other bracket to get $\\int xp(x) -  \\int \\mu p(x) dx$\n",
    "* Both integrals have p(x) so they cancel each other out leaving:\n",
    "* E(X) - $\\mu$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>\n",
    "In a promotion for a particular airline, customers and potential customers were given vouchers. 10% of these vouchers were for a free round-trip anywhere this airline flies. How many vouchers would an individual need to collect in order to have a 50% chance of winning at least one free trip?</b>\n",
    "<br><br>\n",
    "Trigger words here are 'at least'.<br>\n",
    "Probability of not winning at all = $0.9^S$ where s = number of tickets<br>\n",
    "<br>\n",
    "$p(winning) = 1- 0.9^S$\n",
    "<br>\n",
    "7 tickets need to be purchased to have a 50% chance of winning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Karlyn Akimoto operates a small computer store. On a particular day she has three Hewlett-Packard and two Dell computers in stock. Suppose that Susan Spencer comes into the store to purchase two computers. Susan is not concerned about which brand she purchases—they all have the same operating specifications—so Susan selects the computers purely by chance: Any computer on the shelf is equally likely to be selected. What is the probability that Susan will purchase one Hewlett-Packard and one Dell computer?</b>\n",
    "<br><br>\n",
    "<code>p(HP and Dell) = P(HP|Dell first)*P(Dell first) + P(Dell|HP first)*P(HP first) = 3/4*2/5 + 2/4*3/5 = 0.6</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>An urn contains 6 red marbles and 4 black marbles. Two marbles are drawn without replacement from the urn. What is the probability that both of the marbles are black?</b>\n",
    "<br>\n",
    "<br>\n",
    "`p(black & black) = p(black|black)* P(black) = 4/10 * 3/9 = 0.13 => 13%`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Five friends including Omar and Sarah go to a party. On their way out they each pick one of the 5 jackets randomly (without replacement.<br>\n",
    "What is the probability that:<br>\n",
    "a) Omar ends up with his own jacket?<br>\n",
    "b) everyone ends up with their own jacket?<br>\n",
    "c) both Omar and Sarah don't end up with their own jackets?<br>\n",
    "</b>\n",
    "<code>\n",
    "Assuming everyone left at exactly the same time then:<br>\n",
    "a) 1/5 0.2\n",
    "b) 1/5^5= 0.0003\n",
    "c) 4/5*4/5 = 0.640\n",
    "\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<a id='Probability Distributions'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">2. Probability Distributions</h3>\n",
    "\n",
    "<img src=\"../_img/distribution.png\" width=\"700\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What different distributions are good for</b>\n",
    "\n",
    "* Gaussian: Cases that follow this distribution are likely to involve a lot of data or exist in textbooks\n",
    "* Bernoulli: If you can condense the process you are analysing into a binary decision\n",
    "* Poisson: If you are analyzing frequency of something happening\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p><b>Describe the Bernoulli,  Binomal distributions and the Possion Distributions</b>\n",
    "<p><br>\n",
    "A <b>Bernoulli</b> distribution is when the outcome of an event is binary - success or not.\n",
    "<br>\n",
    "A <b>Binomial</b> is like a Benoulli but repeated multiple times (e.g. flipping a coin 10 times). It requires knowing the prob. of something occurring (& hence not occuring too)\n",
    "<br>\n",
    "P(k num of successes out of n trials) = $$\\binom{n}{k}* p(Success)^k*P(Not Success)^{n-k} =  \\frac{n!}{k!(n-k)!} * p^kq^{n-k}$$\n",
    "\n",
    "n = number of trials<br>\n",
    "k = number of successes\n",
    "nCr on calculator will perform the $\\binom{n}{k}$ section\n",
    "</p>\n",
    "<br>\n",
    "The <b>Poisson</b> distribution is popular for modeling the number of times an event occurs in an interval of time or space.\n",
    "<br>\n",
    "$$P\\left( X \\ events \\ in \\ interval\\right) = \\frac{{\\lambda ^x e^{ - \\lambda } }}{{x!}}$$\n",
    "<br>\n",
    "<br>e: A constant equal to approximately 2.71828. (Actually, e is the base of the natural logarithm system.)\n",
    "<br>$\\lambda$: (sometimes referred to as mean $\\mu$). The mean number of successes that occur in a specified period.\n",
    "<br>x: The actual number of successes that occur in a specified period.\n",
    "<br>P(x; $\\lambda$): The Poisson probability that exactly x successes occur in a Poisson experiment, when the mean number of successes is $\\lambda$. \n",
    "<br><br>\n",
    "It applies when: \n",
    "<br>(1) occurrences are independent, so that one occurrence neither diminishes nor increases the chance of another; <br>(2) the average frequency of occurrence for the time period in question is known; and \n",
    "<br>(3) it is possible to count how many events have occurred, such as the number of times a firefly lights up in my garden in a given 5 seconds, some evening, but meaningless to ask how many such events have not occurred. \n",
    "<br>\n",
    "<br>\n",
    "The Poisson Distribution is asymmetrical: given a rate $\\lambda$ = 3, the range of variation ends with zero on one side (you will never find \"minus one\" letter in your mailbox), but is unlimited on the other side (if the label machine gets stuck, you may find yourself some Tuesday with 4,573 copies of some magazine spilling all over your front yard - it's not likely, but you can't call it impossible). The Poisson Distribution, as a data set or as the corresponding curve, is always skewed toward the right, but it is inhibited by the Zero occurrence barrier on the left. \n",
    "\n",
    "The degree of skew diminishes as r becomes larger, and at some point the Poisson Distribution becomes, to the eye, about as symmetrical as the Normal Distribution. But much though it may come to resemble the Normal Distribution, to the eye of the person who is looking at a graph for, say, $\\lambda$ = 35, the Poisson is really coming from a different kind of world event. \n",
    "\n",
    "<br>\n",
    "<br>The cumulative version of this formula is simply to calculate it individually and add it up, or use a Poisson table.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For each case below, state whether the binomial distribution is suitable. If not,\n",
    "give your reasons; if it would, state the values of parameters trials, n and probability p.<br>\n",
    "<br>(i) The number of sixes obtained in three successive throws of a fair die.\n",
    "<br>(ii) The number of girls in the families of British prime ministers.\n",
    "<br>(iii) The number of aces in a hand of four cards dealt from a standard pack of\n",
    "cards.\n",
    "<br>(iv) The number of students in a class of 40 whose birthday falls on a Sunday\n",
    "this year.\n",
    "<br>(v) The number of throws of a fair coin until the first head is obtained.</b>\n",
    "<br>\n",
    "<br>\n",
    "Binomial Distribution require number of trials n, and probabilty of success p, to remain fixed\n",
    "<br>1)Yes, n=3, p=1/6\n",
    "<br>2)No - n is not a constant (different families have different numbers of children)\n",
    "<br>3)No, prob of Aces is not constant (decreases over time)\n",
    "<br>4)Yes - p(Sunday in this year) is constant ~1/7 days, and k = 40\n",
    "<br>5)No - n is not fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Consider a jury trial in which it takes 8 out of the 12 jurors to convict. That is,\n",
    "in order for the defendant to be convicted, at least 8 of the 12 jurors must vote\n",
    "him guilty. Assume that jurors act independently and each makes the right\n",
    "decision with probability p. Let $\\alpha$ denote the probability that the defendant is\n",
    "guilty. What is the probability that the jury renders a correct decision?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`P(correct) = P(guilty verdict)*P(isGuilty) + P(innocent)*P(isInnocent)\n",
    "P(guilty verdict) = Binomoal prob. of 8,9,10,11,12, summed up\n",
    "P(innocent verdcit) = Binomial prob. of 1,2,3,4,5,6,7, summed up`\n",
    "\n",
    "$$P(Guilty Verdict)*P(isGuilty) = \\sum_{k=8} ^{12} \\binom{12}{k}* p^k*(1-P)^{12-k} * \\alpha $$\n",
    "$+$\n",
    "$$P(Innocent Verdict) * P(isInnocent) = \\sum_{k=0} ^{7} \\binom{12}{k}* p^k*(1-P)^{12-k} * (1-\\alpha) $$\n",
    "\n",
    "\n",
    "note: $\\binom{12}{k}$ means $\\frac {12!}{(12-k)!k!}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>An exam paper consists of ten multiple choice questions, each offering four\n",
    "choices of which only one is correct. If a candidate chooses his answers completely at random, what is the probability that<br>\n",
    "(i) he gets at least 8 questions right<br>\n",
    "(ii) the last of the ten questions is the eighth one he gets right <br>\n",
    "(iii) in six such exams, he gets at least 8 questions right in at most one exam?</b>\n",
    "<br>\n",
    "i) <br>\n",
    "p(k>=8) = p(k=8)+p(k=9)+p(k=10)\n",
    "<br>Using Binomal theorem where n=10, p=0.25:<br>\n",
    "p(k=8) = $ \\frac{10!}{8!(10-8)!} * 0.25^8 * 0.75^{2} = 0.0038 * $<br>\n",
    "p(k=9) = $ \\frac{10!}{9!(10-9)!} * 0.25^9 * 0.75^{1}$ = 0.00028<br>\n",
    "p(k=10) = $ \\frac{10!}{10!(10-10)!} * 0.25^{10} * 0.75^{0} = 0.00007$\n",
    "<br>= 0.004\n",
    "<br>In R:\n",
    "dbinom(10, size=10, prob=0.25)+dbinom(9, size=10, prob=0.25)+dbinom(8, size=10, prob=0.25) = 0.0004\n",
    "\n",
    "ii) = P(7/9 right) + 0.25\n",
    "ii) We know the answer to p(of getting at least 8) from part I. So this becomes a new binomial question with k = 1, n=6, and p=0.0004."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Andrew Whittaker, computer center manager, reports that his computer system experienced three component failures during the past 100 days. \n",
    "<br>a. What is the probability of no failures in a given day? \n",
    "<br>b. What is the probability of one or more component failures in a given day? \n",
    "<br>c. What is the probability of at least two failures in a 3-day period?\n",
    "\n",
    "</b>\n",
    "<br>\n",
    "Assuming the past 100 days is typical and component failures are independent of one another then we can computer the probability of failure usisng the Poisson distribution:<br>\n",
    "<br>\n",
    "$\\lambda (mean)$ = 3/100 = 0.03\n",
    "<br><br>a)$ p(x=0) = \\frac {0.03^0*e^-0.03} {0!} = 0.9075$\n",
    "<br>b) 1-p(x=0) = 0.0295\n",
    "<br>c)$\\lambda = 3*0.003 p(x>=2) = 1 - p(x=0)+p(x=1) = 1-0.9139+0.0822=0.003815$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>A typist makes on average 2 mistakes per page. What is the probability of a particular page having no errors on it? </b>\n",
    "<br><br>\n",
    "We have an average rate here: $\\lambda$ = 2 errors per page.\n",
    "Using Poisson distribution. \n",
    "($\\lambda$) = (2 errors per page * 1 page) = 2.\n",
    "Hence P0 = $\\frac{2^0}{0!} * exp(-2) = 0.135$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Components are packed in boxes of 20. The probability of a component being defective is 0.1. What is the probability of a box containing 2 defective components? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "p(defective) = 0.1 and hence p(not defective) = 0.9. Hence, Binomial, with n = 20.  \n",
    "\n",
    "P(2 detective out of 20 trials) = $$  =  \\frac{20!}{2!(18)!} * 0.1^20.9^{18} = 190 * 0.002 = 0.285 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>A coin is tossed 10 times. What is the probability that exactly 6 heads will occur.</b>\n",
    "\n",
    "`Using Binomial formula:\n",
    "Success = \"A head is flipped on a single coin\"\n",
    "p = 0.5\n",
    "q = 0.5\n",
    "n = 10\n",
    "x = 6\n",
    "P(x=6) = 10C6 * 0.5^6 * 0.5^4 = 210 * 0.015625 * 0.0625 = 0.205078125 `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Say you toss 1,000 different coins once each, which you assume are identically\n",
    "distributed. Would you change your test for fairness? Would you think of ways in\n",
    "which the test could fail to behave as expected?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assuming coins were independent (iid) the binomial could be used.\n",
    "If not independent (e.g. coins always landed tails if the year they were made was an odd number, and head otherwise) then you could end up with it not rejecting the null hypothesis when it ought to be rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>If you toss a coin 1,000 times and observe 570 heads, how would you assess the claim\n",
    "that the coin is fair?</b>\n",
    "<br>\n",
    "$H_0 = p(H) = 0.5$<br>\n",
    "Using Binomial: n = 1000, k = 570 \n",
    "$$\\frac{1000!}{570!(1000-570)!} * 500^k500^{1000-570}$$\n",
    "<br>This does not work on a calculator so use R instead:\n",
    "In R:   <code>binom.test(500,1000,0.5) </code>\n",
    "<code>\n",
    "Output:\n",
    "Data:  500 and 1000\n",
    "number of successes = 500, number of trials = 1000, p-value = 1\n",
    "alternative hypothesis: true probability of success is not equal to 0.5\n",
    "95 percent confidence interval:\n",
    " 0.4685492 0.5314508\n",
    "sample estimates:\n",
    "probability of success 0.5 \n",
    "</code>\n",
    "<br>95% CI = 469 - 531. 570 is outside of this range therefore reject null hypothesis.\n",
    "\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Hypothesis Testing'></a>\n",
    "<h2>Hypothesis Testing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain Hypothesis testing</h4>\n",
    "\n",
    "Hypothesis testing is about determining whether some value occured by chance. You determine the probability distribution it would follow if something was random and by chance. This is the null hypothesis.\n",
    "\"A general statement or default position that there is no relationship between two measured phenomena, or no association among groups.\"\n",
    "\n",
    "You then measure the probability of seeing the values you are seeing under this distribution (the p-value). If the p-value is quite low, then you infer that there's a high chance it wasn't due to chance, that there was some underlying relationship/reason for it.\n",
    "\n",
    "If the p-value is high, you conclude that it does not disprove the null hypothesis (but it doesn't mean it proves it either)\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How to test a hypothesis</b>\n",
    "\n",
    "* Construct a null hypothesis and an alternative. Typically the null $H_0$ is that everything is fine and the alternative $H_1$ is that something is different (e.g. a coin being fair or not fair)\n",
    "* Decide on a liklihood function that gives you the p(X = x)\n",
    "* Now construct a two tailed test\n",
    "* Do experiements to see how many x's you get\n",
    "\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is a Type I and Type II error</h4>\n",
    "\n",
    "Type I: Rejecting null hypothesis when it is true - The probability of our pv(X) being less than 0.05,\n",
    "<br>Type II error:  Failing to reject the null hypothesis when it is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Pearsons Chi-squared test for Goodness of Fit</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Goodness of Fit</b>\n",
    "- It compares 'Expected' vs. 'Observed' outcomes where the expected outcome would be from some underlying probability model\n",
    "- It assesses the 'Goodness of fit' through several different algorithms:\n",
    "    - Kolmogorov–Smirnov test\n",
    "    - Pearsons Chi-squared test\n",
    "    - ..and others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is the T-Test?</h4>\n",
    "\n",
    "Ans: The t-test assesses whether the means of two groups are statistically different from each other. This analysis is appropriate whenever you want to compare the means of two groups, and especially appropriate as the analysis for the posttest-only two-group randomized experimental design.\n",
    "\n",
    "\n",
    "A one-sample location test of whether the mean of a population has a value specified in a null hypothesis.\n",
    "A two-sample location test of the null hypothesis such that the means of two populations are equal. All such tests are usually called Student's t-tests, though strictly speaking that name should only be used if the variances of the two populations are also assumed to be equal; the form of the test used when this assumption is dropped is sometimes called Welch's t-test. These tests are often referred to as \"unpaired\" or \"independent samples\" t-tests, as they are typically applied when the statistical units underlying the two samples being compared are non-overlapping.[8]\n",
    "A test of the null hypothesis that the difference between two responses measured on the same statistical unit has a mean value of zero. For example, suppose we measure the size of a cancer patient's tumor before and after a treatment. If the treatment is effective, we expect the tumor size for many of the patients to be smaller following the treatment. This is often referred to as the \"paired\" or \"repeated measures\" t-test:[8][9] see paired difference test.\n",
    "A test of whether the slope of a regression line differs significantly from 0.\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is the Wald test?</h4>\n",
    "\n",
    "Where as the t-test is motivated by small, Gaussian samples, the Wald test uses the same statistic but assumes the sample size is large enough so that the central limit theorem kicks in.\n",
    "–Samples $X_{(i)}$can be of “any” distribution.\n",
    "–Hence the distribution of the statistic (let’s call it W, but it’s the same formula as T) is N(0, 1) now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Chi-Squared Test</b><br><br>\n",
    "If you had results 10,20,20,30,10,10\n",
    "and based on probabilities you expected it to be more like: 20,20,20,20,20,20 then:<br>\n",
    "Chi-Sq test = $\\sum\\frac{(x_i - E_i)^2}{E_i}$ = 20.\n",
    "<br>Look up p-value in Chi-Square table with N-1=5 degrees of freedom to find out what the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>The following table summarizes data from a\n",
    "double-blind experiment that aims at comparing particular drugs for nausea reduction\n",
    "against a placebo. Assume each patient is independently assigned one of the treatment\n",
    "groups, or the placebo.\n",
    "<img src=\"../_img/Placebo.png\" height=\"200\" width=\"400\"> \n",
    "<br>Test each drug versus the placebo at the 5 per cent level. Report what the result would\n",
    "be under a Bonferroni adjustment, and how the interpretation changes.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Each row of data can be considered an independent binomial test with n being num. of patients and k being incidence of Nausea. We can use the placebo to generate the true probaibility that we use as a binomial test for the other rows.<br>\n",
    "\n",
    "However as we are conducting multiple independent trials here the Bonferroni adjustment (which is to divide your $\\alpha$ by the number of tests you are doing could be used to reduce the risk of a Type I error (rejecting the null as over multiple experiments one result happened to be significant). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>George Mendel bred four different types of peas, starting with round yellow seeds and wrinkled green seeds. Each pea could result in one of four categories: round yellow, wrinkled yellow, round green and wrinkled green. Mendel's theory dictates that these categories follow a\n",
    "discrete distribution with respective probabilities\n",
    "<br><br>\n",
    "$$p_0 = \\Bigg(\\frac9{16}\\frac3{16}\\frac3{16}\\frac1{16}\\Bigg)$$\n",
    "<br>\n",
    "His experiment had a sample size n = 556, where the observed counts were X =\n",
    "(315, 101, 108, 32). We want to test whether this data supports the theory or not.\n",
    "<br><br>For that, first calculate Pearson's \u001f$X^2$ statistic where $X_j$ is the count data for category $j$, and $E_j$ is the expected count under the null\n",
    "H0 : $p$ = $p_0$, with $p$ being the distribution parameter vector of the multinomial.\n",
    "If we have $k$ categories, T will have a chi-squared distribution with $k-1$ degrees of freedom\n",
    "(\"degrees of freedom\" is just the fancy name given to the parameter of the chi-squared).\n",
    "Describe how you would use this chi-squared statistic to test Mendel's theory.<b>\n",
    "<br>\n",
    "<br>\n",
    "Observed = 315, 101, 108, 32<br>\n",
    "Expected = 312.7, 104.2, 104.2, 34.75<br>\n",
    "$\\chi^2 = \\frac{5.06}{312.7}+ \\frac{10.56}{104.2}+ \\frac{14.06}{104.2}+\\frac{7.56}{34.75} = 0.47$\n",
    "<br><br>\n",
    "We then look for the critical region for for $\\chi^2$ with d.f of 3 (4-1) and confidence of 95%. Using R or an online calulator:\n",
    "http://www.socscistatistics.com/pvalues/chidistribution.aspx\n",
    "we find that the P-Value is 0.925431. Therefore the result is NOT significant at p < 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Confidence Intervals'></a>\n",
    "<h2>Confidence Intervals</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../_img/CI.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>What is a sampling distribution?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It's the distribution of a statistic that you get from taking lots of samples from a population. So you take a sample, work out your statistic (e.g. mean of your sample), throw the sample away, and repeat. Over-time you will build up a picture (i.e. distribution) of your statistic. The <b>mean</b> of that statistic, whether it's the mean of a mean or mean of something else, will get closer to the mean of the populaton statistic, with the more samples you have and the greater the sample size is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../_img/samplingdist.png\" height=\"200\" width=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> How can you compare the mean across two populations?</b><br>\n",
    "If you have two samples (a & b) which you believe ought to have the same underlying distribution and which to do a test to see if this is the case then:<br>\n",
    "a) You will want to test the difference in a test statistic (e.g. the mean) between a & b\n",
    "<br>b) Provided the samples are both large enough OR both samples are assumed to be from a normal distribution, then you will be able to assume that the difference you see between a and b would follow a normal distribution.\n",
    "<br>c) You can therefore test this difference by saying your null hypothesis is the difference is not statististically different from a difference of 0.\n",
    "<br>d) To work out the boundary (i.e. Confidence Interval) where you can say this you would compute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you took just one sample from the population, you could either ask yourself how close are you to the true statistic, and if you think you are far, then continue sampling; or you could ask whether you are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>You want to  conduct a survey in which you know the population mean to be 0 and need to determine the right sample size for your survey.\n",
    "<br>For a sample size n = 10, 50, 100, consider the test:<br> Null hypothesis $H_0 : \\mu$ (sample mean) = 0 (population mean)<br> vs. Alternative $H_1:\\mu$ (sample mean) <> 0 (population mean) <br>for a sample following a Gaussian distribution N($\\mu, \\sigma^2$), where \u001b$\\sigma^2$\n",
    "is known and the level of the test is $\\alpha$ = 0:05.<br><br> Write down the power of this test as a\n",
    "function of the true mean $\\mu_0$. <br>How would this change if $H_0$ was $\\mu$ <=0?</b>\n",
    "<br><br>\n",
    "a) \n",
    "To calculate a confidence interval you need:\n",
    "$$\\bar{X} \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} $$\n",
    "$\\sigma = std. dev$\n",
    "<br>b) We want the test to be at the 95% Confidence Level. For a two tailed test at this level we know that Z=+/- 1.96 for an alpha of 0.05 (95% confidence) spread out across two tails \n",
    "<br><br>\n",
    "c) Therefore we can say our critical region (a fancy word for the remaining 5% not in the confidence interval) would be from $$CriticalRegion = \\bar{X} \\pm 1.96 \\frac{\\sqrt\\sigma}{\\sqrt{10}}$$\n",
    "\n",
    "According to Prof: \n",
    "<code>The sample variance is a function of the data, defined as the sample average of (x_i – x_bar)^2, that is, sum_i{(x_i – x_bar)^2} / n. It also  gives an estimate of the variance of the data distribution. When n goes to infinite, the sample variance goes to s^2 (in most reasonable conditions).\n",
    " \n",
    "s^2 / n is *not* the sample variance. It is the variance X_bar, which has its own distribution that is related to but *not* the same as the distribution of  X_1 or X_2 etc.. Consider the following. Remember from exercise sheet 1 that Var(aX + b) = a^2 * Var(X), for constants a and b. Also, Var(X + Y) = Var(X) + Var(Y) if X and Y are independent.\n",
    " \n",
    "The following then shows how Var(X_bar) is derived from Var(X_1) = Var(X_2) = ... = Var(X_n) = s^2:\n",
    "1.       Var(X_bar) =  Var((X_ 1 + .. + X_n) /  n  = Var((X_1 + … + X_n)) / n^2 =\n",
    "2.       (Var(X_1) + … + Var(X_n)) / n^2 =\n",
    "3.       n * s^2  / n^2 =\n",
    "4.       s^2 / n.\n",
    "We can estimate s^2 / n by “sample variance” / n.\n",
    " \n",
    "Which is not the same as the variance of some other given statistic. For instance, if I take the sample median (sort the data ; pick point in the middle), its variance in general is *not* sigma^2 /n (it will be if the sample median and the sample mean are the same, but in general they are not) so “sample variance” / n might not make sense as an estimate of the variance of the sample median (hence, the bootstrap can help here). If I take the sample maximum (like in question 10 of exercise 3), its variance in general is not sigma^2  /n either.\n",
    " \n",
    "That is, Var(X_1) = … = Var(X_n) = s^2, which is different from Var(Sample average) which may be different from Var(Sample median) which may be different from Var(Sample Maximum) etc.</code>\n",
    "\n",
    "\n",
    "<b>Power </b>\n",
    "...to be completed...\n",
    "<br>\n",
    "Useful links:\n",
    "<br>http://www.statsref.com/HTML/index.html?test_for_mean_when_standard_de_2.html\n",
    "<br>(http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_HypothesisTest-Means-Proportions/BS704_HypothesisTest-Means-Proportions3.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "- Confidence Intervals can be constructed for any sample statistic, not just the mean\n",
    "- Confidence interval = sample statistic $\\pm$ Margin of error\n",
    "- Margin of error (ME) = Critical value * (either Standard deviation OR Standard error of sample statistic)\n",
    "\n",
    "<b>Finding the critical value</b><br>\n",
    "The central limit theorem states that the sampling distribution of a statistic will be nearly normal, if the sample size is large enough. As a rough guide, many statisticians say that a sample size of 30 is large enough when the population distribution is bell-shaped. But if the original population is badly skewed, has multiple peaks, and/or has outliers, researchers like the sample size to be even larger.\n",
    "\n",
    "- Obtain your alpha $\\alpha$, which is (1 - confidence level)\n",
    "- Divide alpha by 2 if doing a two-tail test and then use either the Z-table or the T-Table to get a Z or T score:\n",
    "    - If the population standard deviation is known, use the z-score.\n",
    "    - If the population standard deviation is unknown, use the t statistic.\n",
    "    - Another approach focuses on sample size.\n",
    "    - If the sample size is large, use the z-score. (The central limit theorem provides a useful basis for determining whether a sample is \"large\".) \n",
    "    - If the sample size is small, use the t statistic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Nine hundred (900) high school freshmen were randomly selected for a national survey. Among survey participants, the mean grade-point average (GPA) was 2.7, and the standard deviation was 0.4. What is the margin of error, assuming a 95% confidence level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>How do you calculate a confidence interval around a mean from a sample of data?</b>\n",
    "<br>\n",
    "Margin of Error (ME) = $Z_{\\alpha/2} \\frac{\\sigma}{\\sqrt(n)}$\n",
    "<br>\n",
    "CI = mean $\\pm$ ME\n",
    "<br>\n",
    "<img src=\"../_img/Alpha.png\" height=\"100\" width=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "George Samson is responsible for quality assurance at Integrated Electronics. Integrated Electronics has just signed a contract with a company in China to manufacture a control device that is a component of its manufacturing robotics products. Integrated Electronics wants to be sure that these new, lower-cost components meet its high-quality standards. George has asked you to establish a quality-monitoring process for checking shipments of control device A. The variability of the electrical resistance, measured in ohms, is critical for this device. Manufacturing standards specify a standard deviation of 3.6, and the population distribution of resistance measurements is normal when the components meet the quality specification. The monitoring process requires that a random sample of n = 6 observations be obtained from each shipment of devices and the sample variance be computed. Determine an upper limit for the sample variance such that the probability of exceeding this limit, given a population standard deviation of 3.6, is less than 0.05.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Linear Regression'></a>\n",
    "<h2>Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Describe the null hypotheses to which the p-values given in the table below correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of sales, TV, radio, and newspaper, rather than in terms of the coefficients of the linear model.<br></b>\n",
    "<img src=\"../_img/Q4_1.png\" height=\"300\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Null hypothesis $H_0$: No linear relationship between the number of units sold and intercept, TV, radio, or newspaper.\n",
    "So for Intercept, TV, and radio, the small p-value means that there is evidence that\n",
    "these contributed to the behaviour of sales, while newpaper advertising did not\n",
    "(given advertising in other media). It cannot be concluded that spending money\n",
    "on newspaper advertising is useless, only that it seems not to contribute to sales\n",
    "when TV and radio are being used. It also does not mean that changing the way\n",
    "newspaper funds are used would continue not to show an effect on sales, only that\n",
    "the way done in the data does not seem to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>What is the power of a test</b>\n",
    "<br>\n",
    "power = 1 – β.\n",
    "In plain English, statistical power is the likelihood that a study will detect an effect when there is an effect there to be detected. If statistical power is high, the probability of making a Type II error, or concluding there is no effect when, in fact, there is one, goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Interpret the following</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<code>\n",
    "Call:\n",
    "lm(formula = mpg ~ horsepower, data = Auto)\n",
    "\n",
    "Residuals:\n",
    "     Min       1Q   Median       3Q      Max \n",
    "-13.5710  -3.2592  -0.3435   2.7630  16.9240 \n",
    "\n",
    "Coefficients:\n",
    "             Estimate Std. Error t value Pr(>|t|)    \n",
    "(Intercept) 39.935861   0.717499   55.66   <2e-16 ***\n",
    "horsepower  -0.157845   0.006446  -24.49   <2e-16 ***\n",
    "\n",
    "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "\n",
    "Residual standard error: 4.906 on 390 degrees of freedom\n",
    "  (5 observations deleted due to missingness)\n",
    "Multiple R-squared:  0.6059,\tAdjusted R-squared:  0.6049 \n",
    "F-statistic: 599.7 on 1 and 390 DF,  p-value: < 2.2e-16\n",
    " </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "a) The p-value on the F-statistic shows the the model was able to make results are statistically significant \n",
    "<br>b) As there's only one covariate we can see the same p-value in the co-efficients row showing horsepower was statistically significant and inversely correlated with the output\n",
    "<br>c) The residuals are farily well banced around the a median that's close to 0\n",
    "<br>d) The Residul standard error of 4.906 shows that the predicted output can vary from the true value by 4.906 on average\n",
    "<br>e) The R-squared of 0.6 can be considered good\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>What does the distribution of P-Values look like?</b>\n",
    "P values have a uniform distribution if the null hypothesis is true. That is to say if the thing you are testing is truly random and there is no correlation then each p-value between 0 and 1 should have an equal chance of getting triggered.\n",
    "\n",
    "http://varianceexplained.org/statistics/interpreting-pvalue-histogram/\n",
    "    \n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is the problem with $R^2$ as a test statistic in regression?</h4>\n",
    "\n",
    "Ans: $R^2$ looks at total sum of squares error -- does not consider the variability of that error around the predicted. E.g. If you have a chart where really there's two distinct regions of data\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> What do these two charts show you?<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"../_img/ResidualPlot.png\" height=\"300\" width=\"500\"> \n",
    "<img src=\"../_img/LeveragePlot.png\" height=\"300\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Top chart is a residual plot. Residual = the difference between you predicted Y and the actual Y, i.e. you are looking at the errors in your model. Very useful chart - you want your errors to be consistent across the predicted values (aka fitted valaues)\n",
    "- Bottom chart is a similar thing but when you are working in higher dimensions (to be completed...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>What are the names for the inputs and outputs of a lineear regression model?</b>\n",
    "<br><br>\n",
    "Input variables can be called:\n",
    "    - Covariates\n",
    "    - Inputs\n",
    "    - Regressors\n",
    "    - Independent variables (bad name!)\n",
    "<br>Output variable is called:\n",
    "    - Output\n",
    "    - Response\n",
    "    - Dependent variable (bad name!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> What is Heteroscedasticity</b>\n",
    "<br><br>\n",
    "In linear regression this means that your variance / error is not consistent due to sub-groups within your data. Example plotting the residuals may show variance increasing over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<q><b>What is collinearity?</b></q>\n",
    "<br><br>\n",
    "When two or more variables are closely correlated with one another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>If your Linear regression model seemed to indicate “If we increase the TV budget by one thousand then, other things being equal, I will sell 400 hundred more units of my product, in expectation.” would this imply it was true?</b>\n",
    "<br><br>\n",
    "No - because there might be hidden causes that is causing both to happen. Example the data from the larger advertising budget came from more economically affluent areas where shoppers have more money to spend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2><b>Questions that are yet to be answered...</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>One method we have seen for finding confidence intervals is finding pivots such as\n",
    "    $Q(X, \\mu) \\equiv \\frac{(\\hat{\\mu}(X) - \\mu)}{\\hat{\\sigma}\u001b(X)}$, where we explicitly represented empirical average $\\hat{\\mu}$\n",
    "and empirical standard deviation $\\sigma$\u001b as functions of the data X. A pivot is not a\n",
    "statistic as it depends on the unknown parameter, but it has a distribution which\n",
    "does not (N(0, 1) in a typical example).<br>\n",
    "<br>Another way of building a confidence interval is by inverting a test statistic.\n",
    "For instance, suppose we have data $X^{(1)}...X^{(n)} ~ N(\\mu, \\sigma^2)$ from a known $\\sigma^2$ but\n",
    "unknown $\\mu$. Consider some test for H0 : $\\mu$ = $\\mu_0$ at a level $\\alpha$. Describe how the\n",
    "machinery behind this test can be converted into a 1 - $\\alpha$ confidence interval for $\\mu$.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First of all let's translate this to plain English.\n",
    "<br>Pivot - refers to anything around which we can build a confidence interval. It's true value will be unknown but it will have a probability distribution, typically a Gaussian one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Suppose that the number of distinct uranium deposits in a given area is a\n",
    "Poisson random variable with parameter $\\lambda$ = 10. If, in a fixed period of\n",
    "time, each deposit is independently discovered with probability 1/50, find the\n",
    "probability that (i) exactly one, (ii) at least one and, (iii) at most one deposit\n",
    "is discovered during that time.</b>\n",
    "<br><br>\n",
    "i) We have a probability here, so we know a bimial probability distribution can be used.\n",
    "For Binomial:\n",
    "<br>P = 1/50\n",
    "<br>Q = 49/50\n",
    "<br>N = this is where you realize N = the Possion distribution(10) <br>\n",
    "<br>\n",
    "After this it gets complicated. Basically you are iterating the Poisson over the Binomial formula<full answer not shown><br>\n",
    "<img src=\"../_img/Q1_h.png\" width=800>\n",
    "<img src=\"../_img/Q1_h2.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>There is a theory that people can postpone their\n",
    "death until after an important event. Here are the numbers, in a particular year, of\n",
    "elderly Jewish and Chinese women who died just before and after the Chinese Harvest\n",
    "Moon Festival.\n",
    "<img src=\"../_img/Deaths.png\" height=\"100\" width=\"200\">\n",
    "<br>\n",
    "Compare the two mortality patterns using a hypothesis test, explaining your reasoning.\n",
    "</b>\n",
    "<br>\n",
    "Method 1:<br>\n",
    "First summarize the data into period 1 and period 2\n",
    "<img src=\"../_img/Deaths2.png\" height=\"100\" width=\"200\">\n",
    "\n",
    "We want to know whether the probability of deaths between the two groups are the same.\n",
    "$p_1$ = proportion of deaths for Chinese in P1\n",
    "$p_2$ = proportion of deaths for Jewish in P1\n",
    "<br>\n",
    "We can now think of this as two binomial distrbutions, one for Chinese and one for Jewish.  <br>\n",
    "<br>C ~ Binomial(198,$p_1$)  \n",
    "J ~ Binomial(586,$p_2$)\n",
    "<br>\n",
    "We want to know whether the two distributions have the same Proportions of people dying in Period 1. Our null hypothesis is no:\n",
    "<br>Null hypothesis H_0: $p_1$ = $p_2$\n",
    "<br>\n",
    "<br>We assume n is large enough such that the central limit theorem kicks in and that the average of p1 and p2 can be used \n",
    "<b>...fuck it I give up...Use goodness of fit instead</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>The proportion of time during a 40-hour week that an industrial robot is in\n",
    "operation is modelled by a random variable X with probability density function:\n",
    "<br>\n",
    "<img src=\"../_img/Q1_i.png\" width=300>\n",
    "<br>where c is a constant. \n",
    "<br>a)Find c. <br>b)Find P(X < 1/2) and P(X > 1=3 j X < 1=2).</b>\n",
    "<br>\n",
    "For a continuous random variable, the probability of p(X=a) = $\\int_{b}^{a}f(x)dx = 0$ \n",
    "\n",
    "http://www.felderbooks.com/papers/dx.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Topics:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Non-parametric denisity estimations: \n",
    "1. Gaussian density estimate, empirical distribution, histograms\n",
    "2. Confidence bands\n",
    "3. Kernal Density Estimate\n",
    "4. Multicariate density estimations\n",
    "\n",
    "Building and estimating multivariate distributions\n",
    "1. Joint distributions\n",
    "2. Maximum liklihood\n",
    "3. Multivariate binomial\n",
    "4. Multivariate Gaussian\n",
    "5. Regularization\n",
    "6. Graphical lasso\n",
    "\n",
    "Dimensionality Reduction\n",
    "1. PCA\n",
    "\n",
    "Latent Variable Models and Clustering\n",
    "1. Latent Gaussian models\n",
    "2. Clustering\n",
    "3. K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: What is variance and covariance?\n",
    "\n",
    "* <b>Variance</b> is the amount of variablility around the Expectation:\n",
    "\n",
    "$$ var[f] = \\mathbf{E}[(f(x) - \\mathbf{E}[f(x)])^2]= \\mathbf{E}[f(x)^2] - \\mathbf{E}[f(x)]^2  $$\n",
    "\n",
    "\n",
    "This translates to: Variation = Mean of what you predicted$^2$ minus what you expected$^2$\n",
    "\n",
    "<br>\n",
    "* <b>Covariance</b>: Measures the joint-variability between two variables. \n",
    "\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What is Expectation? </h4>\n",
    "\n",
    "* Another way of saying average\n",
    "* The average value of some function f(x) under a probability distribution p(x).\n",
    "\n",
    "$ \\mathbf{E}(f) = \\displaystyle \\sum p(x)f(x)  $ -- discreet case (Summing up all the individual probs * value)\n",
    "\n",
    "$ \\mathbf{E}(f) = \\displaystyle \\int p(x)f(x)dx  $ -- continuous case\n",
    "\n",
    "* Expectation can be estimated from a N samples drawn from a probabilty distribution function:\n",
    "\n",
    "$ \\mathbf{E}(f) \\simeq \\frac1 N \\sum f(x_n)$\n",
    "\n",
    "Note: Multiplying by \\frac1 N is the same as dividing by N. You'll see this a lot in machine learning formulas.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: What does this show?\n",
    "\n",
    "<img src=\"../_img/covariance.png\" height=\"200\" width=\"400\">\n",
    "\n",
    "Ans: \n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Stepwise regresslions</b>\n",
    "\n",
    "* Forward stepwise regression: Start with no predictors and keep testing all and adding the best one in, until you can't find one that gives you any significant gain\n",
    "* Backwards stepwise regression: Start will all variables (or as many as you select) and remove any that have the least impact on results, and repeat until everything that remains has a significant impact if removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bivariate or multivariate Gaussian distributions (so like a 3d Gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Suppose you are doing penalized curve fitting\n",
    "\n",
    "$$\\hat g= argmin \\left( \\sum^{n}_{i=1}(y^{(i)}-g(x^{(i)}))^2 + \\lambda \\int[g^m(x)]^2 dx \\right)$$\n",
    "\n",
    "where $g^{m}$ is the m-th derivative of g. Explain what happens when $\\lambda$ = 1 under m = 0 and m = 1.</h4>\n",
    "\n",
    "* When m=0, anything raised to the power of 0 =1 so [g^m(x)]^2 becomes $[g(x)]^2$\n",
    "* This is postive and so the penalty is infinite which will force all the co-efficients to be 0\n",
    "* The argmin will mean that the results of the function boils down to the average of y\n",
    "* This is the same if m=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Logistic Regression'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">6. Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<a id='GLM'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">7. Generalised Linear Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/stats/stats001.png\" height=\"100\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Functions, Functions, Functions</h4>\n",
    "\n",
    "* Logistic Function \n",
    "\n",
    "Recommended reading: http://wmueller.com/precalculus/families/1_80.html\n",
    "\n",
    "$$f(x)=\\frac{L}{1+e^{-k(x-x_0)}}$$\n",
    "\n",
    "* Sigmoid function\n",
    "\n",
    "$$f(x) = \\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "* Logit Function\n",
    "\n",
    "$$\\theta = g^{-1}(n) \\equiv \\frac{1}{1+e^{-n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
