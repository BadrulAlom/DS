{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Cloud Computing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cloud Platforms'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">1. Cloud Platforms</h3>\n",
    "\n",
    "Five principle of cloud computing:\n",
    "* Pooled Resources\n",
    "* Virtualization\n",
    "* Elasticity\n",
    "* Automation\n",
    "* Metered Billing\n",
    "\n",
    "Utility computing\n",
    "* Cost: capital vs. operating expenses\n",
    "* Scalability: “infinite” capacity\n",
    "* Elasticity: scale up or down on demand\n",
    "* Provision of Hadoop clusters on-demand in the\n",
    "cloud\n",
    "* Lower barrier to entry for tackling big-data\n",
    "problems\n",
    "* Commoditization and democratization of big-data\n",
    "capabilities\n",
    "\n",
    "When does the cloud make sense?\n",
    "* Limited lifetime requirement or short-term need\n",
    "* Scale variability or volatility\n",
    "* Nonstrategic applications or low organizational value\n",
    "\n",
    "Cloud operating models\n",
    "* Infrastructure as a Service (IaaS)\n",
    "    * Why buy machines when you can rent cycles?\n",
    "    * Examples: Amazon EC2, Rackspace\n",
    "* Platform as a Service (PaaS)\n",
    "    * Give me nice API and take care of the maintenance, upgrades, …\n",
    "    * Example: Google App Engine (GAE)\n",
    "* Software as a Service (SaaS)\n",
    "    * Just run it for me!\n",
    "    * Example: Gmail, Salesforce’s Online CRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Distributed Systems'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">2. Distributed Systems</h3>\n",
    "\n",
    "<h4>Lamport Timestamps</h4>\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud001.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "How the timestamp (i.e. integer incrementing) works:\n",
    "* Everything is set to 0 to begin with\n",
    "* Everything can do 3 things: Internal action, Send, & Recieve.\n",
    "* Whenver internal or send happens it increments its own timestamp by 1\n",
    "* Whenever something recieves something it takes the max of its own timestamp and that of the recieved message, and increments that by 1 to get to a new timestamp number for itself\n",
    "\n",
    "Notes:\n",
    "* Does not allow global ordering of event\n",
    "* Lamport lacks Gap Detection - cannot tell if an event exists elsewhere that sits between two events\n",
    "* Can however assume that if an event from a comes before event from b, then a's clock is lower than b's clock (Known as the Clock consistency condition)\n",
    "* The strong clock consistency condition assumes this and vice-versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Deadlocks</h4>\n",
    "\n",
    "* A deadlock is a situation in which two or more competing actions are each waiting for the other to finish, and thus neither ever does\n",
    "* The Cauffman conditions for a deadlock to occur are:\n",
    "- Mutual Exclusion: There is a resource that can only be used by one process at a time\n",
    "- Hold and Wait: There is a process that needs to hold a resource and wait for others\n",
    "- No Preemption: The monitor cannot forve a process to give up a resource\n",
    "- Circular Wait: A waits for B who waits for C who waits for A\n",
    "\n",
    "<h4>Livelock</h4>\n",
    "Similar to a deadlock, except that the states of the processes involved constantly change with regard to one another, none progressing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The Cap Theorem</h4>\n",
    "\n",
    "Published by Eric Brewer in 2000, the theorem is a set of basic requirements that describe any distributed system. If you imagine a distributed database system with multiple servers, here's how the CAP theorem applies:\n",
    "\n",
    "* Consistency - All the servers in the system will have the same data so users will get the same copy regardless of which server answers their request.\n",
    "* Availability - The system will always respond to a request (even if it's not the latest data or consistent across the system or just a message saying the system isn't working).\n",
    "* Partition Tolerance - The system continues to operate as a whole even if individual servers fail or can't be reached.\n",
    "\n",
    "It's theoretically impossible to have all 3 requirements met, so a combination of 2 must be chosen and this is usually the deciding factor in what technology is used.\n",
    "\n",
    "When it comes to distributed databases, the two choices are only AP or CP because if it's not partition tolerant, it's not really a reliable distributed database. So the choice is simpler: if a network split happens, do you want the database to keep answering but with possibly old/bad data (AP)? Or should it just stop responding unless you can get the absolute latest copy (CP)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dealing with failures:</h4>\n",
    "\n",
    "* Many cloud computations run for extended periods of time on multiple servers.\n",
    "* Checkpoints are taken periodically in anticipation of the need to restart a process when one or more\n",
    "systems fail.\n",
    "* When a failure occurs, the computation is restarted from the last checkpoint rather than from the beginning.\n",
    "* Intuitively, the construction of the global state is equivalent to taking snapshots of individual processes and then combining these snapshots into a global view.\n",
    "\n",
    "* Yet, combining snapshots is straightforward if and only if all processes have access to a global clock and the snapshots are taken at the same time\n",
    "\n",
    "<b>Chandy-Lamport Algorithm</b>\n",
    "\n",
    "1. The observer process (the process taking a snapshot):  \n",
    "    * Saves its own local state\n",
    "    * Sends a snapshot request message bearing a snapshot token to all other processes\n",
    "2. A process receiving the snapshot token for the first time on any message: \n",
    "    * Sends the observer process its own saved state\n",
    "    * Attaches the snapshot token to all subsequent messages (to help propagate the snapshot token)\n",
    "3. When a process that has already received the snapshot token receives a message that does not bear the snapshot token, this process will forward that message to the observer process. This message was obviously sent before the snapshot “cut off” (as it does not bear a snapshot token and thus must have come from before the snapshot token was sent out) and needs to be included in the snapshot.\n",
    "\n",
    "From this, the observer builds up a complete snapshot: a saved state for each process and all messages “in the ether” are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Crash Failures</h4>\n",
    "1. Crash failure: the process abruptly stops and does not resume\n",
    "2. Byzantine failure: the process fail in arbitrary ways (due to malfunctioning hardware, buggy software, malicious attacks from hackers, etc.)\n",
    "    * Omission failures, e.g., failing to receive a request\n",
    "    or send a response.\n",
    "    * Commission failures, e.g., corrupting the local state, sending an incorrect/inconsistent response to the request.\n",
    "\n",
    "Of the two types of failures,Byzantine failures are far more disruptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Paxos Consensus Protocol</h4>\n",
    "\n",
    "The basic Paxos protocol assumes\n",
    "– Processes run on processors and communicate\n",
    "through a network;\n",
    "processors and network may experience failures,\n",
    "but not Byzantine failures.\n",
    "\n",
    "The Processors\n",
    "* operate at arbitrary speeds;\n",
    "* have stable storage and may rejoin the protocol after a failure;\n",
    "* send messages to one another\n",
    "\n",
    "The network:\n",
    "* may lose, reorder, or duplicate messages;\n",
    "* messages are sent asynchronously; it may take arbitrary long time to reach the destination\n",
    "\n",
    "The basic Paxos protocol has two phases.\n",
    "\n",
    "Phase I\n",
    "* Proposal preparation\n",
    "* Proposal promise\n",
    "\n",
    "Phase II\n",
    "* Accept request\n",
    "* Accepted\n",
    "\n",
    "The benefit of the Paxos protocols is the\n",
    "guarantee of three safety properties\n",
    "* Non-triviality: Only proposed values can be\n",
    "learned.\n",
    "\n",
    "* Consistency: at most one value can be learned.\n",
    "\n",
    "* Liveness: if a value v has been proposed,\n",
    "eventually every learner will learn some value,\n",
    "provided that sufficient processors remain nonfaulty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parallel Computing</b>\n",
    "\n",
    "The speed-up S measures the effectiveness of parallelization:\n",
    "\n",
    "S(N) = sequential\n",
    "computation time of a task / N parallel\n",
    "computation time of task\n",
    "\n",
    "<b>Embarrassingly Parallel Problems</b>\n",
    "*Little or no effort is required to separate the\n",
    "problem into a number of parallel tasks, i.e.,\n",
    "$\\alpha$ ≈ 0\n",
    "\n",
    "\n",
    "<b>Amdahl’s Law</b>\n",
    "* When the problem/dataset size is fixed Amdahl’s Law accounts for the fact that there will still be a non-parallelizable element\n",
    "– If $\\alpha$ = % of sequential time that can't be parallelized:\n",
    "\n",
    "S(N) = 1 / [$\\alpha$ + (1-$\\alpha$)/N] < 1 / $\\alpha$\n",
    "\n",
    "* The speedup of a program using multiple processors in parallel computing is limited by the sequential fraction of the program.\n",
    "\n",
    "<b>Gustafan's Law</b>\n",
    "S(N) = $\\alpha$ + N (1- $\\alpha$) = N - $\\alpha$ (N-1)\n",
    "\n",
    "The limitations of the sequential part of a code can be balanced by increasing the problem size (i.e. do more in one go).\n",
    "\n",
    "<b>Comparison</b>\n",
    "– Amdahl’s law argues that\n",
    "more computing power will make an analysis of\n",
    "the same dataset faster.\n",
    "– Gustafson’s law argues that\n",
    "more computing power will make bigger datasets\n",
    "be analysed or deeper analysis be performed\n",
    "\n",
    "\n",
    "<b>Example question:</b>\n",
    "A data mining program consists of four consecutive parts, P1, P2, P3 and P4 with\n",
    "the percentages of runtime being 10%, 30%, 40% and 20% respectively on a single\n",
    "processor. It is known that P1 and P3 can be parallelised while P2 and P4 cannot. If\n",
    "the problem/dataset size is fixed, how much speedup can this program achieve at most\n",
    "through parallel computing, according to Amdahl’s Law? If the problem/dataset size\n",
    "can be arbitrarily large, how much speedup can this program achieve at most through\n",
    "parallel computing, according to Gustafson’s Law?\n",
    "\n",
    "<h4>Single Program Multiple Data (SPMD)</h4>\n",
    "Single Program Multiple Data (SPMD):\n",
    "multiple copies of the same program run\n",
    "concurrently, each one on a different data block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Concurrency</h4>\n",
    "Concurrency is important\n",
    "* Many cloud applications are data-intensive and\n",
    "use a number of instances which run concurrently\n",
    "\n",
    "Concurrency is challenging\n",
    "* It could lead to race conditions, an undesirable\n",
    "effect when the results of concurrent execution\n",
    "depend on the sequence or timing of events\n",
    "* Shared resources must be protected by locks /\n",
    "semaphores / monitors to ensure serial access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relational databases\n",
    "* Multipurpose\n",
    "    * transactions & analysis\n",
    "    * Batch & interactive\n",
    "* Data integrity via ACID transactions\n",
    "* Lots of tools in software ecosystem\n",
    "    * for ingesting, reporting, etc.\n",
    "* Supports SQL (and SQL integration, e.g., JDBC)\n",
    "* Automatic SQL query optimization\n",
    "\n",
    "MapReduce (Hadoop):\n",
    "* Designed for large clusters, fault tolerant\n",
    "* Data is accessed in “native format”\n",
    "* Supports many query languages\n",
    "* Programmers retain control over performance\n",
    "* Open source\n",
    "\n",
    "Online Transaction Processing (OLTP)\n",
    "* Typical applications:\n",
    "    * e-commerce, banking, airline reservations\n",
    "* User facing:\n",
    "    * real-time, low latency, highly-concurrent\n",
    "* Tasks:\n",
    "    * relatively small set of “standard” transactional queries\n",
    "* Data access pattern:\n",
    "    * random reads, updates, writes (involving relatively\n",
    "small amounts of data\n",
    "\n",
    "Online Analytical Processing (OLAP)\n",
    "* Typical applications:\n",
    "    * business intelligence, data mining\n",
    "* Back-end processing:\n",
    "    * batch workloads, less concurrency\n",
    "* Tasks:\n",
    "    * complex analytical queries, often ad hoc\n",
    "* Data access pattern:\n",
    "    * table scans, large amounts of data involved per query\n",
    "    \n",
    "<b>Hadoop is perfect for ETL:</b>\n",
    "* Most likely, you already have some data\n",
    "warehousing solution\n",
    "* Ingestion is limited by the speed of HDFS\n",
    "* Scales out with more nodes\n",
    "* Massively parallel\n",
    "* Ability to use any processing tool\n",
    "* Much cheaper than parallel databases\n",
    "* ETL is a batch process anyway!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Distributed Systems'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">2. Map-Reduce</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud002.png\" height=\"100\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud003.png\" height=\"100\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Partitioning:</b>\n",
    "* Used to ensure records with the same key end up at the same worker\n",
    "* Uses a simple function hash(key) mod R to decide which Reducer to go to\n",
    "* Sometimes useful to override. E.g hash(hostname(URL)) mod R ensures URLs from one host end up in the same output file\n",
    "    \n",
    "* MapReduce program in Hadoop = Hadoop job\n",
    "\n",
    "<h4> Combiners </h4>\n",
    "\n",
    "This mapper function which has a multii-doc wrapper for a single doc function exemplifies the need for a combiner in a word count of individual documents\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud005.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "* The combiner could group together counts for the same document\n",
    "* While the combiner can do a similar role to the reducer, bear in mind the combiner only gets a subset of the data, so if you were trying to calculate averages for example you'd end calculating a mini average and pushing that forward to the reducer\n",
    "* Using the reducer as a combiner works only if the function we're computing is both commutative (a + b = b + a) and associative (a + (b + c) = (a + b) + c). \n",
    "\n",
    "http://www.philippeadjiman.com/blog/2010/01/14/hadoop-tutorial-series-issue-4-to-use-or-not-to-use-a-combiner/\n",
    "\n",
    "<b>Calculating a co-occurence matrix</b>\n",
    "\n",
    "<b>Pairs method:</b>\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud006.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "<b>Stripes method:(Essentially you can emit an entire row at a time)</b>\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud007.png\" height=\"100\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='MapReduce Optimization'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">4. MapReduce Optimization</h3>\n",
    "\n",
    "<b>Ways to optimize:</b>\n",
    "* Compression of data from one flow to the next\n",
    "    * Trade-off between the volume of data transfer and the (de)compression time.\n",
    "    * Usually, compressing map outputs using a fast compressor increases efficiency\n",
    "\n",
    "* Available memory\n",
    "    * Particularly for Reduce Shuffle and Sort\n",
    "\n",
    "* Speculative Execution\n",
    "    * Jobtracker tries to detect tasks that are taking a long time, such as one node being very slow\n",
    "    * In this case it would make copies of the tasks and execute them\n",
    "    * Whichever one finishes first wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AlgoDesign'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">5. Map-Reduce Algorithm Design</h3>\n",
    "\n",
    "* <b>“In-Mapper Combining”</b>\n",
    "    * The in-mapper combiner takes this optimization a bit further: the aggregations do not even write to local disk: they occur in-memory in the Mapper itself.\n",
    "    * So one example is to have an Initialize, Map, an Call method in your Mapper, where the intialize setups an an associative array to store results, the mappers does each indicidual processing and stores in the array, and close does an aggregation before emitting\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud005.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "Advatages: Speed as not writing to disk\n",
    "Disadvantages: Explicit memory management required. Potential for order-dependent bugs\n",
    "\n",
    "* <b>“Pairs” vs “Stripes”</b>\n",
    " * Pairs is just emitting a key and a value\n",
    " * Stripes is grouping multiple results into an associative array with a defined structure so thaat in the combiner or reduce phase it can efficiently interpret the results\n",
    " \n",
    "* <b>Secondary Sorting</b>\n",
    "    * Value-to-Key Conversion: Creating a composite key is straight forward. What we need to do is analyze what part(s) of the value we want to account for during the sort and add the appropriate part(s) to the natural key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Hadoop'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">3. Hadoop</h3>\n",
    "\n",
    "* SequenceFiles: Binary encoded of a sequence of key/value pairs\n",
    "\n",
    "* Concrete classes for different data types:\n",
    "    * IntWritable\n",
    "    * LongWritable\n",
    "    * Text\n",
    "    * etc.\n",
    "\n",
    "* Writable Defines a de/serialization protocol.\n",
    "* Every data type in Hadoop is a Writable.\n",
    "* WritableComparable Defines a sort order.\n",
    "* All keys must be of this type (but not values).\n",
    "\n",
    "\n",
    "<b>Job submission process</b>\n",
    "* Client (i.e., driver program) creates a job, configures it, and submits it to job tracker\n",
    "* JobClient computes input splits (on client end)\n",
    "* Job data (jar, configuration XML) are sent to JobTracker\n",
    "* JobTracker puts job data in shared location, enqueues tasks\n",
    "* TaskTrackers poll for tasks\n",
    "* Off to the races…\n",
    "\n",
    "<h4>Hadoop Map-Reduce Process</h4>\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud004.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "* Map outputs are buffered in memory in a circular\n",
    "buffer\n",
    "* When buffer reaches threshold, contents are\n",
    "“spilled” to disk\n",
    "* Spills merged in a single, partitioned file (sorted\n",
    "within each partition): combiner runs here\n",
    "\n",
    "\n",
    "Reduce side\n",
    "* First, map outputs are copied over to reducer\n",
    "machine\n",
    "* “Sort” is a multi-pass merge of map outputs\n",
    "(happens in memory and on disk): combiner runs\n",
    "here\n",
    "* Final merge pass goes directly into reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Spark'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">6. Spark</h3>\n",
    "\n",
    "<b>RDD's</b>\n",
    "* Resiliant Distributed Datasets\n",
    "    * A read-only, partitioned collection of records.\n",
    "    * Held as distributed shared memory\n",
    "    * Can only be built from a series of deterministic transformations (e.g. map, filter, join)\n",
    "    * This is known as a DAG (Direct Acyclic Graph)\n",
    "    * Fault tolerance - RDDs track the graph of transformations that built them (their lineage) to rebuild lost data\n",
    "    * Spark offers over 80 high-level operators that make it easy to build parallel apps\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Other'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">7. Other</h3>\n",
    "\n",
    "HTTP Requests:\n",
    "* GET method should be safe (nullipotent) - calling it produces no side effects (unlike PUT and GET which may change things)\n",
    "* The GET, PUT and DELETE methods should be idempotent - repeated calls should have the same effect as a single request \n",
    "* Post is not idempotent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='Q&A'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">8. Q&A</h3>\n",
    "\n",
    "<h4>\n",
    "There is a large text file of information about films stored in the HDFS over a number of\n",
    "machines. Each line of this file describes the details of one film in the following format.\n",
    "title | year | runtime | genres | stars\n",
    "<br><br>\n",
    "The different fields are separated by the | character; the list of genres and the list of stars\n",
    "are both separated by commas; the runtime is measured in minutes.\n",
    "An example line is given below.\n",
    "The Godfather | 1972 | 175 | Crime, Drama | Marlon Brando, Al Pacino, James Caan\n",
    "You can assume that there are no duplicate records, and each distinct star’s name is unique.\n",
    "Write a MapReduce program (in pseudo-code) to calculate for each genre the average\n",
    "runtime of film in the 1970s.\n",
    "A combiner should be implemented to accelerate the computation.\n",
    "</h4>\n",
    "\n",
    "<code>\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud008.png\" height=\"100\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Revision Lecture Notes'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">9. Revision Lecture Notes</h3>\n",
    "\n",
    "* 8 factual questions - keep answers short\n",
    "* 3 algorithm questions (1 graph based)\n",
    "* New for this year - Apache Spark\n",
    "\n",
    "<h4>From week 1</h4>\n",
    "Five principle of cloud computing:\n",
    "* Pooled Resources\n",
    "* Virtualization\n",
    "* Elasticity\n",
    "* Automation\n",
    "* Metered Billing\n",
    "\n",
    "\n",
    "Utility computing\n",
    "* Cost: capital vs. operating expenses\n",
    "* Scalability: “infinite” capacity\n",
    "* Elasticity: scale up or down on demand\n",
    "* Provision of Hadoop clusters on-demand in the\n",
    "cloud\n",
    "* Lower barrier to entry for tackling big-data\n",
    "problems\n",
    "* Commoditization and democratization of big-data\n",
    "capabilities\n",
    "\n",
    "Service Models (Iaas, PaaS, SaaS)\n",
    "\n",
    "When does the cloud make sense?\n",
    "* Limited lifetime requirement or short-term need\n",
    "* Scale variability or volatility\n",
    "* Nonstrategic applications or low organizational value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>From week 2</h4>\n",
    "\n",
    "Speedups: Amdahl vs Gustafson\n",
    "\n",
    "Data/Tasks Parallelism\n",
    "Race conditions , dead/live lock\n",
    "Lamporttime stamps\n",
    "Chady-Lamport snapshot\n",
    "Process failure types\n",
    "RESTful API (definition, constraints, different methods for different purposes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>From week 3</h4>\n",
    "HFDS - underlying assumptions, consisten hashing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>From week 4-7</h4>\n",
    "\n",
    "* Combiner vs. In-Mapper combining\n",
    "* Pairs and Stripes\n",
    "* Order Inversion\n",
    "* Value to Key conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>From week 9</h4>\n",
    "\n",
    "* Relational databases - peojections, selection, group-by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>From week 11</h4>\n",
    "* Spark - no need to write code but no basic ideas\n",
    "* Adv & Disadv\n",
    "* Iterative and interactive \n",
    "* RDDs\n",
    "* Transformation vs Action\n",
    "* 'Map' in Spark\n",
    "* Narrow / wide dependency\n",
    "* D-stream\n",
    "\n",
    "\n",
    "Past paper Map-Reduce questions similar to exam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
