{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Cloud Computing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Distributed Systems'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">1. Distributed Systems</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lamport Timestamps</h4>\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud001.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "How the timestamp (i.e. integer incrementing) works:\n",
    "* Everything is set to 0 to begin with\n",
    "* Everything can do 3 things: Internal action, Send, & Recieve.\n",
    "* Whenver internal or send happens it increments its own timestamp by 1\n",
    "* Whenever something recieves something it takes the max of its own timestamp and that of the recieved message, and increments that by 1 to get to a new timestam number for itself\n",
    "\n",
    "Notes:\n",
    "* Does not allow global ordering of event\n",
    "* Lamport lacks Gap Detection - cannot tell if an event exists elsewhere that sits between two events\n",
    "* Can however assume that if an event from a comes before event from b, then a's clock is lower than b's clock (Known as the Clock consistency condition)\n",
    "* The strong clock consistency condition assumes this and vice-versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Deadlocks</h4>\n",
    "\n",
    "* A deadlock is a situation in which two or more competing actions are each waiting for the other to finish, and thus neither ever does\n",
    "* The Cauffman conditions for a deadlock to occur are:\n",
    "- Mutual Exclusion: There is a resource that can only be used by one process at a time\n",
    "- Hold and Wait: There is a process that needs to hold a resource and wait for others\n",
    "- No Preemption: The monitor cannot forve a process to give up a resource\n",
    "- Circular Wait: A waits for B who waits for C who waits for A\n",
    "\n",
    "<h4>Livelock</h4>\n",
    "Similar to a deadlock, except that the states of the processes involved constantly change with regard to one another, none progressing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The Cap Theorem</h4>\n",
    "\n",
    "Published by Eric Brewer in 2000, the theorem is a set of basic requirements that describe any distributed system. If you imagine a distributed database system with multiple servers, here's how the CAP theorem applies:\n",
    "\n",
    "* Consistency - All the servers in the system will have the same data so users will get the same copy regardless of which server answers their request.\n",
    "* Availability - The system will always respond to a request (even if it's not the latest data or consistent across the system or just a message saying the system isn't working).\n",
    "* Partition Tolerance - The system continues to operate as a whole even if individual servers fail or can't be reached.\n",
    "\n",
    "It's theoretically impossible to have all 3 requirements met, so a combination of 2 must be chosen and this is usually the deciding factor in what technology is used.\n",
    "\n",
    "When it comes to distributed databases, the two choices are only AP or CP because if it's not partition tolerant, it's not really a reliable distributed database. So the choice is simpler: if a network split happens, do you want the database to keep answering but with possibly old/bad data (AP)? Or should it just stop responding unless you can get the absolute latest copy (CP)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dealing with failures:</h4>\n",
    "\n",
    "* Many cloud computations run for extended periods of time on multiple servers.\n",
    "* Checkpoints are taken periodically in anticipation of the need to restart a process when one or more\n",
    "systems fail.\n",
    "* When a failure occurs, the computation is restarted from the last checkpoint rather than from the beginning.\n",
    "* Intuitively, the construction of the global state is equivalent to taking snapshots of individual processes and then combining these snapshots into a global view.\n",
    "\n",
    "* Yet, combining snapshots is straightforward if and only if all processes have access to a global clock and the snapshots are taken at the same time\n",
    "\n",
    "<b>Chandy-Lamport Algorithm</b>\n",
    "\n",
    "1. The observer process (the process taking a snapshot):  \n",
    "    * Saves its own local state\n",
    "    * Sends a snapshot request message bearing a snapshot token to all other processes\n",
    "2. A process receiving the snapshot token for the first time on any message: \n",
    "    * Sends the observer process its own saved state\n",
    "    * Attaches the snapshot token to all subsequent messages (to help propagate the snapshot token)\n",
    "3. When a process that has already received the snapshot token receives a message that does not bear the snapshot token, this process will forward that message to the observer process. This message was obviously sent before the snapshot “cut off” (as it does not bear a snapshot token and thus must have come from before the snapshot token was sent out) and needs to be included in the snapshot.\n",
    "\n",
    "From this, the observer builds up a complete snapshot: a saved state for each process and all messages “in the ether” are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Crash Failures</h4>\n",
    "1. Crash failure: the process abruptly stops and does not resume\n",
    "2. Byzantine failure: the process fail in arbitrary ways (due to malfunctioning hardware, buggy software, malicious attacks from hackers, etc.)\n",
    "    * Omission failures, e.g., failing to receive a request\n",
    "    or send a response.\n",
    "    * Commission failures, e.g., corrupting the local state, sending an incorrect/inconsistent response to the request.\n",
    "\n",
    "Of the two types of failures,Byzantine failures are far more disruptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Paxos Consensus Protocol</h4>\n",
    "\n",
    "The basic Paxos protocol assumes\n",
    "– Processes run on processors and communicate\n",
    "through a network;\n",
    "processors and network may experience failures,\n",
    "but not Byzantine failures.\n",
    "\n",
    "The Processors\n",
    "* operate at arbitrary speeds;\n",
    "* have stable storage and may rejoin the protocol after a failure;\n",
    "* send messages to one another\n",
    "\n",
    "The network:\n",
    "* may lose, reorder, or duplicate messages;\n",
    "* messages are sent asynchronously; it may take arbitrary long time to reach the destination\n",
    "\n",
    "The basic Paxos protocol has two phases.\n",
    "\n",
    "Phase I\n",
    "* Proposal preparation\n",
    "* Proposal promise\n",
    "\n",
    "Phase II\n",
    "* Accept request\n",
    "* Accepted\n",
    "\n",
    "The benefit of the Paxos protocols is the\n",
    "guarantee of three safety properties\n",
    "* Non-triviality: Only proposed values can be\n",
    "learned.\n",
    "\n",
    "* Consistency: at most one value can be learned.\n",
    "\n",
    "* Liveness: if a value v has been proposed,\n",
    "eventually every learner will learn some value,\n",
    "provided that sufficient processors remain nonfaulty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Distributed Systems'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">2. Map-Reduce</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud002.png\" height=\"100\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud003.png\" height=\"100\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Partitioning:</b>\n",
    "* Used to ensure records with the same key end up at the same worker\n",
    "* Uses a simple function hash(key) mod R to decide which Reducer to go to\n",
    "* Sometimes useful to override. E.g hash(hostname(URL)) mod R ensures URLs from one host end up in the same output file\n",
    "    \n",
    "* MapReduce program in Hadoop = Hadoop job\n",
    "\n",
    "<h4> Combiners </h4>\n",
    "\n",
    "This mapper function which has a multii-doc wrapper for a single doc function exemplifies the need for a combiner in a word count of individual documents\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud005.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "* The combiner could group together counts for the same document\n",
    "* While the combiner can do a similar role to the reducer, bear in mind the combiner only gets a subset of the data, so if you were trying to calculate averages for example you'd end calculating a mini average and pushing that forward to the reducer\n",
    "\n",
    "http://www.philippeadjiman.com/blog/2010/01/14/hadoop-tutorial-series-issue-4-to-use-or-not-to-use-a-combiner/\n",
    "\n",
    "<b>Calculating a co-occurence matrix</b>\n",
    "\n",
    "Pairs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='MapReduce Optimization'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">4. MapReduce Optimization</h3>\n",
    "\n",
    "\n",
    "<b>Ways to optimize:</b>\n",
    "* Compression of data from one flow to the next\n",
    "    * Trade-off between the volume of data transfer and the (de)compression time.\n",
    "    * Usually, compressing map outputs using a fast compressor increases efficiency\n",
    "\n",
    "* Available memory\n",
    "    * Particularly for Reduce Shuffle and Sort\n",
    "\n",
    "* Speculative Execution\n",
    "    * Jobtracker tries to detect tasks that are taking a long time, such as one node being very slow\n",
    "    * In this case it would make copies of the tasks and execute them\n",
    "    * Whichever one finishes first wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AlgoDesign'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">5. Map-Reduce Algorithm Design</h3>\n",
    "\n",
    "* <b>“In-Mapper Combining”</b>\n",
    "    * The in-mapper combiner takes this optimization a bit further: the aggregations do not even write to local disk: they occur in-memory in the Mapper itself.\n",
    "    * So one example is to have an Initialize, Map, an Call method in your Mapper, where the intialize setups an an associative array to store results, the mappers does each indicidual processing and stores in the array, and close does an aggregation before emitting\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud005.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "Advatages: Speed as not writing to disk\n",
    "Disadvantages: Explicit memory management required. Potential for order-dependent bugs\n",
    "\n",
    "* <b>“Pairs” vs “Stripes”</b>\n",
    " * Pairs is just emitting a key and a value\n",
    " * Stripes is grouping multiple results into an associative array with a defined structure so thaat in the combiner or reduce phase it can efficiently interpret the results\n",
    " \n",
    "* <b>Secondary Sorting</b>\n",
    "    * Value-to-Key Conversion: Creating a composite key is straight forward. What we need to do is analyze what part(s) of the value we want to account for during the sort and add the appropriate part(s) to the natural key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Hadoop'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">3. Hadoop</h3>\n",
    "\n",
    "* SequenceFiles: Binary encoded of a sequence of key/value pairs\n",
    "\n",
    "* Concrete classes for different data types:\n",
    "    * IntWritable\n",
    "    * LongWritable\n",
    "    * Text\n",
    "    * etc.\n",
    "\n",
    "* Writable Defines a de/serialization protocol.\n",
    "* Every data type in Hadoop is a Writable.\n",
    "* WritableComparable Defines a sort order.\n",
    "* All keys must be of this type (but not values).\n",
    "\n",
    "\n",
    "<b>Job submission process</b>\n",
    "* Client (i.e., driver program) creates a job, configures it, and submits it to job tracker\n",
    "* JobClient computes input splits (on client end)\n",
    "* Job data (jar, configuration XML) are sent to JobTracker\n",
    "* JobTracker puts job data in shared location, enqueues tasks\n",
    "* TaskTrackers poll for tasks\n",
    "* Off to the races…\n",
    "\n",
    "<h4>Hadoop Map-Reduce Process</h4>\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/cloud/cloud004.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "* Map outputs are buffered in memory in a circular\n",
    "buffer\n",
    "* When buffer reaches threshold, contents are\n",
    "“spilled” to disk\n",
    "* Spills merged in a single, partitioned file (sorted\n",
    "within each partition): combiner runs here\n",
    "\n",
    "\n",
    "Reduce side\n",
    "* First, map outputs are copied over to reducer\n",
    "machine\n",
    "* “Sort” is a multi-pass merge of map outputs\n",
    "(happens in memory and on disk): combiner runs\n",
    "here\n",
    "* Final merge pass goes directly into reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Other'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">5. Other</h3>\n",
    "\n",
    "HTTP Requests:\n",
    "* GET method should be safe (nullipotent) - calling it produces no side effects (unlike PUT and GET which may change things)\n",
    "* The GET, PUT and DELETE methods should be idempotent - repeated calls should have the same effect as a single request \n",
    "* Post is not idempotent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='Q&A'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">4. Q&A</h3>\n",
    "\n",
    "<h4>\n",
    "There is a large text file of information about films stored in the HDFS over a number of\n",
    "machines. Each line of this file describes the details of one film in the following format.\n",
    "title | year | runtime | genres | stars\n",
    "<br><br>\n",
    "The different fields are separated by the | character; the list of genres and the list of stars\n",
    "are both separated by commas; the runtime is measured in minutes.\n",
    "An example line is given below.\n",
    "The Godfather | 1972 | 175 | Crime, Drama | Marlon Brando, Al Pacino, James Caan\n",
    "You can assume that there are no duplicate records, and each distinct star’s name is unique.\n",
    "Write a MapReduce program (in pseudo-code) to calculate for each genre the average\n",
    "runtime of film in the 1970s.\n",
    "A combiner should be implemented to accelerate the computation.\n",
    "</h4>\n",
    "\n",
    "<code>\n",
    "class Mapper\n",
    "    method Map{string t, int r}\n",
    "        s = split s based on |\n",
    "        g = get genre from s\n",
    "        r = get run time from s\n",
    "        Emit(string g, pair (r, 1))     # Emit genre and (runtime , 1)\n",
    "\n",
    "clase Combiner\n",
    "    method Combine(string g, pairs[(r1,c1)(r2, c2) ...] P)\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for each pair (r,c) in P\n",
    "        sum = sum + r\n",
    "        count = count + c\n",
    "    Emit (g,pair(sum,count))\n",
    "\n",
    "class Reducer\n",
    "    method Reducer\n",
    "</code>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
