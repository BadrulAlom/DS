{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H3> Bayesian Probability </H3>\n",
    "\n",
    "* A core part of machine learning as well a fundamentally alternate viewpoint on statistical theory itself. \n",
    "* The frequentist view of the world (which is how most people learn statistics) is that one can only make make statements based on observed data (i.e. data sampling). \n",
    "* Bayesians allow for any prior beliefs about the data, prior to doing any sampling, allowing it to alter the posterior belief based on data.\n",
    "* Helpful in situations where there is not much data. For example in earthquake modelling there maybe only be 4 or 5 earthquakes to have ever occurred on some particular fault.\n",
    "* Bayesian probability statements are also easier to interpret \n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q) \n",
    "Suppose we are given a coin and told that it could be biased, so the\n",
    "probability of landing heads is not necessarily 0.5. Let θ denote the\n",
    "probability of it landing heads. We wish to learn about θ .\n",
    "We toss the coin N times and obtain Y heads. In frequentist statistics,\n",
    "the point estimate of θ would be Y / N, and a confidence interval can be\n",
    "constructed around this.\n",
    "Is this reasonable? </h4>\n",
    "\n",
    "Ans:\n",
    "Well, say we performed 100 tosses and got 48\n",
    "heads. The point estimate would be θ = 0.48. However in this situation\n",
    "it may be more reasonable to conclude that the coin isn’t biased as the vast majority of coins in the world are not biased, and observing 48 heads in 100 tosses is a normal outcome from tossing an unbiased coin.\n",
    "\n",
    "In other words, rather than concluding that θ = 0.48, we may wish to\n",
    "include prior information to make a more informed judgement.\n",
    "\n",
    "In a Bayesian analysis, we first need to represent our prior beliefs about\n",
    "θ . Specifically, we construct a probability distribution p (θ) which\n",
    "encapsulates our beliefs.\n",
    "\n",
    "There is no one way to do this! p (θ) represents the beliefs of one\n",
    "particular person based on their assessment of the prior evidence – it\n",
    "will not be the same for different people if they have different knowledge\n",
    "about what proportion of coins are biased. In some cases, p (θ) may be\n",
    "based on subjective judgement, while in others it may be based on\n",
    "objective evidence. This is the essence of Bayesian statistics –\n",
    "probabilities express degrees of beliefs.\n",
    "However since θ here represents the probability of the coin landing\n",
    "heads, it must lie between 0 and 1. So the function we use to represent\n",
    "our beliefs should only have mass in the interval [ 0 , 1 ] .\n",
    "\n",
    "The Beta distribution only has mass in [ 0 , 1 ] so it is a sensible choice for the probability mass funcrion of our prior belief.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Give a high level overview of Bayesian decision making</h4>\n",
    "\n",
    "We start with prior beliefs p (θ) about the state of the world. After observing the\n",
    "data y , we update these to give p (θ| y ) . Based on this, we then choose an\n",
    "action a i from the set of k actions.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>List the fundamental rules of probability</H4>\n",
    "\n",
    "<b>1) UNION (OR) rule:</b> $$p(a \\ or \\ b) = p(a) + p(b) - p(both)$$  i.e. a union b = p(a) + p(b) - p(a intersect b)\n",
    "\n",
    "<b>2) Product/Joint probability rule:</b>\n",
    "$$p(a,b)=p(a|b)*p(b) = p(b|a)*p(a) $$\n",
    "\n",
    "i.e. Specific combination of a & b = prob. of one given the other * prob of the other\n",
    "\n",
    "<b>3) SUM rule / Marginal distribution:</b>\n",
    "$$p(a)=\\sum_{b} p(a,b) =\\sum_{b} p(a|b)*p(b) $$\n",
    "i.e. p(a) across all the possible values of b\n",
    "\n",
    "<b>4) Bayes Rule</b>\n",
    "$$ P(a \\mid b) = \\frac{P(b \\mid a) \\, P(a)}{P(b)}=\\frac{P(a,b) \\,}{P(b)} $$\n",
    "\n",
    "The denominator here can be extended using the Marginal distribution rule to become:\n",
    "\n",
    "$$ P(a \\mid b) =\\frac{P(b \\mid a) \\, P(a)}{\\sum_{b} p(b|a)*p(a)} $$\n",
    "\n",
    "\n",
    "Important to know: \n",
    "* P(a) is referred to as the prior\n",
    "* P(b $\\mid$ a) is referred to as the liklihood\n",
    "* P(a $\\mid$ b) is referred to as the posterior\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q) Explain the chain rule</h4>\n",
    "\n",
    "P(A,B,C) = P(A| B,C) P(B,C) = P(A|B,C) P(B|C) P(C)\n",
    "\n",
    "P(A, B, ..., Z) = P(A| B, ..., Z) P(B| C, ..., Z) P(Y|Z) P(Z)\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Describe the Beta distribution</h4>\n",
    "The Beta distribution only has mass in [ 0 , 1 ] and so it makes a good distribution to use for representing probabilities.\n",
    "\n",
    "* beta(1,2) = 0.5\n",
    "* beta(2,1) = 0.5\n",
    "* beta(1,1) = 1\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain prior and posterior probabilities in relation to estimating parameters</h4>\n",
    "\n",
    "Ans: In a typical inference problem we have an unknown parameter θ which\n",
    "we wish to estimate. For example, θ may be the mean of a Normal\n",
    "distribution, or the probability of a particular coin landing heads when\n",
    "tossed. We also have data Y , such as the outcome of tossing the coin\n",
    "multiple times. We wish to use the data Y to learn about θ .\n",
    "\n",
    "The prior distribution p (θ) represents our beliefs about θ before\n",
    "incorporating the information from the data.\n",
    "The posterior distribution p (θ| Y ) represents our beliefs about θ\n",
    "after incorporating the information from the data.\n",
    "Bayes theorem tells us how to move from p (θ) to p (θ| Y ) . I.e. given we\n",
    "have some beliefs about θ before seeing the data, it tells us the beliefs\n",
    "p (θ| Y ) we should have about θ after seeing the data.\n",
    "\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain what is a conjugate prior</h4>\n",
    "The prior is conjugate if it belongs to the same family as the posterior. This will be the case if it matches the likelihood in terms of its dependence on the parameter.\n",
    "\n",
    "If the posterior distributions p(θ|x) are in the same family as the prior probability distribution p(θ), the prior and posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function. E.g. The beta distribution is a conjugate prior to the binomial liklihood and the resulting posterior is also a beta distribution\n",
    "\n",
    "There are three reasons why it's useful if your problem has a conjugate prior: \n",
    "\n",
    "* Calculating θ is, is made a lot easier: Think about Bayes theorem and what the denominator is for a simple problem in which θ is one of 2 possible values. Think about what the denominator calculation would look like. <br>Not imagine θ is one of any possible values in a distriution -- how much harder is to calculate the denominator now?\n",
    "\n",
    "* A conjugate prior gives you a way to control how much influence the likilihood has in determining the posterior. \n",
    "http://lesswrong.com/lw/5sn/the_joys_of_conjugate_priors/\n",
    "\n",
    "* Every new observation leads only to a change in the values of the parameters of the distribution for θ, as indicated by the sequential learning in § 1; no new algebra needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain what is a predictive function in relation to decision and risk?</h4>\n",
    "\n",
    "* If you see questions such as p($\\theta$  | Y) this is trying to determine $\\theta$ given the historical observations\n",
    "* If you see questions such as p(future value | past results) you are being asked to uses Bayes to predict future values based on taking into account all your historical observations up to that point into your prior.\n",
    "* E.g. (Z|R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is the fundamental equation of Bayesian prediction that uses theorem of total probability?</h4>\n",
    "\n",
    "if you have\n",
    "p($\\tilde{Y}$ | B) and p(B | Y) <br>\n",
    "(Y here represents posterior prob. of historical results)\n",
    "<br><br>\n",
    "Then p($\\tilde{Y}$ | Y) = $\\int$ p($\\tilde{Y}$ | B) p(B | Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Explain conditional independence</h4>\n",
    "\n",
    "Ans: If a and b are independent then p(a and b) = P(a) + p(b)\n",
    "Unfortuntely total independence is rare. Instead two variables may be independent under certain scenarios. \n",
    "Hence we can say, a and b are independent, given c.\n",
    "\n",
    "If a <i>independent</i> b | c, then p(a,b|c) = p(a|c)*p(c)\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Q: What is a loss function?</h4>\n",
    "\n",
    "Also known as a cost function. The loss function L (θ, θ̂) defines the loss incurred if we estimate the true\n",
    "value of θ by $\\hatθ̂$\n",
    "\n",
    "Expected Loss = Loss matrix ($L_{kj}$) * probability of it being x and each possible Class C.   This is expressed as a continuous solution space rather than discreet (so we are interested in the probability of a region, not a point) hence the integral. And we sum up this loss for all k and j (so yeah the sum of the loss in the loss matrix)\n",
    "\n",
    "In the loss matrix, k and j represent the class labels (e.g. isCancer, isNormal). \n",
    "\n",
    "<img src=\"img/lossMatrix.png\" height=\"100\" width=\"150\">\n",
    "\n",
    "Down the side it's what you say the label is, along the top it's what it actually is, and the value in the cross-section is some loss function you devise (in this case loss may be heavier if you say isNormal when its actually isCancer)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What is maximum liklihood estimation</h4>\n",
    "\n",
    "A method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters.\n",
    "\n",
    "In formulas:<br>\n",
    "$\\theta$ represents the parameter <br>\n",
    "$\\theta$ can be one more variables (e.g. mean and std. dev)<br>\n",
    "\n",
    "Max $p(data |  \\theta)$ across all possible values of $\\theta$<br>\n",
    "=Max $p(X_i =x_i|\\theta)$ across all possible values of $\\theta$\n",
    "\n",
    "Pro's:\n",
    "- Easy to compute & Interpret<br>\n",
    "- Asymptotically Consistent (converges towards to true solution as side of data, N, increases)\n",
    "- Lowest asymptotic variance (lowest possible error)\n",
    "- Invariant: Any transformation on the real $\\theta$ can also be applied to the MLE $\\theta$\n",
    "\n",
    "Cons:<br>\n",
    "- Point estimate - no indication of how much uncertainty there is\n",
    "- $\\theta$ may not be unique - could have more than 1 solution\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What is a decision region, decision boundary?</h4>\n",
    "\n",
    "Ans: \n",
    "* Decision region - a subset of your solution space that has been labelled as one classification.\n",
    "* Decision boundary - the boundary between decision regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Decision Theory is concerned with making a decision based on probabilities and particularly Bayes Theorem.\n",
    "How this is applied to machine learning and classification is examined here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Describe minimizing the risk of misclassification</h4>\n",
    "    \n",
    "For classification we can either minimize the probability of misclassification or maximize the probability of correct classification. We can model the decision in terms of Bayes theorem and then pick the classicification based on the whichever option has the lower (minimization of risk) or higher (maximization of being correct) probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is Utility?</h4>\n",
    "Ans: The opposite of loss, U = -L\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: Explain Liklihood, Maximum Liklihood, and Log-likihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Liklihood:</b>\n",
    "\n",
    "Liklihood is the opposite of knowing a probability distribution and asking questions about the probability of seeing a value based on that distributions. Likilhood asks what the is the probability of seeing that distribution given the observed values.\n",
    "\n",
    "$$ L(\\theta) = p(X|\\theta) = \\prod^N_{n=1} p(X_n|\\theta) $$\n",
    "\n",
    "The liklihood of a model with parameter(s) $\\theta$ = the probability of seeing the data sample X given $\\theta$ = the probability of all x given $\\theta$ multiplied together (assuming each x is independent)\n",
    "\n",
    "\n",
    "<b>Log-liklihood</b>\n",
    "\n",
    "For computational reasons its better to work with the log-liklihood.\n",
    "\n",
    "$$ ln \\, L(\\theta) = \\sum^N_{n=1} ln\\,p(X_n|\\theta) $$\n",
    "\n",
    "Note: By using log you can move from a 'product of' equation to a 'sum of' equation as <a href=\"https://people.richland.edu/james/lecture/m116/logs/properties.html\">\"the log of a product is the sum of the logs\"</a>\n",
    "\n",
    "<b> Maximum Liklihood Estimation</b>\n",
    "\n",
    "Think back to generative models where you are trying to build an internal view of an unknown external world  based on your observations. This is what Maximum liklihood estimation (MLE) seeks to do. It is a way of determining the parameter(s) $\\theta$ of whatever model you assume the external world to be, so as to maximize the chances of the values X being observed.\n",
    "\n",
    "$$ \\hat{\\theta} _{MLE} = \\underset{\\theta}{\\arg\\max} \\sum\\limits_{i=1}^n \\log f(x_i|\\theta)  $$\n",
    "\n",
    "Maximizing the log-liklihood is done by actually minimizing the negative log-liklihood  $- \\sum^N_{n=1} ln\\,p(X_n|\\theta) $ \n",
    "\n",
    "\n",
    "To find the minimum of a function we need to find the point at which the gradient is 0.\n",
    "\n",
    "<b> Maximum Liklihood Estimation for a Gaussian distribution</b>\n",
    "\n",
    "If we suspect the external model to be a Gaussian distribution then the process of determining the parameters gets simplified to:\n",
    "\n",
    "mean = $ \\frac1 N * \\sum^N_{n=1} x_n$ - i.e. the mean of your sample\n",
    "\n",
    "variance = $ \\frac1 N * \\sum^N_{n=1} (x_n - \\hat\\mu)^2$ - i.e. the variance of your sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Good video: https://www.youtube.com/watch?v=TaotW-u6eys\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: Imagine you observe two samples of data that come from two Gaussian distributions. You then recieve a new data point. How would you use Maximum Liklihood Estimation to determine which of the two underyling classess the data point belongs to?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Assign based on whether $ P(x | \\mu_1^* \\sum_1^*) > P(x | \\mu_0^* \\sum_0^*)$\n",
    "\n",
    "i.e. If the probabiloty of x happening given class 1 is greater than the probability of x happening given class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: What is the formula for calculating risk?\n",
    "\n",
    "$$Risk(action_i) = \\int p(\\theta|y)L(\\theta, action_i)p(\\theta) = \\sum_{\\theta} p(\\theta|y)L(\\theta,action_i) $$\n",
    "\n",
    "In English:\n",
    "\n",
    "Risk of doing an action = the sum of: \n",
    "    - the prob. of an adverse outcome given data y, \n",
    "    - times the size of loss(if that outcome happened and you did that action) \n",
    "    - times the prob. the prior prob out that outcome happening)\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What are the two main philosophies to predicting the class of something given x, (p|x)?</h4>\n",
    "\n",
    "Ans: Empirical Risk Empirical distribution and Bayesian Decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Explain zero-one loss utility</h4>\n",
    "Ans: Measuring the prediction performance based on the count of correct predictions. In the case of 1 class, Sum of (If correct = 1 else 0). For 2 classes, Sum of (If correct then 1 or 2 depending on which class it was, else 0).\n",
    "\n",
    "For j classes:\n",
    "\n",
    "$$ U(c* = j) = \\sum_i{U}ij p(c^{true} = i|x^*) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>Explain the Trapezoid rule</H4>\n",
    "\n",
    "The Trapezoid rule is one method for calculating the integral (space under a curve) in cases where we cannot use an analytic solution for the indefinite integral.\n",
    "\n",
    "\n",
    "<img src=\"img/0005.png\" height=\"100\" width=\"200\">\n",
    "\n",
    "It works by calculating the average value and multiplying it by the width:\n",
    "\n",
    "$$\\int_a^bf(x)dx \\approx \\frac{f(a)+f(b)}{2}(b-a)$$\n",
    "\n",
    "You can divide the problem space into several widths that you compute separately and add up in you wish to gain more accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Explain Non-informative priors</b>\n",
    " \n",
    "If we have no strong prior beliefs about μ and use an uninformative\n",
    "prior such as Gamma(0,0). Without any prior knowledge, our posterior mean is simply the empirical mean, and the posterior variance is the empirical variance.\n",
    "\n",
    "So we can still do Bayesian inference even when we have no strong prior beliefs about the parameter ( μ ) here - just take prior that has a very high variance, like this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>Explain numerical integration</h4>\n",
    "Numeric integration is a set of techniques for solving definite integrals\n",
    "in cases where we cannot find an analytic solution for the indefinite\n",
    "integral. I.e. it lets us do integrals of the form:\n",
    "\n",
    "$$\\int_a^bf(x)dx$$\n",
    "\n",
    "When doing Bayesian analysis on any non-trivial problem, some form of\n",
    "numeric integration will usually be required. Indeed, while most of the\n",
    "theory and mathematics of Bayesian inference was initially worked out\n",
    "during the years 1900-1970, it was only with the widespread availability\n",
    "of fast computers able to quickly perform numeric integration that it\n",
    "became popuar"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
