{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H3> Bayesian Statistics </h3>\n",
    "\n",
    "* A core part of machine learning as well a fundamentally alternate viewpoint on statistical theory itself. \n",
    "* The frequentist view of the world (which is how most people learn statistics) is that one can only make make statements based on observed data (i.e. data sampling). \n",
    "* Bayesians allow for any prior beliefs about the data, prior to doing any sampling, allowing it to alter the posterior belief based on data.\n",
    "* Helpful in situations where there is not much data. For example in earthquake modelling there maybe only be 4 or 5 earthquakes to have ever occurred on some particular fault.\n",
    "* Bayesian probability statements are also easier to interpret \n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Give a high level overview of Bayesian decision making</h4>\n",
    "\n",
    "We start with prior beliefs p (θ) about the state of the world. After observing the\n",
    "data y , we update these to give p (θ| y ) . Based on this, we then choose an\n",
    "action a i from the set of k actions.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>List the fundamental rules of probability</H4>\n",
    "\n",
    "<b>1) UNION (OR) rule:</b> $$p(a \\ or \\ b) = p(a) + p(b) - p(both)$$  i.e. a union b = p(a) + p(b) - p(a intersect b)\n",
    "\n",
    "<b>2) Product/Joint probability rule:</b>\n",
    "$$p(a,b)=p(a|b)*p(b) = p(b|a)*p(a) $$\n",
    "\n",
    "i.e. Specific combination of a & b = prob. of one given the other * prob of the other\n",
    "\n",
    "<b>3) SUM rule / Marginal distribution:</b>\n",
    "$$p(a)=\\sum_{b} p(a,b) =\\sum_{b} p(a|b)*p(b) $$\n",
    "i.e. p(a) across all the possible values of b\n",
    "\n",
    "<b>4) Bayes Rule</b>\n",
    "$$ P(a \\mid b) = \\frac{P(b \\mid a) \\, P(a)}{P(b)}=\\frac{P(a,b) \\,}{P(b)} $$\n",
    "\n",
    "The denominator here can be extended using the Marginal distribution rule to become:\n",
    "\n",
    "$$ P(a \\mid b) =\\frac{P(b \\mid a) \\, P(a)}{\\sum_{b} p(b|a)*p(a)} $$\n",
    "\n",
    "\n",
    "Important to know: \n",
    "* P(a) is referred to as the prior\n",
    "* P(b $\\mid$ a) is referred to as the liklihood\n",
    "* P(a $\\mid$ b) is referred to as the posterior\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q) Explain the chain rule</h4>\n",
    "\n",
    "P(A,B,C) = P(A| B,C) P(B,C) = P(A|B,C) P(B|C) P(C)\n",
    "\n",
    "P(A, B, ..., Z) = P(A| B, ..., Z) P(B| C, ..., Z) P(Y|Z) P(Z)\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>a) Write down Bayes theorem which relates p(T |E) to p(E|T ) </h4>\n",
    "p(T|E) = p(E|T)p(T)/p(E)\n",
    "\n",
    "<h4>b) Based on past experience, you know that when a large attack occurs, the expert\n",
    "correctly predicts it with probability 0.8. However there is also a 0.4 probability that\n",
    "the expert incorrectly predicts that an attack will occur when in fact no attack occurs.\n",
    "Additionally, your prior p(T) is 0.5\n",
    "Calculate p(T|E)</h4>\n",
    "<br>\n",
    "p(T |E) = 0.8 ∗ 0.5/0.6 = 0.67\n",
    "\n",
    "<h4>c)Write down the Theorem of Total Probability which expresses p(E) in terms of\n",
    "p(E|T ) and p(E|T')   (T' denotes that event T does not occur).</h4>\n",
    "\n",
    "p(E) = p(E|T)p(T) + p(E|T')p(T')\n",
    "p(E) = 0.8 ∗ 0.5 + 0.4 ∗ 0.5 = 0.6\n",
    "\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain prior and posterior probabilities in relation to estimating parameters</h4>\n",
    "\n",
    "Ans: In a typical inference problem we have an unknown parameter θ which\n",
    "we wish to estimate. For example, θ may be the mean of a Normal\n",
    "distribution, or the probability of a particular coin landing heads when\n",
    "tossed. We also have data Y , such as the outcome of tossing the coin\n",
    "multiple times. We wish to use the data Y to learn about θ .\n",
    "\n",
    "The prior distribution p (θ) represents our beliefs about θ before\n",
    "incorporating the information from the data.\n",
    "The posterior distribution p (θ| Y ) represents our beliefs about θ\n",
    "after incorporating the information from the data.\n",
    "Bayes theorem tells us how to move from p (θ) to p (θ| Y ) . I.e. given we\n",
    "have some beliefs about θ before seeing the data, it tells us the beliefs\n",
    "p (θ| Y ) we should have about θ after seeing the data.\n",
    "\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain what is a conjugate prior</h4>\n",
    "\n",
    "If the posterior distributions p(θ|x) are in the same family as the prior probability distribution p(θ), the prior and posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function. E.g. The beta distribution is a conjugate prior to the binomial liklihood and the resulting posterior is also a beta distribution\n",
    "\n",
    "There are two reasons why it's useful if your problem has a conjugate prior. \n",
    "\n",
    "a) Calculating what θ is, is made a lot easier. Think about Bayes theorem and what the denominator is for a simple problem in which θ is one of 2 possible values. Think about what the denominator calculation would look like. <br>Not imagine θ is one of any possible values in a distriution -- how much harder is to calculate the denominator now?\n",
    "\n",
    "b) A conjugate prior gives you a way to control how much influence the likilihood has in determining the posterior. \n",
    "http://lesswrong.com/lw/5sn/the_joys_of_conjugate_priors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Describe the Beta distribution</h4>\n",
    "The Beta distribution only has mass in [ 0 , 1 ] and so it makes a good distribution to use for representing probabilities.\n",
    "\n",
    "* beta(1,2) = 0.5\n",
    "* beta(2,1) = 0.5\n",
    "* beta(1,1) = 1\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>\n",
    "A new medical screening test is developed to assess whether a patient\n",
    "has a particular disease. The test is advertised to have the following\n",
    "degrees of accuracy: ”if the patient truly has the disease, then the test\n",
    "will correctly detect this and return a positive result with probability 0.95.\n",
    "If the patient truly does not have the disease, the test will correctly detect\n",
    "this and return a negative result with probability 0.98”\n",
    "Given that 1 in 1000 people in the population have the disease, what is\n",
    "the chance that a person testing positive on the test really has the\n",
    "disease?</h4>\n",
    "\n",
    "Ans:\n",
    "\n",
    "* p(d) = 1/1000 = 0.001\n",
    "* p(pos|d) = 0.95\n",
    "* p(not pos | not d) = 0.98\n",
    "\n",
    "* Therefore: p(d|pos) =  P(pos | d)P(d) / P(pos) = \n",
    "\n",
    "$\\frac{(0.95 * 0.001)}{(0.95 * 0.001 + 0.02 * 0.999)} = 0.047$\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Q: What is a loss function?</h4>\n",
    "\n",
    "Also known as a cost function. The loss function L (θ, θ̂) defines the loss incurred if we estimate the true\n",
    "value of θ by $\\hatθ̂$\n",
    "\n",
    "Expected Loss = Loss matrix ($L_{kj}$) * probability of it being x and each possible Class C.   This is expressed as a continuous solution space rather than discreet (so we are interested in the probability of a region, not a point) hence the integral. And we sum up this loss for all k and j (so yeah the sum of the loss in the loss matrix)\n",
    "\n",
    "In the loss matrix, k and j represent the class labels (e.g. isCancer, isNormal). \n",
    "\n",
    "<img src=\"img/lossMatrix.png\" height=\"100\" width=\"150\">\n",
    "\n",
    "Down the side it's what you say the label is, along the top it's what it actually is, and the value in the cross-section is some loss function you devise (in this case loss may be heavier if you say isNormal when its actually isCancer)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q) \n",
    "Suppose we are given a coin and told that it could be biased, so the\n",
    "probability of landing heads is not necessarily 0.5. Let θ denote the\n",
    "probability of it landing heads. We wish to learn about θ .\n",
    "We toss the coin N times and obtain Y heads. In frequentist statistics,\n",
    "the point estimate of θ would be Y / N, and a confidence interval can be\n",
    "constructed around this.\n",
    "Is this reasonable? </h4>\n",
    "\n",
    "Ans:\n",
    "Well, say we performed 100 tosses and got 48\n",
    "heads. The point estimate would be θ = 0.48. However in this situation\n",
    "it may be more reasonable to conclude that the coin isn’t biased as the vast majority of coins in the world are not biased, and observing 48 heads in 100 tosses is a normal outcome from tossing an unbiased coin.\n",
    "\n",
    "In other words, rather than concluding that θ = 0.48, we may wish to\n",
    "include prior information to make a more informed judgement.\n",
    "\n",
    "In a Bayesian analysis, we first need to represent our prior beliefs about\n",
    "θ . Specifically, we construct a probability distribution p (θ) which\n",
    "encapsulates our beliefs.\n",
    "\n",
    "There is no one way to do this! p (θ) represents the beliefs of one\n",
    "particular person based on their assessment of the prior evidence – it\n",
    "will not be the same for different people if they have different knowledge\n",
    "about what proportion of coins are biased. In some cases, p (θ) may be\n",
    "based on subjective judgement, while in others it may be based on\n",
    "objective evidence. This is the essence of Bayesian statistics –\n",
    "probabilities express degrees of beliefs.\n",
    "However since θ here represents the probability of the coin landing\n",
    "heads, it must lie between 0 and 1. So the function we use to represent\n",
    "our beliefs should only have mass in the interval [ 0 , 1 ] .\n",
    "\n",
    "The Beta distribution only has mass in [ 0 , 1 ] so it is a sensible choice for the probability mass funcrion of our prior belief.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Explain conditional independence</h4>\n",
    "\n",
    "Ans: If a and b are independent then p(a and b) = P(a) + p(b)\n",
    "Unfortuntely total independence is rare. Instead two variables may be independent under certain scenarios. \n",
    "Hence we can say, a and b are independent, given c.\n",
    "\n",
    "If a <i>independent</i> b | c, then p(a,b|c) = p(a|c)*p(c)\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What is maximum liklihood estimation</h4>\n",
    "\n",
    "A method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters.\n",
    "\n",
    "In formulas:<br>\n",
    "$\\theta$ represents the parameter <br>\n",
    "$\\theta$ can be one more variables (e.g. mean and std. dev)<br>\n",
    "\n",
    "Max $p(data |  \\theta)$ across all possible values of $\\theta$<br>\n",
    "=Max $p(X_i =x_i|\\theta)$ across all possible values of $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pro's:\n",
    "- Easy to compute & Interpret<br>\n",
    "- Asymptotically Consistent (converges towards to true solution as side of data, N, increases)\n",
    "- Lowest asymptotic variance (lowest possible error)\n",
    "- Invariant: Any transformation on the real $\\theta$ can also be applied to the MLE $\\theta$\n",
    "\n",
    "Cons:<br>\n",
    "- Point estimate - no indication of how much uncertainty there is\n",
    "- $\\theta$ may not be unique - could have more than 1 solution\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Decision Theory is concerned with making a decision based on probabilities and particularly Bayes Theorem.\n",
    "How this is applied to machine learning and classification is examined here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What is a decision region, decision boundary?</h4>\n",
    "\n",
    "Ans: \n",
    "* Decision region - a subset of your solution space that has been labelled as one classification.\n",
    "* Decision boundary - the boundary between decision regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Describe minimizing the risk of misclassification</h4>\n",
    "    \n",
    "For classification we can either minimize the probability of misclassification or maximize the probability of correct classification. We can model the decision in terms of Bayes theorem and then pick the classicification based on the whichever option has the lower (minimization of risk) or higher (maximization of being correct) probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is Utility?</h4>\n",
    "Ans: The opposite of loss, U = -L\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: Explain Liklihood, Maximum Liklihood, and Log-likihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Liklihood:</b>\n",
    "\n",
    "Liklihood is the opposite of knowing a probability distribution and asking questions about the probability of seeing a value based on that distributions. Likilhood asks what the is the probability of seeing that distribution given the observed values.\n",
    "\n",
    "$$ L(\\theta) = p(X|\\theta) = \\prod^N_{n=1} p(X_n|\\theta) $$\n",
    "\n",
    "The liklihood of a model with parameter(s) $\\theta$ = the probability of seeing the data sample X given $\\theta$ = the probability of all x given $\\theta$ multiplied together (assuming each x is independent)\n",
    "\n",
    "\n",
    "<b>Log-liklihood</b>\n",
    "\n",
    "For computational reasons its better to work with the log-liklihood.\n",
    "\n",
    "$$ ln \\, L(\\theta) = \\sum^N_{n=1} ln\\,p(X_n|\\theta) $$\n",
    "\n",
    "Note: By using log you can move from a 'product of' equation to a 'sum of' equation as <a href=\"https://people.richland.edu/james/lecture/m116/logs/properties.html\">\"the log of a product is the sum of the logs\"</a>\n",
    "\n",
    "<b> Maximum Liklihood Estimation</b>\n",
    "\n",
    "Think back to generative models where you are trying to build an internal view of an unknown external world  based on your observations. This is what Maximum liklihood estimation (MLE) seeks to do. It is a way of determining the parameter(s) $\\theta$ of whatever model you assume the external world to be, so as to maximize the chances of the values X being observed.\n",
    "\n",
    "$$ \\hat{\\theta} _{MLE} = \\underset{\\theta}{\\arg\\max} \\sum\\limits_{i=1}^n \\log f(x_i|\\theta)  $$\n",
    "\n",
    "Maximizing the log-liklihood is done by actually minimizing the negative log-liklihood  $- \\sum^N_{n=1} ln\\,p(X_n|\\theta) $ \n",
    "\n",
    "\n",
    "To find the minimum of a function we need to find the point at which the gradient is 0.\n",
    "\n",
    "<b> Maximum Liklihood Estimation for a Gaussian distribution</b>\n",
    "\n",
    "If we suspect the external model to be a Gaussian distribution then the process of determining the parameters gets simplified to:\n",
    "\n",
    "mean = $ \\frac1 N * \\sum^N_{n=1} x_n$ - i.e. the mean of your sample\n",
    "\n",
    "variance = $ \\frac1 N * \\sum^N_{n=1} (x_n - \\hat\\mu)^2$ - i.e. the variance of your sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Good video: https://www.youtube.com/watch?v=TaotW-u6eys\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: Imagine you observe two samples of data that come from two Gaussian distributions. You then recieve a new data point. How would you use Maximum Liklihood Estimation to determine which of the two underyling classess the data point belongs to?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Assign based on whether $ P(x | \\mu_1^* \\sum_1^*) > P(x | \\mu_0^* \\sum_0^*)$\n",
    "\n",
    "i.e. If the probabiloty of x happening given class 1 is greater than the probability of x happening given class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: What are the two main philosophies to predicting the class of something given x, (p|x)?</h4>\n",
    "\n",
    "Ans: Empirical Risk Empirical distribution and Bayesian Decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Explain zero-one loss utility</h4>\n",
    "Ans: Measuring the prediction performance based on the count of correct predictions. In the case of 1 class, Sum of (If correct = 1 else 0). For 2 classes, Sum of (If correct then 1 or 2 depending on which class it was, else 0).\n",
    "\n",
    "For j classes:\n",
    "\n",
    "$$ U(c* = j) = \\sum_i{U}ij p(c^{true} = i|x^*) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: You are planning a vacation in Italy. Before packing, you hear that there might\n",
    "be an earthquake the day you arrive.\n",
    "After consulting Google, you learn that in recent years there have been (on\n",
    "average) five earthquakes a year in the part of the country you are visiting\n",
    "(ignore leap years). Moreover, you learn that when there is an earthquake, the\n",
    "earthquake forecast service has correctly predicted it 90% of the time. The other\n",
    "10% of the times an earthquake is predicted, the forecast its wrong and there is\n",
    "no earthquake.\n",
    "What is the probability that there will be an earthquake on the day you arrive?</h4>\n",
    "\n",
    "\n",
    "Ans: \n",
    "* e = earthquake, e' = not earthquake,\n",
    "* f = an earthake being forecasted,   f' = an earthquake not being forecasted\n",
    "* p(e) = 5/365 = 0.0137,  p(e') = 1-p(e) = 0.9863\n",
    "* p(f|e) = 0.9,   p(f|e') = 0.1\n",
    "* p(f) = p(f|e)*p(e) + p(f|e')*p(e')       (prob of forecast given earthquake + prob. of forecast given no earthquake)\n",
    "\n",
    "Therefore: p(e|f) = p(f|e)p(e) / p(f) = 0.9*0.0137 / 0.9*0.0137 + 01*0.9863 = 0.11 ~ 11%\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: Consider a woman who has a brother with haemophilia, but whose father does\n",
    "not have haemophilia. This implies that her mother must be a carrier of the\n",
    "haemophilia gene on one of her X chromosomes and that her father is not a\n",
    "carrier. The woman herself thus has a fifty-fifty chance of having the gene.\n",
    "The situation involving uncertainty is whether or not the woman carries the\n",
    "haemophilia gene. The parameter of interest θ can take two states:\n",
    "• Carries the gene (θ = 1)\n",
    "• Does not carry the gene (θ = 0).\n",
    "<br><br>\n",
    "1. Write down the prior distribution for θ using the above information.\n",
    "<br>\n",
    "2. The data Y is the number of the woman’s sons who are infected. Suppose\n",
    "she has two sons, neither of whom is affected. Assuming the status of the two\n",
    "sons is independent, write down the likelihood function p(Y |θ) \n",
    "\n",
    "Note: if the woman is\n",
    "not a carrier then her sons cannot be affected, but if she is a carrier they each\n",
    "have a 50% chance of being effected).\n",
    "<br>\n",
    "3. Find the corresponding posterior distribution for θ</h4><br>\n",
    "\n",
    "1) $p(\\theta$ = 0) = 0.5, p($\\theta$ = 1) = 0.5\n",
    "\n",
    "2) The data is that neither son is affected. Let ’D’ denote this data.\n",
    "\n",
    "p(D|$\\theta$ = 0) = 1 (we know that neither son can get infected if the mother is not a carrier)\n",
    "\n",
    "p(D|$\\theta$ = 1) = 0.5 * 0.5 = 0.25\n",
    "\n",
    "3) \n",
    "p(D) = p(D|θ=0)p(θ = 0) + p(D|θ = 1)p(θ = 1) = 1 ∗ 0.5 + 0.25 ∗ 0.5 = 0.625\n",
    "<img src=\"img/0006.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Q: What is the formula for calculating risk?\n",
    "\n",
    "$$Risk(action_i) = \\int p(\\theta|y)L(\\theta, action_i)p(\\theta) = \\sum_{\\theta} p(\\theta|y)L(\\theta,action_i) $$\n",
    "\n",
    "In English:\n",
    "\n",
    "Risk of doing an action = the sum of: \n",
    "    - the prob. of an adverse outcome given data y, \n",
    "    - times the size of loss(if that outcome happened and you did that action) \n",
    "    - times the prob. the prior prob out that outcome happening)\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: The police believe that a criminal is guilty of theft. A criminal prosecutor has\n",
    "to decide whether the case is worth taking to court. He will take it to court if\n",
    "he believes the person will be convicted of the crime, and not take it to court\n",
    "otherwise (he is more concerned with his own career advancement than with\n",
    "justice!)\n",
    "\n",
    "Based on previous experience, the prosecutor knows that 70% of people who the\n",
    "police believe are guilty of theft get convicted in court. His loss function (based\n",
    "on career considerations) is as follows:\n",
    "\n",
    "<img src=\"img/dr1.png\" height=\"100\" width=\"400\">\n",
    "<br>\n",
    "\n",
    "Based purely on the prosecutor’s prior beliefs, should he take the case to\n",
    "court? (i.e. calculate the risks of both taking to court, and not taking to court)</h4>\n",
    "\n",
    "\n",
    "Ans:\n",
    "\n",
    "* p(guilty) = 0.7,  p(not guilty) = 0.3\n",
    "\n",
    "* Risk if taken to court = p(not guilty)* loss(if not found guity & taken to court) = $0.3 * 5 = 1.5$ \n",
    "\n",
    "* Risk if not taken to court = p(found guilty) * loss(if found guilty) = $0.7 * 1 = 0.7$\n",
    "\n",
    "Risk is lower is not taken to course therefore do not take to court.\n",
    "\n",
    "-----------------\n",
    "\n",
    "<h4>Q: A witness comes forward and claims to have information that will prove the\n",
    "person is guilty. The prosecutor knows that not all witnesses are reliable. Based\n",
    "on previous experience he knows that the probability of getting a conviction with\n",
    "a favourable witness is 0.9. Now that the prosecutor has this witness testimony, compute the risks of both\n",
    "taking to court and not taking to court, and find his optimal decision\n",
    "(hint: treat ”having a witness” as being the y = 1 case).</h4>\n",
    "\n",
    "\n",
    "Ans:\n",
    "After seeing the data, the risk becomes:\n",
    "\n",
    "$R(a_0 |y) = p(θ = 0|y)L(θ = 0, a_0 )+p(θ = 1|y)L(θ = 1, a_0 ) = 0.9∗0+0.1∗5 = 0.5$\n",
    "\n",
    "$R($a_1$ |y) = p(θ = 0|y)L(θ = 0, a_1 )+p(θ = 1|y)L(θ = 1, a_1 ) = 0.9∗1+0.1∗0 = 0.9$\n",
    "\n",
    "The risk is now minimised by taking to court\n",
    "\n",
    "Note: the calculations in this case are easier than the ones from the lecture\n",
    "because you are given p(θ|y) here, while in the lecture you were only given\n",
    "p(y|θ) and had to use Bayes theorem to find p(θ|y). Make sure you understand\n",
    "the difference! The question stated:\n",
    "”Based on previous experience he knows that the probability of getting a con-\n",
    "viction with a favourable witness is 0.9”\n",
    "i.e. this is telling you p(θ = 0|y) = 0.9 and p(θ = 1|y) = 0.1 directly.without\n",
    "the need for further calculation.\n",
    "\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q:\n",
    "A manufacturing company knows from previous experience that only 0.3% of batches are bad but also knows that the percentage of defective items in each bad batch varies. They know based on previous experience that it is equal to 0.05 on average, with a standard\n",
    "deviation of 0.01. A new batch is tested that contains 4 defective widgets out of 100. </h4>\n",
    "\n",
    "<h4>Derive the risk associated with both decisions (keeping and scrapping the batch), using the loss function below, where $\\theta = 1$ means batch is bad and $a_0$ is to keep the batch.\n",
    "<br>\n",
    "In other words, rather than assuming that the defective rate is equal to 0.05, put a Beta distribution prior on the defective rate with α and β chosen to give a mean of 0.05 and standard deviation 0.01, and then the risk of both decisions under this posterior. Recall that the dbeta() function in R will evaluate p(y|θ)).</h4>\n",
    "\n",
    "<img src=\"img/0007.png\" width=\"150\">\n",
    "\n",
    "\n",
    "The risk associated with action $a_1$ is:\n",
    "\n",
    "$$R(a_1|y) = \\sum_{i=0}^1 p(θ = i|y)L(θ=i,a_1) = p(θ=0|y)$$\n",
    "\n",
    "<img src=\"img/0008.png\" width=\"500\">\n",
    "\n",
    "so the risk is minimised by taking action $a_0$ , i.e. keeping the batch\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>Q: Suppose that we believe that the time-between-earthquakes on a particular fault follows an Exponential(0.1) distribution (higher numbers towards beginning then long tail). If an earthquake occurs today, what is the probability of the next earthquake occurring within 10 years?”</H4>\n",
    "\n",
    "* The R function pexp(x, lambda) returns the probability of a random variable with the Exponential(λ) distribution having a value <b>less than or equal to</b> x\n",
    "* pexp(10,0.1) = 0.6321206\n",
    "* The probability of the next earthquake happening within 10 years is hence 0.63, or 63%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Q: The average number of fatalities in a terrorist attack is 4.17 and follows an exponential distribution with $\\lambda$ = 0.24, what is the probability of 10 or more people dying? </h4>\n",
    "\n",
    "* The probability of more than 10 peple dying would be: 1 minus the probability of less than 10 dying\n",
    "* =1-pexp(10,0.24) = 0.09071795. Therefore 9% chance.\n",
    "\n",
    "<h4>Q: What would the probability of 30 or more people dying be if the number of attacks increased to 2000 a year?</h4>\n",
    "\n",
    "= 1 - pexp(30,0.24)$^{2000}$ = 0.78\n",
    "\n",
    "So there is a 78 % chance of at least one attack killing 30 or more people\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Suppose that a parameter θ has only two possible values, 1 or 2. A random\n",
    "variable Y is observed with the following distribution:\n",
    "<br><br>\n",
    "$$p(Y|θ = 1) = Gamma(2, 4)$$\n",
    "$$p(Y |θ = 2) = Gamma(6, 8)$$\n",
    "<br>\n",
    "\n",
    "Your task is to estimate θ. Let the actions $a_1$ and $a_2$ correspond to claiming that\n",
    "θ = 1 and θ = 2 respectively. The loss function is:</h4>\n",
    "\n",
    "<img src=\"img/0001.png\" height=\"100\" width=\"150\">\n",
    "\n",
    "<h4>\n",
    "a) Before observing the observation Y, your prior on θ is p(θ = 1) = 0.75. Compute\n",
    "the risk associated with both actions based only on this prior knowledge, and hence\n",
    "decide which action to take. </h4>\n",
    "\n",
    "For action $a_1$ , the risk is: R($a_1$) = L(θ = 1, $a_1$)p(θ = 1) + L(θ = 2, $a_1$)p(θ = 2)\n",
    "= 0 + 9 ∗ 0.25 = 2.25\n",
    "\n",
    "\n",
    "and for action $a_2$ the risk is:\n",
    "R($a_2$) = L(θ = 1, $a_2$)p(θ = 1) + L(θ=2, $a_1$)p(θ = 2 = 2 ∗ 0.75 + 0 = 1.5\n",
    "\n",
    "So we would take action $a_2$\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>\n",
    "\n",
    "b) You now observe the value Y = 1. Compute the risk of both actions given this\n",
    "observation, and hence decide which action to take. You may want to use the formula\n",
    "sheet. Note that when n is a positive integer, the Gamma function Γ(n) used in the\n",
    "Gamma distribution is equal to Γ(n) = (n − 1)! = 1 × 2 × ... × (n − 1). Also, recall\n",
    "that 0! = 1.</h4>\n",
    "\n",
    "<img src=\"img/0003.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "Notes:\n",
    "* We have to compute posterior probability given that we have observational data\n",
    "* We write out Bayes theorem as shown\n",
    "* 0.29 is calculated as: $\\frac{4^2}{1!}1^{2-1}e^{-6}$\n",
    "* 0.22P(Y) should read 0.22 / p(Y)\n",
    "* $\\frac{0.22}{p(Y)} + \\frac{0.18}{p(Y)} = \\frac{0.4}{p(Y)}=1;  p(Y) = 0.4$\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>An investment company wants to predict the probability of a stock having a negative\n",
    "log return on a particular week. The company has access to the previous 10 weekly\n",
    "log returns of the stock. \n",
    "\n",
    "Let $Y_i$ denote the log return of the stock on week i for\n",
    "i = 1, 2, . . . , 10. \n",
    "<br>\n",
    "$Z_i$ = 0 if $Y_i$ ≥ 0 and $Z_i$ = 1 if $Y_i$ < 0. \n",
    "<br>\n",
    "Let:\n",
    "    $$R = \\sum^{10}_{i=1}{Z_i}$$\n",
    "\n",
    "be the number of weeks with negative log returns in the historical data.</h4>\n",
    "<h4>\n",
    "Assuming that the $Y_i$ variables are independent and identically distributed, then R has a Binomial(10, \\theta). distribution. \n",
    "<h4>\n",
    "a) explain why the Beta(α, β) distribution is the conjugate prior for \\theta. You do not\n",
    "need to explicitly calculate the integral in the denominator of Bayes theorem.\n",
    "</h4>\n",
    "The prior distribution $p(\\theta)$ is said to be conjugate to the liklihood $p(Y|\\theta)$, if multiplying these two distributions together (as you do in the top row of Bayes Theorem) and normalizing (as you do using the denominator in Bayes theorem), gives another distribution of the same form as the posterior $p(\\theta|Y)$\n",
    "<br>\n",
    "<br>In this case the likelihood (up to proportionality, i.e. ignoring the normalizing part of the binomial formula) is $$\\theta^R (1 − \\theta)^{n−R}$$ \n",
    "The beta distribution matches this form and is hence conjugate\n",
    "<h4>\n",
    "b) Show that the posterior distribution p(\\theta|Y 1 , . . . , Y 10 ) is Beta(α + R, β + 10 − R).\n",
    "You do not need to explicitly calculate the integral in the denominator.\n",
    "</h4>\n",
    "$$p(\\theta|Y)  = p(\\theta|R) ∝ p(R|\\theta)p(\\theta) ∝ \\theta^R (1 − \\theta)^{10−R}\\theta^{α−1}(1 − \\theta)^{β−1}$$\n",
    "<br>\n",
    "This has the form of a Beta(α + R, β + 10 − R) distribution\n",
    "<br>\n",
    "\n",
    "<h4>\n",
    "For the remainder of this question you should use the fact that the Beta function\n",
    "B(α, β) used to define the Beta distribution, is defined as:</h4>\n",
    "\n",
    "<img src=\"img/0002.png\" height=\"100\" width=\"160\">\n",
    "\n",
    "<b>and that when n is a positive integer, Γ(n) = (n − 1)! <br>(this is known as the gamma function)</b>\n",
    "\n",
    "<h4>c) Suppose that 6 of the 10 observed log returns $Y_i$ are negative (i.e. R=6), and\n",
    "that that a uniform Beta(1,1) prior is chosen for the unknown Binomial parameter \\theta.\n",
    "Using the Trapezoid rule, compute the probability that \\theta is between 0.5 and 0.6</h4>\n",
    "\n",
    "* P(\\theta|Y) follows a Beta(7, 5) distribution. \n",
    "* To calculate the probabilty of Y being less than or equal to any 1 value in this distribution, you can use the Beta function. \n",
    "* For this question we neeed to calculate the probability it is between two points on the distribution\n",
    "\n",
    "* Therefore we need:\n",
    "\n",
    "$$\\frac{1}{\\frac{Γ(\\alpha)Γ(\\beta)}{Γ(\\alpha+\\beta)}} = 2310$$\n",
    "Note that: Γ(n) = (n − 1)! \n",
    "<br>\n",
    "$$\\int_{0.5}^{0.6}2310*\\theta^6(1-\\theta)^4$$\n",
    "\n",
    "We can approximate above integral using trapezoid rule $\\int_a^b f(x)dx = (b−a)(f(a) + f(b))/2$\n",
    "\n",
    "In this case we have f(0.5) = 2.26, and f(0.6) = 2.76.\n",
    "So probability is approximately 0.25\n",
    "\n",
    "<h4>d) Again suppose that R = 6 and that a Beta(1,1) prior has been chosen for \\theta. Show\n",
    "that the predictive distribution:<br>\n",
    "$$p(\\tilde{Z}|R) =\\int  p(\\tilde{Z}|\\theta)p(\\theta|R)d\\theta$$\n",
    "\n",
    "for predicting whether the log return will be negative on a particular week in the\n",
    "future is equal to:<br>\n",
    "$$p(\\tilde{Z}|R) = \\frac{1}{12} \\frac{Γ(7 + \\tilde{Z})Γ(6 − \\tilde{Z})}{Γ(7)Γ(5)}$$\n",
    "\n",
    "where $\\tilde{Z}$ i is the value of $Z_i$ on the week in question</h4>\n",
    "\n",
    "\n",
    "$$NOT YET ANSWERED$$\n",
    "\n",
    "<h4>\n",
    "e) Based on the above equation for p($\\tilde{Z}$|R) given in part d), compute the probability\n",
    "of the log return being negative on a particular week in the future.\n",
    "\n",
    "Note that when n is a positive integer, the Gamma function Γ(n) is equal to Γ(n) =\n",
    "(n − 1)! = 1 × 2 × ... × (n − 1). \n",
    "\n",
    "$$NOT YET ANSWERED$$\n",
    "\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>An insurance company offers hurricane insurance. To price the insurance product,\n",
    "the company must estimate the number of hurricanes that occur in a given year. Let\n",
    "$Y_1 , . . . , Y_n$ denote the number of hurricanes that have occurred in each of the previous n years. The company models these as independent and identically distributed Poisson(λ) random variables, i.e. $Y_i ∼ Poisson(λ)$.\n",
    "<br><br>\n",
    "a) Show that the Gamma(\\alpha, \\beta) distribution is the conjugate prior for λ (you do not need to evaluate the integral in the denominator of Bayes theorem).</h4>\n",
    "\n",
    "* Starting with writing out Bayes theorem (minus the denominator) and substituting both the poisson and gamma functions in:\n",
    "\n",
    "$$p(λ|Y) \\propto p(Y|λ)p(λ) = \\frac{λ^Ye^{-λ}}{Y!} \\frac{\\beta^{\\alpha}}{Γ(\\alpha)}λ^{\\alpha-1}{e^{-\\betaλ}}$$\n",
    "\n",
    "* Then take out the parts that are not dependent on λ as they are just a normalizing factor:\n",
    "\n",
    "$$\\propto  λ^{\\alpha-1}{e^{-\\betaλ}λ^Ye^{-λ}}$$\n",
    "\n",
    "* Then simplify:\n",
    "$$=λ^{\\alpha−1+Y}e^{−λ(\\beta+1)}$$\n",
    "\n",
    "This is a Gamma(\\alpha + Y, \\beta + 1) distribution.\n",
    "\n",
    "\n",
    "Notes: This is demonstrating the conjugate prior definition (see above) in action. The posterior is proportional to the liklihood * prior. The denominators are dropped as they only serve a normalization role and don't impact the solution.\n",
    "\n",
    "<h4>\n",
    "b) Write down the posterior distribution of λ given an uninformative Gamma(0,0)\n",
    "prior, and the observations $Y_1 = 3, Y_2 = 0, Y_3 = 1, Y_4 = 0, Y_5 = 4$.</h4>\n",
    "\n",
    "Based on the above argument, given $Y_1 to Y_n$ the posterior is Gamma($\\alpha+\\sum Y_i , \\beta + n$).\n",
    "\n",
    "So in this case the posterior is Gamma(8,5).\n",
    "\n",
    "<h4>\n",
    "c) Derive the predictive distribution:\n",
    "$$p(\\tilde{Y} |Y_1 , . . . , Y_5 ) = \\int p(\\tilde{Y}|\\theta)p(\\theta|Y_1 , . . . , Y_5 )d\\theta$$\n",
    "\n",
    "for predicting the number of hurricanes occurring in a future year, given the prior\n",
    "and data from part b). </h4>\n",
    "\n",
    "<img src=\"img/0004.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "Note: Prior and liklihood positions have been switched around here\n",
    "\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>Explain numerical integration</h4>\n",
    "Numeric integration is a set of techniques for solving definite integrals\n",
    "in cases where we cannot find an analytic solution for the indefinite\n",
    "integral. I.e. it lets us do integrals of the form:\n",
    "\n",
    "$$\\int_a^bf(x)dx$$\n",
    "\n",
    "When doing Bayesian analysis on any non-trivial problem, some form of\n",
    "numeric integration will usually be required. Indeed, while most of the\n",
    "theory and mathematics of Bayesian inference was initially worked out\n",
    "during the years 1900-1970, it was only with the widespread availability\n",
    "of fast computers able to quickly perform numeric integration that it\n",
    "became popuar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<H4>Explain the Trapezoid rule</h4>\n",
    "\n",
    "The Trapezoid rule is one method for calculating the integral (space under a curve) in cases where we cannot use an analytic solution for the indefinite integral.\n",
    "\n",
    "\n",
    "<img src=\"img/0005.png\" height=\"100\" width=\"200\">\n",
    "\n",
    "It works by calculating the average value and multiplying it by the width:\n",
    "\n",
    "$$\\int_a^bf(x)dx \\approx \\frac{f(a)+f(b)}{2}(b-a)$$\n",
    "\n",
    "You can divide the problem space into several widths that you compute separately and add up in you wish to gain more accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
