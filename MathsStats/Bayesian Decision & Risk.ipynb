{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<H3> Bayesian Statistics </h3>\n",
    "\n",
    "Bayesian theory on probability is a core part of machine learning as well a fundamentally alternate viewpoint on statistical theory itself. The frequentist view of the world is that one can only make make statements based on observed data (i.e. data sampling). Bayesians allow for any prior beliefs about the data, prior to doing any sampling, allowing it to alter the posterior belief based on data.\n",
    "\n",
    "This is helpful in situations where there is not much data. For example in earthquake\n",
    "modelling there maybe only be 4 or 5 earthquakes to have ever\n",
    "occurred on some particular fault.\n",
    "\n",
    "Bayesian probability statements are also easier to interpret which is\n",
    "important when communicating with non-statisticians. A frequentist 95 % confidence interval for a parameter θ does not mean that we are 95 % sure that θ lies in the interval. However, Bayesian credible intervals do have this interpretation. \n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give a high level overview of Bayesian decision making\n",
    "\n",
    "We start with prior beliefs p (θ) about the state of the world. After observing the\n",
    "data y , we update these to give p (θ| y ) . Based on this, we then choose an\n",
    "action a i from the set of k actions.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>List the fundamental rules of probability</H4>\n",
    "\n",
    "<b>1) UNION (OR) rule:</b> $$p(a \\ or \\ b) = p(a) + p(b) - p(both)$$  i.e. a union b = p(a) + p(b) - p(a intersect b)\n",
    "\n",
    "<b>2) Product/Joint probability rule:</b>\n",
    "$$p(a,b)=p(a|b)*p(b) = p(b|a)*p(a) $$\n",
    "\n",
    "i.e. Specific combination of a & b = prob. of one given the other * prob of the other\n",
    "\n",
    "<b>3) SUM rule / Marginal distribution:</b>\n",
    "$$p(a)=\\sum_{b} p(a,b) =\\sum_{b} p(a|b)*p(b) $$\n",
    "i.e. p(a) across all the possible values of b\n",
    "\n",
    "<b>4) Bayes Rule</b>\n",
    "$$ P(a \\mid b) = \\frac{P(b \\mid a) \\, P(a)}{P(b)}=\\frac{P(a,b) \\,}{P(b)} $$\n",
    "\n",
    "The denominator here can be extended using the Marginal distribution rule to become:\n",
    "\n",
    "$$ P(a \\mid b) =\\frac{P(b \\mid a) \\, P(a)}{\\sum_{b} p(b|a)*p(a)} $$\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Explain prior and posterior probabilities in relation to estimating parameters</h4>\n",
    "\n",
    "Ans: In a typical inference problem we have an unknown parameter θ which\n",
    "we wish to estimate. For example, θ may be the mean of a Normal\n",
    "distribution, or the probability of a particular coin landing heads when\n",
    "tossed. We also have data Y , such as the outcome of tossing the coin\n",
    "multiple times. We wish to use the data Y to learn about θ .\n",
    "\n",
    "The prior distribution p (θ) represents our beliefs about θ before\n",
    "incorporating the information from the data.\n",
    "The posterior distribution p (θ| Y ) represents our beliefs about θ\n",
    "after incorporating the information from the data.\n",
    "Bayes theorem tells us how to move from p (θ) to p (θ| Y ) . I.e. given we\n",
    "have some beliefs about θ before seeing the data, it tells us the beliefs\n",
    "p (θ| Y ) we should have about θ after seeing the data.\n",
    "\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Describe the Beta distribution</h4>\n",
    "Excellent explanation: http://stats.stackexchange.com/questions/47771/what-is-the-intuition-behind-beta-distribution\n",
    "\n",
    "beta(1,2) = 0.5\n",
    "\n",
    "beta(2,1) = 0.5\n",
    "\n",
    "beta(1,1) = 1\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "A new medical screening test is developed to assess whether a patient\n",
    "has a particular disease. The test is advertised to have the following\n",
    "degrees of accuracy: ”if the patient truly has the disease, then the test\n",
    "will correctly detect this and return a positive result with probability 0.95.\n",
    "If the patient truly does not have the disease, the test will correctly detect\n",
    "this and return a negative result with probability 0.98”\n",
    "Given that 1 in 1000 people in the population have the disease, what is\n",
    "the chance that a person testing positive on the test really has the\n",
    "disease?</h4>\n",
    "\n",
    "Ans:\n",
    "\n",
    "* p(d) = 1/1000 = 0.0001\n",
    "* p(pos|d) = 0.95\n",
    "* p(not pos | not d) = 0.98\n",
    "\n",
    "* Therefore: p(d|pos) =  P(pos | d)P(d) / P(pos) = \n",
    "\n",
    "$(0.95 * 0.001) / (0.95 * 0.001 + 0.02 * 0.999) = 0.045$\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Your company is launching a new product and is trying to determine whether a customer will buy the product after viewing it. Based on gut feel Tom thinks the probability distribution for whether someone will buy it is centered around 0.5 (half the people will buy it) and is quite confident about this. His colleague Jill also thinks it's 0.5 but thinks there's a wider amount of uncertainty around it. From an early test you carried out you found that 48% of people (out of 100 people who viewed it) purchased the product. How would you go about defining the probability distribution on what the true probability of buying the product is and the variance around it?</h4>\n",
    "\n",
    "1. Buying or not buy can be represented with a binomial distribution (a series of successes and failures).\n",
    "2. The best way to represent the prior expectations of Tom and Jill is with the Beta distribution. The domain of the Beta distribution is (0, 1), just like a probability distribution, so we already know we're on the right track- but the appropriateness of the Beta for this task goes far beyond that. \n",
    "3. We can ask for some estimates of the mean and variance and then develop the beta distribtution that matches these views. \n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q) \n",
    "Suppose we are given a coin and told that it could be biased, so the\n",
    "probability of landing heads is not necessarily 0 . 5. Let θ denote the\n",
    "probability of it landing heads. We wish to learn about θ .\n",
    "We toss the coin N times and obtain Y heads. In frequentist statistics,\n",
    "the point estimate of θ would be Y / N, and a confidence interval can be\n",
    "constructed around this.\n",
    "Is this reasonable? </h4>\n",
    "\n",
    "Ans:\n",
    "Well, say we performed 100 tosses and got 48\n",
    "heads. The point estimate would be θ = 0 . 48. However in this situation\n",
    "it may be more reasonable to conclude that the coin isn’t biased as the vast majority of coins in the world are not biased, and observing 48 heads in 100 tosses is a normal outcome from tossing an unbiased coin.\n",
    "\n",
    "In other words, rather than concluding that θ = 0 . 48, we may wish to\n",
    "include prior information to make a more informed judgement.\n",
    "\n",
    "In a Bayesian analysis, we first need to represent our prior beliefs about\n",
    "θ . Specifically, we construct a probability distribution p (θ) which\n",
    "encapsulates our beliefs.\n",
    "\n",
    "There is no one way to do this! p (θ) represents the beliefs of one\n",
    "particular person based on their assessment of the prior evidence – it\n",
    "will not be the same for different people if they have different knowledge\n",
    "about what proportion of coins are biased. In some cases, p (θ) may be\n",
    "based on subjective judgement, while in others it may be based on\n",
    "objective evidence. This is the essence of Bayesian statistics –\n",
    "probabilities express degrees of beliefs.\n",
    "However since θ here represents the probability of the coin landing\n",
    "heads, it must lie between 0 and 1. So the function we use to represent\n",
    "our beliefs should only have mass in the interval [ 0 , 1 ] .\n",
    "\n",
    "The Beta distribution only has mass in [ 0 , 1 ] so it is a sensible choice for the probability mass funcrion of our prior belief.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q) Explain the chain rule</h4>\n",
    "\n",
    "P(A,B,C) = P(A| B,C) P(B,C) = P(A|B,C) P(B|C) P(C)\n",
    "\n",
    "P(A, B, ..., Z) = P(A| B, ..., Z) P(B| C, ..., Z) P(Y|Z) P(Z)\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q: What is the difference between generative and discriminative models?\n",
    "\n",
    "* Discriminative models learn the (hard or soft) boundary between classes.\n",
    "* Generative models model the distribution of individual classes. I.e. they build a model of the external world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: Explain conditional independence</h4>\n",
    "\n",
    "Ans: If a and b are independent then p(a and b) = P(a) + p(b)\n",
    "Unfortuntely total independence is rare. Instead two variables may be independent under certain scenarios. \n",
    "Hence we can say, a and b are independent, given c.\n",
    "\n",
    "If a <i>independent</i> b | c, then p(a,b|c) = p(a|c)*p(c)\n",
    "\n",
    "i.e. If a and b are independent given c, then the probability of one of those, let's say a, is gonna be the probability of a given c, times the probability of c happening\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: What is Expectation? </h4>\n",
    "\n",
    "* Another way of saying average\n",
    "* The average value of some function f(x) under a probability distribution p(x)\n",
    "\n",
    "$ \\mathbf{E}(f) = \\displaystyle \\sum p(x)f(x)  $ -- discreet case\n",
    "\n",
    "$ \\mathbf{E}(f) = \\displaystyle \\int p(x)f(x)dx  $ -- continuous case\n",
    "\n",
    "* Expectation can be estimated from a N samples drawn from a probabilty distribution function:\n",
    "\n",
    "$ \\mathbf{E}(f) \\simeq \\frac1 N \\sum f(x_n)$\n",
    "\n",
    "Note: Multiplying by \\frac1 N is the same as dividing by N. You'll see this a lot in machine learning formulas.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q) Question</h4>\n",
    "\n",
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What is variance and covariance?\n",
    "\n",
    "* <b>Variance</b> is the amount of variablility around the Expectation:\n",
    "\n",
    "$$ var[f] = \\mathbf{E}[(f(x) - \\mathbf{E}[f(x)])^2]= \\mathbf{E}[f(x)^2] - \\mathbf{E}[f(x)]^2  $$\n",
    "\n",
    "\n",
    "This translates to: Variation = Mean of what you predicted$^2$ minus what you expected$^2$\n",
    "\n",
    "<br>\n",
    "* <b>Covariance</b>: Measures the joint-variability between two variables. \n",
    "\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What does this show?\n",
    "\n",
    "<img src=\"img/covariance.png\" height=\"200\" width=\"400\">\n",
    "\n",
    "Ans: \n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: What is maximum liklihood estimation</h4>\n",
    "\n",
    "A method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters.\n",
    "\n",
    "In formulas:<br>\n",
    "$\\theta$ represents the parameter <br>\n",
    "$\\theta$ can be one more variables (e.g. mean and std. dev)<br>\n",
    "\n",
    "Max $p(data |  \\theta)$ across all possible values of $\\theta$<br>\n",
    "=Max $p(X_i =x_i|\\theta)$ across all possible values of $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro's:\n",
    "- Easy to compute & Interpret<br>\n",
    "- Asymptotically Consistent (converges towards to true solution as side of data, N, increases)\n",
    "- Lowest asymptotic variance (lowest possible error)\n",
    "- Invariant: Any transformation on the real $\\theta$ can also be applied to the MLE $\\theta$\n",
    "\n",
    "Cons:<br>\n",
    "- Point estimate - no indication of how much uncertainty there is\n",
    "- $\\theta$ may not be unique - could have more than 1 solution\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Theory is concerned with making a decision based on probabilities and particularly Bayes Theorem.\n",
    "How this is applied to machine learning and classification is examined here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: What is a decision region, decision boundary?</h4>\n",
    "\n",
    "Ans: \n",
    "* Decision region - a subset of your solution space that has been labelled as one classification.\n",
    "* Decision boundary - the boundary between decision regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: Describe minimizing the risk of misclassification</h4>\n",
    "    \n",
    "For classification we can either minimize the probability of misclassification or maximize the probability of correct classification. We can model the decision in terms of Bayes theorem and then pick the classicification based on the whichever option has the lower (minimization of risk) or higher (maximization of being correct) probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Q: What is a loss function?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Also known as a cost function. \n",
    "    \n",
    "$$ \\mathbf{E}[L] = \\sum_k \\sum_j \\int_{R} L_{kj}p(x,C_k)dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translates to: Expected Loss = Loss matrix (L_kj) * probability of it being x and each possible Class C.   This is expressed as a continuous solution space rather than discreet (so we are interested in the probability of a region, not a point) hence the integral. And we sum up this loss for all k and j (so yeah the sum of the loss in the loss matrix)\n",
    "\n",
    "In the loss matrix, k and j represent the class labels (e.g. isCancer, isNormal). \n",
    "\n",
    "<img src=\"img/lossMatrix.png\" height=\"100\" width=\"150\">\n",
    "\n",
    "Down the side it's what you say the label is, along the top it's what it actually is, and the value in the cross-section is some loss function you devise (in this case loss may be heavier if you say isNormal when its actually isCancer)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>What is Utility?</h4>\n",
    "Ans: The opposite of loss, U = -L\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q: Explain Liklihood, Maximum Liklihood, and Log-likihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Liklihood:</b>\n",
    "\n",
    "Liklihood is the opposite of knowing a probability distribution and asking questions about the probability of seeing a value based on that distributions. Likilhood asks what the is the probability of seeing that distribution given the observed values.\n",
    "\n",
    "$$ L(\\theta) = p(X|\\theta) = \\prod^N_{n=1} p(X_n|\\theta) $$\n",
    "\n",
    "The liklihood of a model with parameter(s) $\\theta$ = the probability of seeing the data sample X given $\\theta$ = the probability of all x given $\\theta$ multiplied together (assuming each x is independent)\n",
    "\n",
    "\n",
    "<b>Log-liklihood</b>\n",
    "\n",
    "For computational reasons its better to work with the log-liklihood.\n",
    "\n",
    "$$ ln \\, L(\\theta) = \\sum^N_{n=1} ln\\,p(X_n|\\theta) $$\n",
    "\n",
    "Note: By using log you can move from a 'product of' equation to a 'sum of' equation as <a href=\"https://people.richland.edu/james/lecture/m116/logs/properties.html\">\"the log of a product is the sum of the logs\"</a>\n",
    "\n",
    "<b> Maximum Liklihood Estimation</b>\n",
    "\n",
    "Think back to generative models where you are trying to build an internal view of an unknown external world  based on your observations. This is what Maximum liklihood estimation (MLE) seeks to do. It is a way of determining the parameter(s) $\\theta$ of whatever model you assume the external world to be, so as to maximize the chances of the values X being observed.\n",
    "\n",
    "$$ \\hat{\\theta} _{MLE} = \\underset{\\theta}{\\arg\\max} \\sum\\limits_{i=1}^n \\log f(x_i|\\theta)  $$\n",
    "\n",
    "Maximizing the log-liklihood is done by actually minimizing the negative log-liklihood  $- \\sum^N_{n=1} ln\\,p(X_n|\\theta) $ \n",
    "\n",
    "\n",
    "To find the minimum of a function we need to find the point at which the gradient is 0.\n",
    "\n",
    "<b> Maximum Liklihood Estimation for a Gaussian distribution</b>\n",
    "\n",
    "If we suspect the external model to be a Gaussian distribution then the process of determining the parameters gets simplified to:\n",
    "\n",
    "mean = $ \\frac1 N * \\sum^N_{n=1} x_n$ - i.e. the mean of your sample\n",
    "\n",
    "variance = $ \\frac1 N * \\sum^N_{n=1} (x_n - \\hat\\mu)^2$ - i.e. the variance of your sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Good video: https://www.youtube.com/watch?v=TaotW-u6eys\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Imagine you observe two samples of data that come from two Gaussian distributions. You then recieve a new data point. How would you use Maximum Liklihood Estimation to determine which of the two underyling classess the data point belongs to?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Assign based on whether $ P(x | \\mu_1^* \\sum_1^*) > P(x | \\mu_0^* \\sum_0^*)$\n",
    "\n",
    "i.e. If the probabiloty of x happening given class 1 is greater than the probability of x happening given class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>Q: What are the two main philosophies to predicting the class of something given x, (p|x)?</h4>\n",
    "\n",
    "Ans: Empirical Risk Empirical distribution and Bayesian Decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: Explain zero-one loss utility</h4>\n",
    "Ans: Measuring the prediction performance based on the count of correct predictions. In the case of 1 class, Sum of (If correct = 1 else 0). For 2 classes, Sum of (If correct then 1 or 2 depending on which class it was, else 0).\n",
    "\n",
    "For j classes:\n",
    "\n",
    "$$ U(c* = j) = \\sum_i{U}ij p(c^{true} = i|x^*) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: You are planning a vacation in Italy. Before packing, you hear that there might\n",
    "be an earthquake the day you arrive.\n",
    "After consulting Google, you learn that in recent years there have been (on\n",
    "average) five earthquakes a year in the part of the country you are visiting\n",
    "(ignore leap years). Moreover, you learn that when there is an earthquake, the\n",
    "earthquake forecast service has correctly predicted it 90% of the time. The other\n",
    "10% of the times an earthquake is predicted, the forecast its wrong and there is\n",
    "no earthquake.\n",
    "What is the probability that there will be an earthquake on the day you arrive?</h4>\n",
    "\n",
    "\n",
    "Ans: \n",
    "* e = earthquake, e' = not earthquake,\n",
    "* f = an earthake being forecasted,   f' = an earthquake not being forecasted\n",
    "* p(e) = 5/365 = 0.0137,  p(e') = 1-p(e) = 0.9863\n",
    "* p(f|e) = 0.9,   p(f|e') = 0.1\n",
    "* p(f) = p(f|e)*p(e) + p(f|e')*p(e')       (prob of forecast given earthquake + prob. of forecast given no earthquake)\n",
    "\n",
    "Therefore: p(e|f) = p(f|e)p(e) / p(f) = 0.9*0.0137 / 0.9*0.0137 + 01*0.9863 = 0.11 ~ 11%\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: Consider a woman who has a brother with haemophilia, but whose father does\n",
    "not have haemophilia. This implies that her mother must be a carrier of the\n",
    "haemophilia gene on one of her X chromosomes and that her father is not a\n",
    "carrier. The woman herself thus has a fifty-fifty chance of having the gene.\n",
    "The situation involving uncertainty is whether or not the woman carries the\n",
    "haemophilia gene. The parameter of interest θ can take two states:\n",
    "• Carries the gene (θ = 1)\n",
    "• Does not carry the gene (θ = 0).\n",
    "<br><br>\n",
    "1. Write down the prior distribution for θ using the above information.\n",
    "<br>\n",
    "2. The data Y is the number of the woman’s sons who are infected. Suppose\n",
    "she has two sons, neither of whom is affected. Assuming the status of the two\n",
    "sons is independent, write down the likelihood function p(Y |θ) (if the woman is\n",
    "not a carrier then her sons cannot be affected, but if she is a carrier they each\n",
    "have a 50% chance of being effected).\n",
    "<br>\n",
    "3. Find the corresponding posterior distribution for θ</h4><br>\n",
    "\n",
    "1) $p(\\theta$ = 0) = 0.5, p($\\theta$ = 1) = 0.5\n",
    "\n",
    "2) \n",
    "\n",
    "p(Y|$\\theta$ = 0) = 1 (we know that neither son can get infected if the mother is not a carrier)\n",
    "\n",
    "p(Y|$\\theta$ = 1) = 0.5 * 0.5 = 0.25\n",
    "\n",
    "3) \n",
    "p($\\theta$ = 0 | Y) = $\\frac{p(Y|\\theta = 0)p(\\theta = 0)}{p(Y)}$ \n",
    "p(Y) = 1 * 0.5 + 0.25 * 0.5 = 0.625\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q: What is the formula for calculating risk?\n",
    "\n",
    "$$Risk(action_i) = \\int p(\\theta|y)L(\\theta, action_i)p(\\theta) = \\sum_{\\theta} p(\\theta|y)L(\\theta,action_i) $$\n",
    "\n",
    "In English:\n",
    "\n",
    "Risk of doing an action = the sum of: \n",
    "    - the prob. of an adverse outcome given data y, \n",
    "    - times the size of loss(if that outcome happened and you did that action) \n",
    "    - times the prob. the prior prob out that outcome happening)\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: The police believe that a criminal is guilty of theft. A criminal prosecutor has\n",
    "to decide whether the case is worth taking to court. He will take it to court if\n",
    "he believes the person will be convicted of the crime, and not take it to court\n",
    "otherwise (he is more concerned with his own career advancement than with\n",
    "justice!)\n",
    "\n",
    "Based on previous experience, the prosecutor knows that 70% of people who the\n",
    "police believe are guilty of theft get convicted in court. His loss function (based\n",
    "on career considerations) is as follows:\n",
    "\n",
    "<img src=\"img/dr1.png\" height=\"100\" width=\"400\">\n",
    "\n",
    "\n",
    "Based purely on the prosecutor’s prior beliefs, should he take the case to\n",
    "court? (i.e. calculate the risks of both taking to court, and not taking to court)</h4>\n",
    "\n",
    "\n",
    "Ans:\n",
    "\n",
    "* p(guilty) = 0.7,  p(not guilty) = 0.3\n",
    "\n",
    "* Risk if taken to court = p(not guilty)* loss(if not found guity & taken to court) = $0.3 * 5 = 1.5$ \n",
    "\n",
    "* Risk if not taken to court = p(found guilty) * loss(if found guilty) = $0.7 * 1 = 0.7$\n",
    "\n",
    "Risk is lower is not taken to course therefore do not take to court.\n",
    "\n",
    "-----------------\n",
    "\n",
    "<h4>Q: A witness comes forward and claims to have information that will prove the\n",
    "person is guilty. The prosecutor knows that not all witnesses are reliable. Based\n",
    "on previous experience he knows that the probability of getting a conviction with\n",
    "a favourable witness is 0.9. Now that the prosecutor has this witness testimony, compute the risks of both\n",
    "taking to court and not taking to court, and find his optimal decision\n",
    "(hint: treat ”having a witness” as being the y = 1 case).</h4>\n",
    "\n",
    "\n",
    "Ans:\n",
    "\n",
    "* p(found guilty | witness) = 0.9\n",
    "* Risk if taken to court = 0.1*\n",
    "\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>Q: A company knows from previous experience that only 0.3% of batches are bad but also knows that the percentage of defective items in each bad batch varies. They know based on previous experience that it is equal to 0.05 on average, with a standard\n",
    "deviation of 0.01. A new batch is tested that contains 4 defective widgets out of 100. </h4>\n",
    "\n",
    "<h4>Derive the\n",
    "risk associated with both decisions (keeping and scrapping the batch)\n",
    "(in other words, rather than assuming that the defective rate is equal to 0.05,\n",
    "put a Beta distribution prior on the defective rate with α and β chosen to give a\n",
    "mean of 0.05 and standard deviation 0.01, and then the risk of both decisions under\n",
    "this posterior. Recall that the dbeta() function in R will evaluate p(y|θ)).</h4>\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: Items are produced on an assembly line and the probability that any item is\n",
    "defective is given by θ. A uniform prior on θ is assumed (i.e. Beta(1,1)). An\n",
    "item is selected from the line and tested. What is the posterior distribution for\n",
    "θ if the item is\n",
    "(a) defective?\n",
    "(b) non defective?</h4>\n",
    "\n",
    "\n",
    "*  As the prior here is a Beta distribution, we can look up the conjugate-prior of Wikipedia as being:\n",
    "\n",
    "$$\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +n-\\sum _{i=1}^{n}x_{i}$$\n",
    "\n",
    "* For this question where we have Beta(1,1) to start with, this translates into: \n",
    "$$p(\\theta |Y=0) = 1 +\\sum _{i=1}^{n}x_{i},\\,1 +n-\\sum _{i=1}^{n}x_{i}$$ where n is the number of trials (in this case 1) and x is the number of successes (either 1 or 0 depending on whether its defective)\n",
    "\n",
    "Therefore:\n",
    "* p(0|Y=0) = Beta(1,2)\n",
    "* p(1|Y=1) = Beta(2,1)\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Q: Question template</h4>\n",
    "\n",
    "Answer..\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
