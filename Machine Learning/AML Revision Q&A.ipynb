{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center>Applied Machine Learning Q&A</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3>Topics covered in class</h3>\n",
    "\n",
    "<br>[<b>0. Key Revision Questions</b>](#KeyQuestions) \n",
    "\n",
    "<br>[<b>1. Linear Regression</b>](#Linear Regression)\n",
    "<br>[Least Squares Loss](#Loss)\n",
    "<br>[Auto Regressive Models](#AutoRegresiveModels)\n",
    "<br>[Radial Basis Functions](#Radial)  -- to do\n",
    "\n",
    "<br>[<b>2. Clustering and Classification</b>](#Clustering)\n",
    "<br>[Logistic Regression](#LogisticRegression)\n",
    "<br>[Maximum Liklihood](#MaxLiklihood)  -- to do\n",
    "<br>[Nearest  Neighbours](#Nearest Neighbours)\n",
    "<br>[Fastest Nearest Neighbours](#FastestNN)  --- not complete\n",
    "\n",
    "<br>[Naieve Bayes](#NaieveBayes)\n",
    "<br>[SVMs](#SVMs)\n",
    "<br>[Decision Trees](#DecisionTrees)  -- to do\n",
    "<br>[Mixture Models](#MixtureModels) -- to do\n",
    "\n",
    "<br>[<b>3. Ensemble Models (ISL only)</b>](#Clustering)\n",
    "<br>[Adaboost](#AdaBoost)\n",
    "<br>[Random Forest](#RandomForest)\n",
    "\n",
    "<br>[<b>4. Optimization</b>](#Optimization)\n",
    "<br>[Gradient Descent method](#GradientDescent)\n",
    "<br>[Newtons Method](#NewtonsMethod)\n",
    "<br>[Conjugate Gradients Method](#CG)\n",
    "<br>[Line search & conjugate gradients](#ConjugateGradients)\n",
    "<br>[Higher order methods](#HigherOrder)\n",
    "<br>[Dealing with Sparsity](#Sparsity)\n",
    "\n",
    "<br>[<b>5. Large Scale Machine Learning</b>](#LargeScale)\n",
    "<br>[Stochastic Gradient Descent](#SGD)\n",
    "<br>[Sparsity](#SGD)\n",
    "<br>[Batch vs Online](#BatchOnline)\n",
    "\n",
    "<br>[<b>6. Dimensionality Reduction</b>](#Dimensionality Reduction)\n",
    "<br>[PCA](#PCA)\n",
    "<br>[Non-Negative Matrix Factorization](#NNMF)\n",
    "<br>[ICA](#ICA)\n",
    "<br>[Fishers Linear Discrimnate & Canonical Variables](#Fishers)\n",
    "\n",
    "<br>[<b>7. Neural Networks</b>](#NN)\n",
    "<br>[Auto Encoders](#AutoEncoders)\n",
    "<br>[CNNs](#CNNs)\n",
    "<br>[NLP](#NLP)\n",
    "<br>[RNNs](#RNNs)\n",
    "<br>[Gradient Decay/Explosion](#DecayExplosion)\n",
    "<br>[LSTM](#LSTM)\n",
    "<br>[SeqToSeq and Bidirectional](#Seq)\n",
    "<br>[Parameter Tying](#ParamTying)\n",
    "<br>[BackProp Through Time](#BPTime)\n",
    "<br>[Auto Differentiation](#AutoDiff)\n",
    "<br>[Initialization](#Initializtion)\n",
    "\n",
    "<br>[<b>8. Visualization</b>](#Visualization)\n",
    "<br>[T-SNE](#TSNE)\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Useful Latex Math symbols</h4>\n",
    "\n",
    "http://web.ift.uib.no/Teori/KURS/WRK/TeX/symALL.html\n",
    "\n",
    "------------------------\n",
    "\n",
    "<h4>Guide</h4>\n",
    "* I have found that not all the formulas show up in Github - you may need to pull to your local computer and run Jupyter\n",
    "* If I say some external resource is 'recommended' it means it's a useful resource that will help cement the idea\n",
    "* If I say it's 'essential' it means drop everything you're doing and view it instead of reading my notes (e.g. https://www.youtube.com/watch?v=TEB2z7ZlRAw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='KeyQuestions'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">0. Key questions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1. [Explain Linear Regression](#Linear Regression)\n",
    "1. [Explain how regularization works](#Regularization)\n",
    "2. Discuss different types of regularizer terms\n",
    "3. Talk about non-squared loss\n",
    "4. Explain Nearest Neighbours, Mahalanobis distance, and K-NN\n",
    "2. Explain Naieve Bayes\n",
    "3. What is the log liklihood function?\n",
    "\n",
    "14. [Explain Gradient descent for minimizing least squared loss & adv/disadv](#GradientDescent)\n",
    "15. [Explain Conjugate Vectors method for minimizing least squared loss & adv/disadv](#CG)\n",
    "16. [Explain Newtons method for minimizing least squared loss & adv/disadv](#NewtonsMethod)\n",
    "17. [Explain Nesterovs Method](#Nesterov)\n",
    "18. [Explain Momentum](Momentum#)\n",
    "\n",
    "4. [Explain the PCA algorithm](#PCA)\n",
    "5. Explain why the SVD method is related to the eigen decomposition of S\n",
    "6. Compute the Gradient and Hessian of $$E(w) = \\frac{1}{N} \\sum^N_{n=1}(y^n-w^Tx^n)^2$$\n",
    "7. Explain what Stochastic Gradient Descent is and how it could be used to find\n",
    "the w that minimises E(w)\n",
    "8. Explain Conjugate Gradients\n",
    "9. Describe Forward Auto-Diff\n",
    "10. Describe Reverse Auto-Diff\n",
    "11. Explain Auto-Encoders and compare them to PCA\n",
    "12. Explain Fishers Linear Discrimnant\n",
    "13. Explain the relationship between Sparse vectors and Conjugate gradients\n",
    "Optimization:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Linear Regression'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">1. Linear Regression</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Introduction</h4>\n",
    "\n",
    "$$y_i = \\beta x^T +\\epsilon$$\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml010.png\" height=\"100\" width=\"300\">\n",
    "\n",
    "* Y is called the the response variable or dependent variable\n",
    "* X is called the regressors, explanatory variables, covariates, input variables, predictor variables, or independent variables \n",
    "* $\\beta$ is the parameter vector. <b>You will often see it being denoted by W, a weight vector.</b> Elements of this are interpreted as the partial derivatives of the dependent variable with respect to the various independent variables.\n",
    "* $\\epsilon$ is called the error term, disturbance term, or noise. This variable captures all other factors which influence the dependent variable y_i other than the regressors xi. The relationship between the error term and the regressors, for example whether they are correlated, is a crucial step in formulating a linear regression model, as it will determine the method to use for estimation.\n",
    "* Linear regression has a number of assumptions (https://en.wikipedia.org/wiki/Linear_regression#Extensions) some of which are addressed by the many extensions to it\n",
    "* Under-determined”: we have more parameters than training points - as such we have more unknowns than constraints. \n",
    "* ”Over-determined”: we have more training points than parameters. This means it'll be hard for the parameters to properly explain the output and will instead approximate to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4 style=\"background-color:#616161;color:white\">Measuring loss</h4>\n",
    "\n",
    "A large number of procedures have been developed for parameter estimation and inference in linear regression. \n",
    "\n",
    "<h4>Linear or Ordinary Least Squares (OLS)</h4>\n",
    "\n",
    "* Least squares problems fall into two categories: linear or ordinary least squares and non-linear least squares, depending on whether or not the residuals are linear in all unknowns. \n",
    "* The linear least-squares problem occurs in statistical regression analysis; and has a closed-form solution. \n",
    "* The non-linear problem is usually solved by iterative refinement; at each iteration the system is approximated by a linear one, and thus the core calculation is similar in both cases.\n",
    "\n",
    "Given N rows of data, the OLS loss is\n",
    "\n",
    "$$Loss(\\beta) = \\sum^N_{i=1} (y^i - \\beta^Tx^i)^2$$\n",
    "\n",
    "or\n",
    "\n",
    "$$E(w) = \\sum^N_{i=1} (y^i - w^Tx^i)^2$$\n",
    "\n",
    "* While this has a closed form solution it is computationally very expensive and not practical for a large matrix.\n",
    "* In this situation, using an iterative method is much more computationally efficient than using the closed form solution to the least squares problem. \n",
    "\n",
    "<h4>Generalised Least Squares (GLS)</h4>\n",
    "\n",
    "* An extension of OLS that allows estimation when heteroscedasticity (no constant variance), or correlations are present among the error terms of the model; as long as the form of heteroscedasticity and correlation is known independently of the data.\n",
    "\n",
    "<h4>Total least squares (TLS)</h4>\n",
    "An approach to least squares estimation of the linear regression model that treats the covariates and response variable in a more geometrically symmetric manner than OLS. It is one approach to handling the \"errors in variables\" problem, and is also sometimes used even when the covariates are assumed to be error-free.\n",
    "\n",
    "<h4>Maximum-likelihood estimation and related techniques</h4>\n",
    "\n",
    "- Maximum likelihood estimation can be performed when the distribution of the error terms is known to belong to a certain parametric family ƒθ of probability distributions. \n",
    "\n",
    "- Ridge regression and other forms of penalized estimation such as Lasso regression deliberately introduce bias into the estimation of $\\beta$ in order to reduce the variability of the estimate. The resulting estimators generally have lower mean squared error than the OLS estimates, particularly when multicollinearity is present or when overfitting is a problem. They are generally used when the goal is to predict the value of the response variable y for values of the predictors x that have not yet been observed. These methods are not as commonly used when the goal is inference, since it is difficult to account for the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Regularization'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Regularization</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain how regularization works</h4>\n",
    "\n",
    "* Adding a regularization term such as λw2λw2 to penalise rapid changes in the output helps reduce overfitting (when a statistical model describes random error or noise rather than the underlying relationship)\n",
    "\n",
    "Loss function adds one a term at the end (ususally the 'L2' term as shown):\n",
    "* $$E(w) =\\sum^{N}_{n=1}(y^n-w^Tx^n)^2+\\lambda w^Tw$$\n",
    "\n",
    "* The penalizes the loss function if w gets too big\n",
    "* But it plays no role in deterining the update to the weights\n",
    "\n",
    "* Without the regulaization the update to w would have been:\n",
    "\n",
    "$$w= \\left(\\sum_{n=1}^{N}x^n(x^n)^T  \\right)^{-1}\\left(\\sum_{n=1}^{N}y^nx^n\\right)$$\n",
    "\n",
    "* With regularization it is (proof below):\n",
    "$$w= \\left(\\sum_{n=1}^{N}x^n(x^n)^T + \\lambda I \\right)^{-1}\\left(\\sum_{n=1}^{N}y^nx^n\\right)$$\n",
    "\n",
    "* (The I identity matrix I is simply a trick we use to use the $\\lambda$ constant in a matrix multiplication)\n",
    "* So we see that the impact on how w is determined is negligible\n",
    "\n",
    "\n",
    "--------------------\n",
    "\n",
    "\n",
    "<h4>Proof</h4>\n",
    "\n",
    "Useful: http://www.statpower.net/Content/310/Summation%20Algebra.pdf\n",
    "<br><br>\n",
    "We wish to find w for the point at which the loss function is at its minimum:\n",
    "\n",
    "$$E(w) =\\sum^{N}_{n=1}(y^n-w^Tx^n)^2+\\lambda w^Tw$$\n",
    "\n",
    "1. Differentiate and equate to 0: \n",
    "$$\\frac{dE}{dw}=2\\sum^N_{n=1} (y^n-w^Tx^n)x^n + \\lambda w= 0$$\n",
    "\n",
    "\n",
    "2. Divide both sides by -2 then multiply out with $x^n$:\n",
    "$$\\sum^N_{n=1} (y^n)x^n - \\sum^N_{n=1}(w^Tx^n)x^n + \\lambda w = 0$$\n",
    "\n",
    "3. Using summation rule 2 to move the w out\n",
    "$$\\sum^N_{n=1} (y^nx^n) - w^T\\sum^N_{n=1}(x^n)(x^n)^T + \\lambda w = 0$$\n",
    "\n",
    "4. Note that the regularizer can also be written $w\\lambda$. Reverse multiply out with the w in the regularizing term (I gets introduced to keep $\\lambda$ in vector form once w disappears)\n",
    "$$ \\sum^N_{n=1} (y^nx^n) w \\left( \\sum^N_{n=1} ( x^n)(x^n)^T + \\lambda I \\right)  = 0$$\n",
    "\n",
    "5. Move yx to the right hand side\n",
    "$$ \\left(w^T\\sum^N_{n=1}x^n(x^n)^T \\right) + w \\lambda = \\sum^N_{n=1} (y^nx^n)$$\n",
    "\n",
    "6. Use inversion to divide\n",
    "\n",
    "$$w= \\left(\\sum_{n=1}^{N}y^nx^n\\right) \\left(\\sum_{n=1}^{N}x^n(x^n)^T + \\lambda I \\right)^{-1}$$</h4>\n",
    "\n",
    "<br>\n",
    "\n",
    "Note:\n",
    "* In practice you don't use matrix inversion because it's an O($n^3$) calculation and you also have to store the hessian at every iteration which is also very expensive\n",
    "* Gaussian elimination is faster and numerically more stable\n",
    "\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Discuss different types of regulatizer terms</h4>\n",
    "\n",
    "L1\n",
    "* Term is: $\\sum abs(w)$\n",
    "* Heavy and small $w_i$ is penalized by the a constant proportional amount\n",
    "* Penalty can't be differentiated so requires special optmization routines\n",
    "* But will mean that only significant weights remain\n",
    "* In practice (e.g. deep learning) people don't worry about it being non-differentiable and just proceed with gradient based training as normal\n",
    "\n",
    "L2\n",
    "* Term is: $ w^T w$ or $\\sum_i{w^2_i}$\n",
    "* Penalizes large W more than small ones\n",
    "* Penalty is differentiable\n",
    "* Small weights will still persists\n",
    "\n",
    "Shapes for regularisation penalty for 2 weights $\\sum_i | w_i|^q$\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml006.png\" height=\"100\" width=\"600\">\n",
    "\n",
    "* As we decrease q towards 0 we get the ‘ideal’ regulariser that selects weights\n",
    "which are 0 if they do not contribute.\n",
    "* For q = 1 the objective function for squared loss linear regression remains\n",
    "convex and easy to optimise\n",
    "* The objective function is complicated (non convex) for q < 1\n",
    "\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Loss Function'></a>\n",
    "\n",
    "<h4 style=\"background-color:#616161;color:white\">Loss Function</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* It’s very common to train models using the squared loss. However, if the task performance is measured by some other loss, it often makes more sense to train the model using the correct loss. \n",
    "\n",
    "* In which case optimal predictor won’t necessarily be simply the average of the prediction distribution. For example if using the summed absolute loss.\n",
    "\n",
    "* One often sees users train a model using one kind of loss, but evaluate it using a very different loss – seems a bad idea in general.\n",
    "\n",
    "* It’s also worth noting that the loss can heavily effect how easy it is to train a model. For example, in classification, using the logistic regression model gives a convex optimisation problem for θ. Using a squared loss gives a non-convex problem\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='AutoRegressiveModels'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Auto Regressive Models</h4>\n",
    "\n",
    "* In sequential data it's easy to incorporate previous values into our prediction model by having $k_{t-n}$ variables\n",
    "* Each term can have its own co-efficient to control the weighting you give it\n",
    "\n",
    "$$y_t \\approx \\sum^N_{i=1} w_i x_{t-i}$$\n",
    "\n",
    "* The model predicts the future based on a linear combination of the previous observations.\n",
    "* We can train this model as usual using the least squares objective with $L_1$ or $L_2$ regularisation.\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml019.png\" height=\"100\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Radial'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Radial Basis Functions</h4>\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---------------------------\n",
    "\n",
    "<a id='Clustering'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">2. Clustering & Classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='LogisticRegression'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Introduction</h4>\n",
    "\n",
    "* Logistic regression seeks to predict a class of data (binary or multi-class)\n",
    "* Like other linear regression inputs may be linear or categorical\n",
    "* The observed label in (binary) logistic regression is however a zero-or-one variable\n",
    "* The logistic regression estimates the odds, as a continuous variable\n",
    "* In some applications the odds are all that is needed. In others, a specific yes-or-no prediction is needed for whether the dependent variable is or is not a case; this categorical prediction can be based on the computed odds of a success, with predicted odds above some chosen cutoff value being translated into a prediction of a success.\n",
    "* Simple and fast to train\n",
    "* Fast to apply – typically scales O (D)\n",
    "* Objective function is concave\n",
    "* Can increase complexity by using kernels or non-linear mappings\n",
    "*Can easily scale up to huge sparse data\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain Binary Logistic regression</h4>\n",
    "\n",
    "<b>The main formula</b>\n",
    "\n",
    "* The Binary logistic regression formula is below, and the alternative (where c=0) is just 1 minus c=1:\n",
    "$$p(c = 1|x) = \\sigma(w^Tx + b)$$\n",
    "$$p(c = 0|x) = 1 − p(c = 1 |x)$$\n",
    "\n",
    "* As an aside compare this to the linear regression formula, so you see the main differenrence is the sigmoid function:\n",
    "$$y_i = w x^T +\\epsilon$$\n",
    "\n",
    "* The sigmoid function is used to control the prob that c= 0 or 1 only:\n",
    "$$\\sigma(x)=\\frac{e^x}{1+e^x}$$\n",
    "\n",
    "-----------\n",
    "\n",
    "<b>The loss function</b>\n",
    "\n",
    "$$L(w,b) = \\sum^N_{n=1}c^n log \\sigma (b+w^Tx^n)+ (1-c^n) log (1-\\sigma(b+w^Tx^n))$$\n",
    "\n",
    "* iterate through every data value and multiply up the estimated probability of it being in the class that its actually in\n",
    "* within the iteration the $C^n$ and $(1-C^n)$ are used to choose between the left or right probability as one will be 1 and the other 0\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "<b>Finding the minimal</b>\n",
    "\n",
    "* Requires solving it iteratively by finding the optimal weights w, and bias, b\n",
    "\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>\n",
    "Missing data is a common problem in practice. Describe how you might adapt logistic regression when there are missing elements in the input data vectors. Discuss the advantages and disadvantages of your approaches.\n",
    "</h4>\n",
    "<br><br>\n",
    "\n",
    "Would modify the cost function to using Naieve Bayes instead  as this can cope with missing data.(insert formula).\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<h4>\n",
    "In classification we often have an associated 'loss' function for each class. For\n",
    "example it might be that it is important in a medical situation to detect cancer, even\n",
    "if some of the detections are actually false. We can use a loss function L(ctrue, cpd)\n",
    "to measure our loss when our predicted class is Cpred whereas the truth is ctrue.\n",
    "<h4>\n",
    "i. Explain how to adapt logistic regression to minimize expected loss L(w) and derive a gradient based training scheme.\n",
    "<br><br>\n",
    "https://www.youtube.com/watch?v=IxotEG3yWHs\n",
    "\n",
    "<br><br>\n",
    "Replace the quadratic loss function with a Cross-entropy loss function\n",
    "\n",
    "<br><br>\n",
    "\n",
    "f. Comment on the geometric structure of the objective function L(w) and discuss any potential computational issues involved in training this model.\n",
    "<br><br>\n",
    "</h4>\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='NaieveBayes'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Naieve Bayes</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is Naieve Bayes</h4>\n",
    "\n",
    "<H2>Naieve Bayes</H2>\n",
    "<br>\n",
    "* Uses the Prediction formula from Bayesian Inference\n",
    "* Fast to train and apply\n",
    "* Can easily deal with missing data\n",
    "* Classifier is quite weak\n",
    "\n",
    "<h4>The algorithm</h4>\n",
    "\n",
    "$${\\begin{aligned}p(Y_{k}\\vert x_{1},\\dots ,x_{n})&\\varpropto p(Y_{k})\\prod _{{i=1}}^{n}p(x_{i}\\vert Y_{k})\\,.\\end{aligned}}$$\n",
    "\n",
    "\n",
    "* The maths behind it is explained very well in the <a href=\"http://scikit-learn.org/stable/modules/naive_bayes.html\">Skikit-learn pages</a>\n",
    "\n",
    "* p(x) can consist of mutiple things .. i.e.  inputs $x_1$,$x_2$,$x_3$\n",
    "* if the inputs $x_1$,$x_2$,$x_3$ are \"naievely\" assumed to be independent of each other (more on this later), so they don't impact each others probability of y, then we can use the multiplicative rule or probability and simplify the top to: \n",
    "$$p(Y_k)\\prod_{{i=1}}^{n} p(x_{i}\\vert Y_{k})$$\n",
    "* We do not need a denominator for this as we can say that it's a constant, having analyzed a corpus of data and determined the p of each x. For purposes of classification we can therefore ignore it.\n",
    "\n",
    "\n",
    "<i>$\\varpropto$ means in proportion to</i>\n",
    "\n",
    "Notes:\n",
    "<br>\n",
    "* The ability to assume independence under a given class is a crucial part of applied Bayes. So the words 'great' and tremendous' are postively correlated in a movie review, but if you took it for granted that the movie review was positive, then the probability of 'great' is unlikely to correlate as strongly with 'tremendous' - the two may be equally likely for instance.\n",
    "\n",
    "* Naieve Bayes is very fast to train, deals with more than two classes, and can deal with missing data\n",
    "* In the case of low counts the method can be overconfident although the use of pseudocounts can help (see literature)\n",
    "<br>\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='NearestNeighbour'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Nearest Neighbour</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain Linear Separability</h4>\n",
    "\n",
    "* If all the data for class 1 lies on one side of a hyperplane, and for class 0 on the\n",
    "other, the data is said to be linearly separable.\n",
    "* We can map using a non-linear vector function ψ(x) to make it linearly separable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain the Nearest Neighbour algorithm</h4>\n",
    "\n",
    "* New item x is classified based on the class of it's nearest neighbour in the dataset $x_1 ... x_n$\n",
    "* Distance is measured as the sum of the Euclidean squared distance across all dimensions D\n",
    "$$d(x,x') = \\sqrt{\\sum_{i=1}^{D}(x_i - x'_i)^2}$$\n",
    "* PCA can be used in cases of a high number of dimensions to improve calculation speed and improve results\n",
    "* It is not clear how to deal with missing data however or incorporate prior beliefs and domain knowledge\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is KNN?</h4>\n",
    "\n",
    "* Extension of NN where you use the class of the K nearest neighbours not just the 1st nearest\n",
    "* We first work out the liklihood model for each class (across all the data of that class):\n",
    "$$ p(x|c=0) = \\frac{1}{N_{class0}} \\sum_n \\mathcal{N}(x|x^n, \\sigma^2I)$$\n",
    "$$ p(x|c=1) = \\frac{1}{N_{class1}} \\sum_n \\mathcal{N}(x|x^n, \\sigma^2I)$$\n",
    "\n",
    "\n",
    "* We work out the probability of a point being within a normal distribution of every other point\n",
    "* To deal with outliers we create aritifical points where the mean of the class is, and give it a very large variance. That way the outlier's class is not infuenced by whatever is closes and effectively reverts back to the prior\n",
    "\n",
    "To then classify a new data point we use Bayes rule:\n",
    "\n",
    "$$ p(c=0|x^{*}) = \\frac{p(x^* | c = 0)p(c=0)}{p(x^{*}|c=0)p(c=0)+p(x^{*}|c=1)p(c=1)}$$\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is Mahalanobis distance?</h4>\n",
    "This is where you multiply the distance by the covariance matrix of the input (from all classes) which rescales the input vector and thus large values dominate less\n",
    "\n",
    "$$d(x, x') = (x − x' ) S^{−1} (x − x')$$\n",
    "\n",
    "where S is the covariance matrix of the inputs (from all classes)\n",
    "\n",
    "This helps make the input vector more scale tolerant (inputting as mm vs cm should provide similar results)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='FastestNN'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Fastest Nearest Neighbours</h4>\n",
    "\n",
    "* K-NN has the problem of being computationally expensive for large datasets. It takes O(D) complexity as for every data point you wish to classify you have to examine every other data point\n",
    "\n",
    "* There are several extensions that try and over come this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Orchard's Algorithm</h4>\n",
    "\n",
    "\n",
    "* Creates a one-time ordered list of the distance between each data point that you can use to to speed up the calculation of your nearest neighbours\n",
    "* Utilizes this rule\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml014.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "Notes:\n",
    "* Precomputation of distance matrix: O DN$^2$\n",
    "* Evaluating each member in the list: O (D)\n",
    "* Need to examine M < N members in the lists.\n",
    "* Orchard’s algorithm can work well in low dimensional cases, avoiding the calculation of many distances.\n",
    "* It requires however a potentially very time consuming one-time calculation of all point to point distances.\n",
    "* The storage of this inter-point distance matrix can be prohibitive.\n",
    "\n",
    "\n",
    "<h4>AESA</h4>\n",
    "\n",
    "The triangle inequality can be used to form a lower bound\n",
    "$$d(q,x^j ) \\geq d(q, x^i ) − d(x^i , x^j )$$\n",
    "\n",
    "Define I to be the set of datapoints for which d(q, x^i ), i \\element I has already\n",
    "been computed. One can then maximise the lower bounds to find the tightest\n",
    "lower bound on all other d(q, x^j )\n",
    "\n",
    "$$d(q, x^j ) \\geq max [d(q, x^i ) − d(x^i , x^j )]$$\n",
    "where i∈I\n",
    "\n",
    "* All datapoints x j whose lower bound is greater than the current best nearest\n",
    "neighbour distance can then be eliminated. \n",
    "* One may then select the next (non-eliminated) candidate datapoint x j corresponding to the lowest bound and continue, updating the bound and eliminating.\n",
    "\n",
    "Notes:\n",
    "* Precomputation of distance matrix: O (DN^2)\n",
    "* Evaluating the bound for all M remaining datapoints: O (M (N − M ))\n",
    "\n",
    "Need to compute M < N bounds.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "* Both Orchard’s algorithm and AESA can significantly reduce the number of\n",
    "distance calculations required.\n",
    "\n",
    "* However, we pay an O N 2 storage cost. For very large datasets, this storage cost is likely to be prohibitive.\n",
    "* (More strictly, we can actually compute the distances d(x i , x j ) ‘on the fly’ when they are required. For a single query this may be effective; however for many different queries, we would end up recomputing these distances – hence we may as well store them.)\n",
    "\n",
    "* Given the difficulty in storing d i,j , an alternative is to consider the distances between the training points and a smaller number of strategically placed ‘buoys’ (also called ‘pivots’ or ‘basis vectors’)\n",
    "\n",
    "* These buoys can be either a subset of the original datapoints, or new positions.\n",
    "\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "<h4>KD Trees</h4>\n",
    "\n",
    "* K-dimensional trees are a way to form a hierarchical partition of the space that can be used to help speed up search.\n",
    "* This is a form of ‘spatial data structure’\n",
    "* An advantage over the Orchard and AESA approaches is that the storage cost of the tree is only O(N).\n",
    "* Also, only in the worst case are O (N) operations required for a new query.\n",
    "* Before introducing the tree, we’ll discuss the basic idea on which the potential speed-up is based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='SVMs'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">SVMs</h3>\n",
    "\n",
    "Recommended: http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf\n",
    "\n",
    "Recommended: http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html\n",
    "\n",
    "* Basic concept is that we can linearly separate what appears to be linearly inseparable data by addining new dimensions to it until we can find a linear seperation that works (think going from 2d to 3d). This transformation is known as a Kernel.\n",
    "* However as technically transforming all the data like that is computationally in efficient there is a 'Kernel trick' that allows us to find the separation without having to transform the data\n",
    "* <b>The Kernel Trick</b>: In the dual formulation of the SVM, features only appear as dot products which can be represented compactly by kernels.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* For large values of C, the penalty for misclassifying points is very high, so the decision boundary will perfectly separate the data if possible.\n",
    "\n",
    "* C is the penalty amount given to the slack variablles:\n",
    "    -  A large value of C means slack variables are being penalized a lot, so you have a narrow margin and \n",
    "    - A low C means more slack\n",
    "* Consider a point that is correctly classified and distant from the decision boundary. The hinge loss used by SVMs gives zero weight to these points (in constrst to log-loss used by logistic regression, which gives a little bit of weight to these points.)\n",
    "* A flexible model approximates the target function well in the training set but can “overtrain” and have poor performance on the test set (“variance”)\n",
    "* A rigid model’s performance is more predictable in the test set but the model may not be good even on the training set (“bias”)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='EnsembleMethods'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">3. Ensemble Methods (ISL only)</h2>\n",
    "\n",
    "<a id='AdaBoost'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Adaboost</h3>\n",
    "\n",
    "\n",
    "<h4>The concept</h4>\n",
    "Create a good classifier by combining the outputs of multiple weak classifier - a \"wisdom of the crowds\" approach.\n",
    "\n",
    "$$F_T(x) = \\sum_{t=1}^T f_t(x)\\,\\!$$\n",
    "\n",
    "- where T = total number of classifiers\n",
    "- $f_t$ is individual weak classifier, $F_T$ is the strong classifier\n",
    "- x is the input value you wish to classify\n",
    "\n",
    "<h4>The algorithm</h4>\n",
    "<br>\n",
    "1. Given N rows of input (x) and output (y), where the y is either a 1 or a -1\n",
    "2. Distribute the initial weights as simply 1/N .   So $D_1(i) = 1/N$\n",
    "3. Iterate through each classifier (t) that you want to try (so t = 1 to T)\n",
    "    * See which classifer has the lowest error given the initial weight distribution\n",
    "    * Update the weight distribution such that that those that matched decrease in weighting, and those that did not match have a stronger weight (the idea being their error is being emphasised in the next iteration)\n",
    "4. Final classifier will be the weighted sum of the best 'weak' classifier in each iteration\n",
    "\n",
    "Notes:\n",
    "\n",
    "* As Adaboost is a combination of linear classifiers it will not be able to reach zero loss if the data is not linearly separable\n",
    "* The condition for Adaboost to progress is that the expected error is less than 0.5. If it becomes equal to 0.5 then the weight of the weak learner becomes 0 - so there is no progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Optimization'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">3. Optimization</h2>\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml018.png\" height=\"100\" width=\"300\">\n",
    "\n",
    "Recommended reading: http://sebastianruder.com/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='GradientDescent'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Gradient Descent</h4>\n",
    "\n",
    "Essential viewing: https://www.youtube.com/watch?v=TEB2z7ZlRAw\n",
    "\n",
    "* Gradient descent is an iterative method that seeks to minimize some function f(x) in cases where no closed form solution exists\n",
    "* It works by determining the new value of f(x) as: <br>\n",
    "$$=NewFunctionValue \\approx OldFunctionValue + VectorChange * GradientOfFunction$$\n",
    "\n",
    "$$= f(x_{k+1})\\approx f(x_k)+(x_{k+1}-x_k)^T \\triangledown f(x_k)$$ \n",
    "\n",
    "* We can infer that the value that maximizes the change in the function is going to be when the VectorChange (can be thought of as the direction of change) overlaps the most it is in the same direction as the gradient.\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml013.png\" height=\"100\" width=\"300\">\n",
    "\n",
    "* The VectorChange is worked out as: \n",
    "$$New \\ x = previous \\ x - LearningRate* GradientOfFunction$$\n",
    "\n",
    "$$x_{k+1} = x_k - \\epsilon \\triangledown f(x_k)$$\n",
    "\n",
    "* We can aso write this out in Matrix notation:\n",
    "\n",
    "$$x_{k+1} = x_k - \\epsilon C^{-1}g$$\n",
    "where the C is a positive definite matrix so that $\\epsilon$ gets converted into a vector\n",
    "\n",
    "Notes:\n",
    "* It is the 'previous x minus' that causes it to go to do gradient descent rather than ascent\n",
    "\n",
    "Advantages:\n",
    "* Simple and easy to implement\n",
    "\n",
    "Disadvantages:\n",
    "* If the LearningRate is too great it may overshoot the optimal and hence zig-zag\n",
    "* If it's too small it will take a long time to converge\n",
    "* Co-ordinate system dependent\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='NewtonsMethod'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Newtons Method</h4>\n",
    "\n",
    "<h4> Explain Newtons Optimization Method</h4>\n",
    "\n",
    "* The Taylor series expansion tells us that any function can be written as a series of higher order polynomial expansions\n",
    "\n",
    "* Newtons methods makes use of this to write $f(x + \\triangle)$ up to the second order, where the second order of the gradient is known as the Hessian matrix, H\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml015.png\" height=\"100\" width=\"300\">\n",
    "\n",
    "* Written in this way, we are able to differentiate and find the minimal value as the inverse of the Hessian multiplied by the gradient (remember $^{-1}$ is how  you divide in Matrix multiplication):\n",
    "\n",
    "$$x_{k+1} = x_k - \\epsilon H_f^{-1} \\nabla f$$\n",
    "\n",
    "* However storing the Hessian and solving the linear system like this is computationally very expensive\n",
    "* So instead we can use Conjugate gradient to minimize $H\\triangle = \\nabla f$ instead\n",
    "\n",
    "\n",
    "* This means Newtons method can converge in one step (for $\\epsilon$ = 1), although generally one uses a $\\epsilon$ < 1 to avoid overshooting effects.\n",
    "\n",
    "<b>Adv/Dis-adv</b>\n",
    "\n",
    "* Adv: The decrease of the objective function is independent of the coordinate system (for linear transformations of the coordinates)\n",
    "* However we cant' guarantee we will go downhill unless the learning rate is small and H is a positive definite\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='CG'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Congjugate Gradients</h4>\n",
    "\n",
    "https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf\n",
    "\n",
    "* Conjugate gradient descent is a way of doing gradient descent by optimizing along one dimension at a time\n",
    "* We have a set of weights, x that we wish to update with each iteration until it reaches the optimal\n",
    "$$x_k+1 = x_k + \\alpha_kp_k$$\n",
    "\n",
    "* Imagine an n dimensional problem that is convex such as this quadratic: \n",
    "\n",
    "    <img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml011.png\" height=\"100\" width=\"300\">\n",
    "<br>\n",
    "* A represents the thing you are multiplying your weights with (so in NN either input data or output from the prevous layer)\n",
    "\n",
    "* We wish to find the optimal weights (x in this formula) such that it minimizes the error\n",
    "\n",
    "* Conjugate gradient descent says that we get the zig-zag behaviour because A is not diagonal (it has values everywhere and therefore you cannot optimize for just one dimension without impacting the others\n",
    "\n",
    "\n",
    "* So we break up our weight vector x into two components $\\alpha$ and P such that $P^TAP$  is a diagonal matrix \n",
    "\n",
    "* In other words P becomes a filter that diagonalizes the problem for any given iteration leaving us free to do a line search for the optinal alpha in that iteration\n",
    "\n",
    "* We can now optimize along each dimension i, and each time the $p_i$ vector is updated such that it is orthogonal to all previous p vectors in order for this filtering to work\n",
    "\n",
    "* You can imagine this in the bowl as a two vectors that are orthogonal (right-angled) from each other - that way  you can optimize one without worrying about the effect it will have on the other\n",
    "\n",
    " <img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml012.png\" height=\"100\" width=\"200\">\n",
    " \n",
    "* In a quadratic problem this means that this:\n",
    "$$f(x)=\\frac{1}{2}x^TAx-b^Tx $$\n",
    "becomes this (i.e. x replaced by $\\alpha$ p):\n",
    "\n",
    "$$f(x)=\\frac{1}{2}p^TAp-b^Tp $$\n",
    "\n",
    "$$f(x)=\\sum_{i=1}^{n} \\left(\\frac{1}{2} \\alpha_i^2p_i^TAp_i-\\alpha_ib^Tp_i \\right ) $$\n",
    "\n",
    "\n",
    "* We can find each new p using the Polak-Ribière formula: which uses the gradients to find the next conjugate vector, which then allow us to make the update within each iteration:\n",
    "$$x_k+1 = x_k + \\alpha_kp_k$$\n",
    "\n",
    "where each p is a diagonal only for k (so when you move to the next direction it becomes 0's)\n",
    "\n",
    "* Note: In a non quadratic problem no such method exists\n",
    "\n",
    "Finally we get to the following algorithm:\n",
    "\n",
    "1. k = 1\n",
    "2. Choose $x_1$\n",
    "3. $p_1$ = $−g_1$  # pick any gradient\n",
    "4. while $g_k \\neq 0$ do  # while not at the minimum\n",
    "    \n",
    "    * $\\alpha_k$ = argmin $f(x_k + \\alpha_k p_k) $  &nbsp;&nbsp;&nbsp;&nbsp; # Do a line search to find the optimal $\\alpha$\n",
    "    * $x_{k+1} := x_k + \\alpha_k p_k$    &nbsp;&nbsp;&nbsp;&nbsp; # Add on the optimum\n",
    "    * $\\beta_k := g_{k+1}^Tg_{k+1}/(g^T_kg_k)$  &nbsp;&nbsp;&nbsp;&nbsp; # Find new conjugate direction\n",
    "    * $p_{k+1} =  -g_{k+1} + \\beta_kp_k$     &nbsp;&nbsp;&nbsp;&nbsp; # Update next p\n",
    "    * k = k +1\n",
    "10. end while\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Momentum'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Momentum</h4>\n",
    "\n",
    "* Taking a moving average of the update \n",
    "* Reduces zig-zagging behaviour and help push past saddle points (local minima followe by a local maxima)\n",
    "* It is one way of updating the moving average without re-computing everything\n",
    "$$x_k + \\tilde g_{k+1}$$ \n",
    "\n",
    "* Momentum can increase the speed of convergence since, for smooth objectives, as we get close to the minimum the gradient decreases and standard gradient descent would start to slow down\n",
    "* If the learning rate is too large, standard gradient descent may oscillate, but momentum may reduce oscillations by going in the average direction.\n",
    "* However, the momentum parameter $\\mu$ may need to be reduced with the iteration count to ensure convergence.\n",
    "* Particularly useful when the gradient is noisy. By averaging over previous gradients, the noise ‘averages’ out and the moving average direction can be much less noisy.\n",
    "* Momentum is also useful to avoid saddles (a point where the gradient is zero, but the objective function is not a minimum, such as the function x 3 at the origin) since typically the momentum will carry you over the saddle.\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Nestorov'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Nestorov's accelerated gradient</h4>\n",
    "\n",
    "* New weights = Prev weights + Previous update - LearningRate*(derivative of \"new weights if you stick to previous update\" w.r.t  old weights)\n",
    "\n",
    "$$x_k = x_k-1 + V_k$$ \n",
    "where $$v_k = v_k-1 - \\epsilon\\frac{\\delta}{\\delta x}f(x_{k-1} + v_{k-1}*dampening factor)$$\n",
    "\n",
    "* So you are in effect moving the previous update in the optimal direction\n",
    "* Nestorov also added a factor to slow down the momentum as the solution approached the minimum so that it would converge. The final equation for v is:\n",
    "where $$v_{k-1} = \\mu v_{k-1} - \\epsilon\\frac{\\delta}{\\delta x}f(x_{k-1} + \\mu_{k-1}v_{k-1}*dampening factor)$$\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='LargeScale'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">5. Large Scale Machine Learning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Sparsity'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Dealing with Sparsity</h4>\n",
    "\n",
    "If d = density (1-d = sparsity), D = dimensions, and n= data points then:\n",
    "\n",
    "<b>Gradient Descent</b>\n",
    "* If each x is itself sparse, with density factor 0 ≤ d ≤ 1, computing the gradient takes O(dDN) time and order O(N + D) storage.\n",
    "\n",
    "<b>Newtons Method</b> \n",
    "* No efficiency gain from Sparsity as inverse multiplication requires the entire matrix. So still computationally inefficient.\n",
    "\n",
    "\n",
    "<b>Conjugate Gradients</b>\n",
    "* has a Sparse complexity of O(dD $\\sqrt N$)\n",
    "* (based on pg 44 of http://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf)\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='SGD'></a>\n",
    "<h4 style=\"background-color:#616161;color:white\">Stochastic Gradient Descent</h4>\n",
    "\n",
    "* In normal ('Batch') gradient descent you analyze all the data before making first W update\n",
    "\n",
    "* In SGD you update W after each single row of data\n",
    "\n",
    "* This means that while you are performing more updates, and may not reach the true optimal, you converge approximately to the optimal faster precisely because you are doing more updates so each new one update gains from the fact lots of other ones have happened before it\"\n",
    "<br>\n",
    "* This is useful in situations where that dataset is too big to store it all in memory and/or it will take a long time to update\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Dimensionality Reduction'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">4. Dimensionality Reduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='PCA'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">PCA</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Good resource: https://www.coursera.org/learn/machine-learning/lecture/ZYIPa/principal-component-analysis-algorithm\n",
    "http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues\n",
    "\n",
    "\n",
    "<h4>Explain the PCA algorithm</h4>\n",
    "\n",
    "<b>Pre-processing:</b>\n",
    "1. If the mean of the data is not 0 to begin with center the data by substracting the mean of each dimension, D\n",
    "2. If the different features have vastly different scales then (e.g. size of house, number of rooms) then normalize, typically done by dividng by the std. deviation\n",
    "\n",
    "<b>Main PCA algorithm:</b>\n",
    "1. Formulate the co-variance matrix, S, as a DxD matrix: $S=\\frac{1}{N} XX^T$\n",
    "\n",
    "2. If using Eigen-decomposition approach (theoretical way):\n",
    "    * Calculate the Eigenvectors of S such that they are each orthogonal to the ones previously\n",
    "    * B = top M eigenvectors\n",
    "    * Complexity based on eigen-decomposition is O($D^3$)\n",
    "\n",
    "3. In practice, it can be impractical to first compute the covariance matrix and then the eigenvalues. Instead we can use the SVD approach which works here as S is a positive semi-definite matrix. This gives a more stable result:\n",
    "    * the SVD of S gives you $UDV^T$\n",
    "    * We only care about the first M columns of U, which form the basis matrix B.\n",
    "\n",
    "4. Reduced dimensional representations is then $Y = B^T \\tilde X$.\n",
    "5. The approximate higher dimensional reconstruction back again is given by $\\tilde X$ ≡ BY + M where M = is a vector of means that you are adding back on (see pre-processing). Also note it's B not $B^T$ here.\n",
    "6. The error is calculated as the sum of the squares difference between, $\\tilde x$, and x\n",
    "\n",
    "Notes:\n",
    "\n",
    "* B is a D x H dimensional matrix (for every dimension you have a reduced H mapping)\n",
    "* B consists of vectors that are orthogonal to the original data points. But it does not take into account the rotation - the data that is projected back out could fit the same variance as the original but rotated in the dimension space.\n",
    "\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Principal Component Analysis (PCA) is a method to form a lower-dimensional representation of data. For datapoints $x^n,n=1,...N$, define the matrix\n",
    "\n",
    "$$X=[x^1,x2...x^N]$$\n",
    "\n",
    "That is, for datapoints x with dimension D, then X is DxN dimensional. The data is such that the mean is zero.\n",
    "\n",
    "The covariance matrix of the data S, has elements \n",
    "\n",
    "$$S_ij=\\frac{1}{N}\\sum^N_nx^n_ix^n_j$$\n",
    "\n",
    "1. Explain how to write S in terms of matrix multiplication X</h4>\n",
    "<br>\n",
    "S is a co-variance matrix therefore DxD so: $$S=\\frac{1}{N} XX^T$$\n",
    "\n",
    "<hr />\n",
    "\n",
    "<h4>2. PCA is based on the linear model of the data\n",
    "\n",
    "$$x^n\\approx My^n$$\n",
    "\n",
    "where M is a DxH dimensional matrix, and each $y^n$ is a H dimensional vector, with $H<D$. \n",
    "<br><br>\n",
    "With reference to an orthognal matrix\n",
    "<br>\n",
    "$$R^TR=I$$\n",
    "<br>\n",
    "explain why there is no unique setting in general for M and $y^n$. Use also a diagram to explain the geometric meaning of this result\n",
    "</h4>\n",
    "\n",
    "* The log-liklihood is the same even with an orthogonal rotation of B --> RB where $R^TR$ = I. \n",
    "* draw a line on a diagonal line on a grid with dots around it, rotate the line and show how the variance captured by the line can stay the same even though it has rotated\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Datapoints $x^n,n=1,...N$, define the matrix\n",
    "$$X=[x^1,x^2,...x^N]$$\n",
    "\n",
    "That is, for data points x with dimension D, then X is D $\\times$ N dimensional. The data is such that the mean is 0, that is:\n",
    "\n",
    "$$\\sum_{n=1}^{N}x^n=0$$\n",
    "\n",
    "K-dimensional PCA aims to find a representation:\n",
    "\n",
    "$$x^n\\equiv \\sum_{k=1}^{K}y^n_kb^k$$\n",
    "\n",
    "where $b^1,...b^K$ are 'basis' vectors and $y^n_k$ are coeffcients\n",
    "<br>\n",
    "<br>\n",
    "Explain how to efficiently compute the basis vectors and coefficients in order to minimize the squared loss between the approximation and each $x^n$, namely:\n",
    "\n",
    "$$\\sum_{n=1}{N}\\left(x^n-\\sum_{k=1}^{K}y^n_kb^k\\right)^2$$</h4>\n",
    "\n",
    "Ans:\n",
    "* Basis vectors can be calculated through finding Eigenvectors of the co-variance matrix or by performing Singular Value Decomposition of the co-variance matrix\n",
    "* In either case we pick the top M vectors to form the matrix B\n",
    "* The co-efficients are the lower dimensional representation of the data and can be found by:\n",
    "$Y = B^T X$.\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain why PCA is often used as a pre-processing step in machine learning and explain what the geometric meaning of PCA is</h4>\n",
    "\n",
    "http://visionandbeyond.blogspot.co.uk/2014/08/how-to-apply-pca.html\n",
    "\n",
    "* PCA is used as it reduces the data dimensions to something more manageable, and in particular by making the matrix more dense, so the algorithm is more efficient\n",
    "* The geometric meaning of is that PCA1 capture the greatest distance in the dimension space, so if the data as shaped like an oval in a 2d space, it would capture the diameter from one end to the other. PCA2 captures the the distance that is perpendicular to this (so the second greatest distance) and the process continues until principal components count = desired num of dimensions and <=D\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain how to write the co-variance matrix S, in terms of the matrix multiplication of X</h4>\n",
    "* As we have assumed the mean is zero we can write: \n",
    "$$S = \\frac{1}{N-1}XX^T$$\n",
    "\n",
    "where N = num of observations\n",
    "<br>\n",
    "(Dummys note: so we are matrix-multiplying X with itself to find the strength of the correlation, and taking the average)\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Consider the situation in which the datapoints x n are very sparse - that is, only a few elements of each vector x n are non-zero, resulting also in a sparse matrix S. Describe a computationally efficient procedure to estimate the principal direction (the largest eigenvector of S) and explain why this is efficient.</h4>\n",
    "\n",
    "* One way of finding the principal eigenvector (the one with the larges value, PCA1) is to take any non-zero vector, and repeatedly multiply it with the covariance matrix\n",
    "* This process will converge to the principal eigenvector (eigenvector with the largest eigenvalue). \n",
    "* This is particularly efficient for the case that S is sparse since each matrix-vector product will be fast\n",
    "\n",
    "See: https://www.youtube.com/watch?v=fKivxsVlycs\n",
    "\n",
    "-----------------\n",
    "\n",
    "<h4> Continuing with the sparse dataset scenario, what would be a technique to perform full PCA (not just the principal eigenvector) efficiently?</h4>\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sparse_PCA\n",
    "\n",
    "*  Using the method described above one could find the princial eigenvector then deflate \n",
    "\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> How do you break rotational invariance in PCA</h4>\n",
    "\n",
    "* You set you principal eigenvector to be the one that maximizes the variance (corresponds to the largest eigenvalue of S)\n",
    "* All subsequent vectors will have to be orthogonal to preceding ones which together means your solution will not be rotationally invariant\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <h4> Explain why the SVD method is related to the eigen decomposition of S and explain the computational complexity of this approach to performing PCA compared to directly computing the eigen-dcomposition of S</h4>\n",
    "* The SVD approach is equivalent to finding an eigen-decomposition of the sample covariance matrix and then taking the leading M eigenvectors and their correspoding eigenvalues $\\lambda_i$\n",
    "* $\\lambda_i = D^2_ii$ of S V D\n",
    "\n",
    "* Using the SVD to perform PCA makes much better sense numerically than forming the covariance matrix to begin with, since the formation of $XX^T$ can cause loss of precision\n",
    "\n",
    "* PCA requires calculating the eigenvalues and eigenvectors of the covariance matrix, which is the product $XX^⊤$, where X is the data matrix and when the mean is 0.\n",
    "\n",
    "* Since the covariance matrix is symmetric, the matrix is diagonalizable, and the eigenvectors can be normalized such that they are orthonormal\n",
    "\n",
    "* PCA corresponds to setting B = $U_M$ and the eigenvalues are the diagonal elements of $D_M$ squared.\n",
    "\n",
    "\n",
    "\n",
    " -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is the orthonormality constraint in PCA?</h4>\n",
    "* $B^TB$ must $= I$, so that the basis vectors are mutually orthogonal and of unit length.\n",
    "* Done using Larange multipliers so that the objective is to minimize:\n",
    "$$-trace(SBB^T)+trace (L(B^TB-I))$$\n",
    "\n",
    "-----------------_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain PCA with missing data</h4>\n",
    "\n",
    "* The idea that if you have a fixed b, then you can optimize on Y instead (still doing using x to measure the loss)\n",
    "* This results in finding a Y that results in filling in the missing data\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain Canonical Variates</h4>\n",
    "\n",
    "A form of dimensionality reduction in supervised learning that seeks to encode <class distinction in the basis vectors so that the the classifications aren't lost when doing PCA\n",
    "\n",
    "1. Compute the between and within class scatter matrices A, and B.\n",
    "2. Compute the Cholesky factor $\\tilde B$ of B.\n",
    "3. Compute the L principal eigenvectors [$e_1 , . . . , e_L$ ] of $\\tilde B^{-T} A \\tilde B^{−1}$.\n",
    "4. Return W = [$e_1 , . . . , e_L$] as the projection matrix.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='NNMF'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Non Negative Maxtrix Factorization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>PCA can be considered a form of matrix factorisation. An alternative matrix factorisation method is probabilistic latent semantic analysis (PLSA) (also called non\n",
    "negative matrix factorisation). This takes a positive matrix X whose entries all sum to 1:\n",
    "    \n",
    "$$\\sum_{ij}X_{ij}=1, \\quad 0\\leq X_{ij} \\leq 1$$\n",
    "\n",
    "and forms an approximation based on\n",
    "\n",
    "$$X_ij \\approx  \\sum^H_{k=1}U_{ik}V_{kj}$$\n",
    "\n",
    "for matrices U and V non-negative entries and $\\sum_iU_{ik} = 1 \\quad and \\quad \\sum_kV_{kj}=1$\n",
    "<br><br>\n",
    "1. Explain what are the typical characteristics of the 'eigenfaces'in PCA compared with the 'plsa' faces in Matrix Factorization.\n",
    "<br><br>\n",
    "2. Derive an algorithm to find U and V based on an interpretation of X, U and V in terms of probability distributions.\n",
    "\n",
    "</h4>\n",
    "\n",
    "1. The PSLA faces are more localised and one of them, for example, might be clearly\n",
    "emphasising aspects of the chin. The eigenfaces are more general and emphasise broader\n",
    "aspects of the image. (Note though that overall, PLSA must have a higher reconstruction\n",
    "error since it has more constraints (positive bases).)\n",
    "\n",
    "2.\n",
    "** I am only 20% sure this answer is anywhere close to being correct **\n",
    "* We can transform X,U and V into probability distributions using $p = \\frac {CountOfElement }{SumOfElement Count}$\n",
    "* Let p = p(X,Y): This is the true probability\n",
    "* Let $\\tilde p$ = p(X,UV) \n",
    "* Let z = p(U) and y = p(V)\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml001.png\" height=\"100\" width=\"300\">\n",
    "\n",
    "Notes:\n",
    "* Line 3 - is keeping track of the p(z|x,y) in the last iteration\n",
    "* Line 4 - is updating p(x|z) using chain rule to match p(x, y) * previous weightings\n",
    "* Line 5 - is doing the same but in the output end, p(y|z)\n",
    "* Loops until the difference between old & new p(z | x,y) is minimal\n",
    "\n",
    "* Now derive z from the conditional probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Convexity'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Convexity</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Show that $-log \\sigma(x)$  is convex where $\\sigma$ represents the sigmoid function</h4>\n",
    "\n",
    "$$\\frac{df}{dx} = \\frac{1}{\\sigma(x)}\\sigma(1-\\sigma) = \\sigma(x) -1$$\n",
    "<br><br>\n",
    "$$\\frac{dfdx}{dx} = \\sigma(x) (1- \\sigma(x)$$\n",
    "\n",
    "Because sigma lies between 0-1 we, this function will also always lie between 0 and 1, threfore > 0 and hence convex\n",
    "\n",
    "Notes:\n",
    "* derivative of a log(x) is the $\\frac{1}{log(x)}$\n",
    "* derivative of a sigmoid is sigmoid(x)*(1-sigmoid(x))\n",
    "* in an exam the x they give you might be more complicated. Don't fall for it - just say z= .... and repeat steps above\n",
    "\n",
    "------------------------\n",
    "\n",
    "<h4> Show that this is convex</h4>\n",
    "$$E(W) =\\frac^N_{n=1}(y^n-w^Tx^n)^2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain the concept of line search optimization and show that for a line going through the point $w_k$ and direction $p_k$,\n",
    "\n",
    "$w=w_k + \\lambda p_k$\n",
    "<br>\n",
    "the optimal point on the line to minimize the squared error E(w) is given when:\n",
    "<br><br>\n",
    "$$\\lambda = \\frac{(b-Ap_k)^Tp_k}{p^T_kAp_k}$$</h4>\n",
    "\n",
    "** No idea where I got this question from **\n",
    "\n",
    "* Line search optimization is when you choose to only change one dimension within the weight vector and optimize along that direction before repeating for other dimensions until convergence is found\n",
    "\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain convergence rate for convex funtions</h4>\n",
    "\n",
    "* Assuming a convex function with $x_1$ to $x_T$ steps the gradience descent algorithm will take\n",
    "* and there is an optimal finite x^*\n",
    "* Then the gradient has a constant, L, that means the Hessian maximum Eigenvalue is less than or equal to L\n",
    "$$H(x) \\succeq LI$$ ($\\succeq$ means that $H(x_i) \\leq LI $ for every index i)\n",
    "\n",
    "* In this case we can say that the convergence rate is of order O(1/T) where T is the number of iterations\n",
    "* $$f(x_T) - f(x^*) \\leq \\frac{1}{2 \\epsilon T}(x_1-x^*)^2$$\n",
    "\n",
    "(the amount you are above the optimal by will be <=  ...)\n",
    "\n",
    "* In practice the results may be better than this\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml007.png\" height=\"100\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain the meaning of the 'conjugate direction' and why this means that the optimum of E(w) can be found by optimizing along each conjugate direction independently</h4>\n",
    "\n",
    "Ans\n",
    "* This is the idea of moving along one dimension to the find the optimal,then moving along another dimension that is conjugate to the first one. This way the change in the new dimension will not impact the change from the first dimension.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> For input-output training points $(xn,yn), n = 1; ... ,N$, where each input $x^n$ is a vector\n",
    "and each output yn is a scalar, the squared loss of a linear regression model is\n",
    "\n",
    "$$E(w) = \\frac{1}{N} \\sum^N_{n=1}(y^n-w^Tx^n)^2$$\n",
    "<br><br>\n",
    "1. Compute the gradient and Hessian of this objective function and show that E (w) is convex.</h4>\n",
    "<br><br>\n",
    "\n",
    "$\\frac{\\delta E}{\\delta w_i} = 2\\sum_n(y^n-w^Tx^n)x^n_i $\n",
    "\n",
    "$\\frac{\\delta E}{\\delta w_ij} = 2\\sum_n(x^n)x^n_i = 2 \\sum x^n_jx^n_i   $\n",
    "\n",
    "Or in matrix form $= 2X^TX$\n",
    "<br><br>\n",
    "This will always be > 0 and is therefore convex\n",
    "\n",
    "-----------------------\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml009.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "-----------------\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml008.png\" height=\"100\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='AutoDiff'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Auto Differentiation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Essential: https://www.youtube.com/watch?v=mYOkLkS5yqc\n",
    "\n",
    "Recommended: https://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/\n",
    "\n",
    "<h4>Describe Forward Automatic Differentiation (AutoDiff) and give two procedures\n",
    "(one exact and the other an approximation) that compute the gradient of a subroutine\n",
    "f(x) with respect to its arguments x, giving time complexities of the approaches.</h4>\n",
    "\n",
    "Ans:\n",
    "* AutoDiff takes a function f(x) and calculates the gradient\n",
    "* Crucially it does this without having to calculate the gradient for each element of x indivually, so it scales more efficiently\n",
    "* AutoDiff exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically and accurately to working precision\n",
    "* Forward autodiff, takes the bottoms up approach by calculating the inner differentials first (the ones with respect to independent variables) before moving up the chain.\n",
    "* It does by incrementing each input x by a small delta, calculating the impact it has along the function to work out the overall partial derivative, then repeating for the next x. Hence it isn't very efficient.\n",
    "* The complexity of forward autodiff is equivalent to the original function for which it is calculating the gradient\n",
    "\n",
    "There are two approaches to Forward-Auto Diff\n",
    "* Complex Arithmetic - gives an approximate answer only\n",
    "* Dual Arithmetic - gives an exact answer but it not efficient \n",
    "\n",
    "Both these approaches introduce an imaginary number $\\epsilon$\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain reverse mode Auto-Diff:</h4>\n",
    "\n",
    "* You can break up a complex function into series of partial deritives components using the chain rule\n",
    "* Read the following - it's really good\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml020.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml021.png\" height=\"100\" width=\"500\">\n",
    "\n",
    "\n",
    "* Reverse autodiff then takes the top down (or outside in) approach, calculating the outer derivatives first and working inwards. \n",
    "* It is efficient as unlike Forward AD it remembers calculations so that it doesn't need to calculate the same part twice (e.g. when two child functions roll up into one parent)\n",
    "\n",
    "* In cases where you have multiple input variables, dy/dx is efficient because it remembers the partial derivatives of such that parts of the derivative chain that are shared by multiple variables, are calculated only once.\n",
    "\n",
    "\n",
    "* This requires storing all the intermediate calculations in memory as you go along, which may cause problems, unless checkpointing is used in which certain portions would have to reevaluated at the end\n",
    "* One can show that, if done efficiently, one can always calculate the gradient in less than 5 times the time it takes to compute f (x).\n",
    "* Forward-mode is efficient for functions taking one input and producing many outputs. Reverse-mode is efficient for functions taking many inputs and producing a single output. (That output would be a “loss function” in machine learning)\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is the Reverse Mode Differentiation algorithm </h4>\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml005.png\" width=\"500\">\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain how we can calculate the quantity Hessian-vector product $Hv$ using the autodiff framework:</h4>\n",
    "\n",
    "----------------\n",
    "\n",
    "We use the fact that $D_v(\\frac{\\partial E}{\\partial \\theta_i}) = [Hv]_i$ and then use the usual rule of reverse differentiation from autodiff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Consider a time series prediction problem in which, given a sequence of inputs\n",
    "Xl,X2\", \"Xt, we make a prediction)it for the output at time t. To do this we define:\n",
    "    \n",
    "$$h_1=x_1$$\n",
    "$$h_t=f(x_t, h{_t-1}, A)  \\quad t>1$$\n",
    "$$\\tilde y_t = g(h_t,B)$$\n",
    "\n",
    "where A and B are parameters and f and g are some (unspecified) functions. The\n",
    "objective is to find parameters A and B that minimise the loss\n",
    "\n",
    "$$\\sum^T_{t=1}(y_t-\\tilde Y_t)^2$$\n",
    "\n",
    "Explain how to use Reverse AutoDiff to efficiently calculate the gradient of this loss\n",
    "function with respect to A and B.\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='NN'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">6. Neural Networks</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='AutoEncoders'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Auto Encoders</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>\n",
    "Explain how auto-encoders can be used to find low dimensional representations of data and explain how PCA relates to an Autoencoder.</h4>\n",
    "\n",
    "\n",
    "Ans:\n",
    "\n",
    "* Auto-encoders use neural nets to learn to represent data using. Data is fed into a neural net with one or more hidden layers. The hidden layer with the smallest number of weights effective becomes the lower-level representation of the data. The outputs are then scaled back up to map the output back in the form of the original data. \n",
    "\n",
    "* The loss function then checks the difference between what was generated and the original input.\n",
    "\n",
    "* PCA is equivalent to an Autoencoder with a single hidden layer with a linear trasfer function. In this case PCA is a more efficient way of calculating the optimal.\n",
    "-----------------------\n",
    "\n",
    "We can break an autoencoder into two parts -- an encoder from the input to the bottleneck layer and a decoder from the bottleneck to the reconstruction. Both encoder and decoder can contain multiple layers. Let's write h=f(x) for the encoder part and x'=g(h) for the decoder.   If the decoder is a linear function, then the autoencoder cannot beat PCA. Otherwise it can.  Essentially this is what we showed in the lectures.\n",
    "\n",
    "Remember that f and g can themselves represent multiple layers. Consider an autoencoder x->h1->h2->h3->h4->h5->x' in which h3 is the bottleneck. Then even if (for example) h5->x' is linear, then the overall decoder h3->h4->h5->x' can still be a non-linear function of h3, provided either h3->h4 or h4->h5 is non-linear. Hence this autoencoder could beat PCA even with a linear output layer.\n",
    "\n",
    "\n",
    "<h4>\n",
    "Consider and Auto-encoder with structure x$\\rightarrow$ h $\\rightarrow \\tilde x$, trained to minimize the squared loss:\n",
    "\n",
    "$$\\sum_{n=1}{N}\\left(\\tilde x - x^n \\right)^2$$ \n",
    "with $h^n=f(Ax^n)$ and $\\tilde x^n = Bh^n$ for matrices A,B and a non linear function f.\n",
    "\n",
    "For k-dimensional h, is this non-linear procedure in principle more powerful than K-dimensional PCA, in the sense that it has lower squared loss? Explain fully your answer.\n",
    "</h4>\n",
    "\n",
    "Ans:\n",
    "\n",
    "------------------_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain what is meant by an auto-encoder neural network</h4>\n",
    "\n",
    "* An auto-encoder NN tried to find a lower dimensional representation of data by setting the output to to match the input dimensions, with reduction of dimension in 1 or more hidden layers in between\n",
    "\n",
    "* The hidden layer with the smaller dimensions (bottleneck layer) is the lower dimensional representation of the input data\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='RNNS'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">RNNs</h3>\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml004.png\" height=\"100\" width=\"200\">\n",
    "\n",
    "* Each h in this digram represents 1 or more hidden layers of that same time step\n",
    "* RNNs are used in timeseries applications\n",
    "* The basic idea is that the hidden units at time $h_t$ (and possibly output $y_t$ ) depend on the previous state of the network $h_t−1 , x_t−1 , y_t−1$ for inputs $x_t$ and outputs $y_t$ .\n",
    "* The above network is ‘unrolled the net through time’ to give a standard NN diagram.\n",
    "* Potential links from $x _t−1$ , $y_t−1$ to $h_t$  have been omitted\n",
    "\n",
    "There are two ways to train an RNN:\n",
    "* RTRL (which is a single forward pass in time but has high storage cost) \n",
    "* BPTT (which is a forward and backward pass with more modest storage cost). RTRL is straightforward, but BPTT requires an understanding of parameter tying (or more generally AutoDiff).\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is Parameter tying?</h4>\n",
    "\n",
    "* Parameter tying addresses the issue of how to differentiate netsted functions in which there is a common paramter $\\theta$ (not to be confused with input x)\n",
    "* One way would have been to do the chain rule\n",
    "* But another way is to treat the two as two separate functions and differentiate them individually\n",
    "* Then join the two unconstrained derivatives together (sum) and apply a constraint that $\\theta_1 = \\theta_2$\n",
    "\n",
    "1. Treat all parameters as independent and calculate the gradient with respect to\n",
    "each independent parameter.\n",
    "2. Sum all the resulting independent gradients together.\n",
    "3. Evaluate the expression by setting all the independent parameters to the same\n",
    "value.\n",
    "Note that this is a general result and can be used to deal with parameter tying\n",
    "in any objective, not just Deep Learning and Neural Nets.\n",
    "(Of course, this is again just a special case of AutoDiff)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='LSTM'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">LSTM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### An input-output time-series ($X_t,Y_t$), t = 1...T can be modelled by a recurrent LSTM (Long ShortTerm Memory) network. Explain the essential components of an LSTM network and what difficulties it tries to overcome (compared to standard recurrent networks).\n",
    "\n",
    "Ans:\n",
    "\n",
    "* AN LSTM tried to overcome the limitations of an RNN when it comes to storing long-term dependencies in memory. With a standard RNN this becomes computationally inefficient.\n",
    "* It does this by introducing the concept of a memory gates that can affect the memory state running through the function\n",
    "* The forget gate takes in the current input ($C_t$) and the previous output and  and uses them to decide whic parts of the current state should be reduced (forgotten)\n",
    "* The input gate also takes in the current input ($C_t$) and the previous output and decides whether anything should be added to the memory. This then gets added to the result of the forget step\n",
    "* The output gate then decides whether to activate an output based on the results at this timestep. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Initialization'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Initialization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://cs231n.github.io/neural-networks-2/#datapre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Visualization'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">7. Visualization\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='TSNE'></a>\n",
    "<h4> Explain SNE and T-SNE</h4>\n",
    "\n",
    "<b>SNE</b>\n",
    "\n",
    "* Stochastic Neighbourhood Embedding was invented by Hinton and Rowels\n",
    "* It represents any high dimensional object, i, as the probability of it being close to every other neighbour,j\n",
    "$$p_{ij} = \\frac{exp(-d^2_ij)}{\\sum_{k \\neq i } exp(-d^2_{ik})}$$\n",
    "* The distance measure can be anything but Hinton proposes Eucliden distance $-(x_i - x_j)^2/(2\\sigma^2_i) $\n",
    "* This should give each point its own Gaussian distribution. Remeber that i and k here represent the dimension and could be large\n",
    "* The next step is to define a probability distribution that is a similar shape but it based on a lower level of dimensions\n",
    "$$q{j|i} = \\frac{exp(-(y_i-y_j)^2)}{\\sum_{j \\neq i} exp(-y_i-y_j)^2)}$$\n",
    "* When determining whether the two probabilities are similar SNE uses KL divergance\n",
    "* However this isn't symmetric - it maintains local structure but is in accurate on global structure\n",
    "* The Gaussian distribution also means that points far away have almost no impact in determining q\n",
    "\n",
    "<b>T-SNE</b>\n",
    "* Uses symmetric loss function when optimizing q\n",
    "* Uses a Students-T distribution for q\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml002.png\" height=\"100\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Practice Questions'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">Practice Questions\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<q4> Explain how to use Reverse AutoDiff to efficiently calculate the gradient with respect to $\\theta_1 and \\theta_2$ of $$\\sum^N_{n=1}(y^n-sin(\\theta_1 + \\theta_2 x^n))^2$$\n",
    "Your computation graph should have nodes representing elementary functions. Annotate your graph\n",
    "suitably and define the forward and backward passes explicitly.\n",
    "\n",
    "Ans:\n",
    "* To solve this put the wrt at the top of the chart (in this case two nodes of $\\theta_1$ and $\\theta_2$\n",
    "* then draw arrows down to show the tranistions, labelling the next node $f_1, f_2$ and so on\n",
    "* on the RHS explain what each f represents\n",
    "\n",
    "Now put the following explanation below\n",
    "* Reverse Mode Auto-Diff first does a forward pass to build up the above graph\n",
    "* Then go through the nodes in reverse order and calculate the derivative of each one, recursiely traversing through the child nodes in order to do so and remembering the child derivatives on the way back up\n",
    "* This is more efficient as you calculate common components just once\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Calculate the Gradient of $E(0) = [y - f(\\theta g(x\\theta))]^2$</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Write out the reverse mode differentiation for this:\n",
    "<img src=\"../_img/aml_2.jpg\" height=\"100\" width=\"300\"></h4>\n",
    "\n",
    "\n",
    "1. $\\frac{df}{dx} = (2x + gh) + (g^2xg) + (2x2gxxg) + (2xxh)$\n",
    "2. Substitute f and g to get to $2x + 8x^7$\n",
    "\n",
    "Note: If you are asked to create a graph for a function, then first differentiate that function then create the graph, building up each step of the calculation as an $f_1$ , $f_2$ etc as you go\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
