{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center>Applied Machine Learning Revision Q&A</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3>Topics covered in class</h3>\n",
    "\n",
    "<br>[<b>1. Linear Regression</b>](#Linear Regression)\n",
    "<br>[Least Squares Loss](#Loss)\n",
    "<br>[Auto Regressive Models](#Loss)\n",
    "<br>[Radial Basis Functions](#Radial)\n",
    "\n",
    "<br>[<b>2. Clustering and Classification</b>](#Clustering)\n",
    "<br>[K-NN](#KNN)\n",
    "<br>[Maximum Liklihood](#MaxLiklihood)\n",
    "<br>[Naieve Bayes](#NaieveBayes)\n",
    "<br>[SVMs](#SVM)\n",
    "<br>[Decision Trees](#DecisionTrees)\n",
    "<br>[Mixture Models](#MixtureModels)\n",
    "\n",
    "<br>[<b>3. Dimensionality Reduction</b>](#Dimensionality Reduction)\n",
    "<br>[PCA](#PCA)\n",
    "<br>[Non-Negative Matrix Factorization](#MF)\n",
    "<br>[ICA](#ICA)\n",
    "<br>[Fishers Linear Discrimnate & Canonical Variables](#Fishers)\n",
    "\n",
    "<br>[<b>4. Optimization</b>](#Optimization)\n",
    "<br>[Gradient Descent](#Gradient Descent)\n",
    "<br>[Line search & conjugate gradients](#ConjugateGradients)\n",
    "<br>[Higher order methods](#HigherOrder)\n",
    "\n",
    "<br>[<b>5. Large Scale Machine Learning</b>](#LargeScale)\n",
    "<br>[Stochastic Gradient Descent](#SGD)\n",
    "<br>[Sparsity](#SGD)\n",
    "<br>[Batch vs Online](#BatchOnline)\n",
    "\n",
    "<br>[<b>6. Neural Networks</b>](#NN)\n",
    "<br>[Auto Encoders](#AutoEncoders)\n",
    "<br>[CNNs](#CNNs)\n",
    "<br>[NLP](#NLP)\n",
    "<br>[RNNs](#RNNs)\n",
    "<br>[Gradient Decay/Explosion](#DecayExplosion)\n",
    "<br>[LSTM](#LSTM)\n",
    "<br>[SeqToSeq and Bidirectional](#Seq)\n",
    "<br>[Parameter Tying](#ParamTying)\n",
    "<br>[BackProp Through Time](#BPTime)\n",
    "<br>[Auto Differentiation](#AutoDiff)\n",
    "<br>[Initialization](#Initializtion)\n",
    "\n",
    "<br>[<b>7. Visualization</b>](#Visualization)\n",
    "<br>[T-SNE](#TSNE)\n",
    "\n",
    "<br>[<b>8. Fastest Nearest Neighbours</b>](#FastestNN)\n",
    "<br>[Orchard](#Orchard)\n",
    "<br>[AESA](#AESA)\n",
    "<br>[KD Trees](#KD Trees)\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Useful Latex Math symbols</h4>\n",
    "\n",
    "http://web.ift.uib.no/Teori/KURS/WRK/TeX/symALL.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Linear Regression'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">1. Linear Regression</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Explain the issues of overfitting and describe what we add to the loss function to prevent it</h4>\n",
    "\n",
    "* Overfitting is when a statistical model describes random error or noise rather than the underlying relationship\n",
    "* Adding a regularization term to penalise rapid channges in the output helps reduce this\n",
    "* For example adding an L2 regularization (aka Ridge Regression) to the previous solution would make the w:\n",
    "$$w=\\left(\\sum_{n=1}{N}x^n(x^n)^T+\\lambda w^Tw\\right)^{-1}\\left(\\sum_{n=1}^{N}y^nx^n\\right)$$\n",
    "\n",
    "\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>For a dataset of inputs x and scalar outputs y, ${(x^n,y^n),n=1, ...,N}$, linear regression is the model\n",
    "\n",
    "$$y=w^Tx$$\n",
    "<br>\n",
    "i. The least squares criterion with regularizer term, sets w based on minimizing\n",
    "\n",
    "$$E(w) =\\sum^{N}_{n=1}(y^n-w^Tx^n)^2+\\lambda w^Tw$$\n",
    "\n",
    "Show that the optimal solution is given by\n",
    "\n",
    "$$w= \\left(\\sum_{n=1}^{N}x^n(x^n)^T + \\lambda I \\right)^{-1}\\left(\\sum_{n=1}^{N}y^nx^n\\right)$$</h4>\n",
    "\n",
    "Ans:\n",
    "\n",
    "Useful: http://www.statpower.net/Content/310/Summation%20Algebra.pdf\n",
    "<br><br>\n",
    "Starting with\n",
    "\n",
    "$$E(w) =\\sum^{N}_{n=1}(y^n-w^Tx^n)^2+\\lambda w^Tw$$\n",
    "\n",
    "1. Differentiate: \n",
    "$$\\frac{dE}{dw}=2\\sum^N_{n=1} (y^n-w^Tx^n)x^n + \\lambda w= 0$$\n",
    "\n",
    "\n",
    "2. Divide both sides by -2 then multiply out with $x^n$:\n",
    "$$\\sum^N_{n=1} (y^n)x^n - \\sum^N_{n=1}(w^Tx^n)x^n + \\lambda w = 0$$\n",
    "\n",
    "3. Using summation rule 2 to move the w out\n",
    "$$\\sum^N_{n=1} (y^nx^n) - w^T\\sum^N_{n=1}x^n(x^n)^T + \\lambda w = 0$$\n",
    "\n",
    "4. Reverse of multipying out with the w in the regularizing term (I gets introduced to keep $\\lambda$ in vector form once w disappears)\n",
    "$$ \\sum^N_{n=1} (y^nx^n) w \\left( \\sum^N_{n=1} ( x^n(x^n)^T + \\lambda I \\right)  = 0$$\n",
    "\n",
    "5. Move yx to the right hand side\n",
    "$$ \\left(w^T\\sum^N_{n=1}x^n(x^n)^T \\right) + w \\lambda = \\sum^N_{n=1} (y^nx^n)$$\n",
    "\n",
    "6. Use inversion to divide\n",
    "\n",
    "$$w= \\left(\\sum_{n=1}^{N}y^nx^n\\right) \\left(\\sum_{n=1}^{N}x^n(x^n)^T + \\lambda I \\right)^{-1}$$</h4>\n",
    "\n",
    "<br>\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "<h4>Give also an expression for the computational complexity required to find $w_{opt}$ using this expression and explain why in practice it is not recommended to find w by using matrix inversion as above, explain an alternative procedure</h4>\n",
    "\n",
    "* You don't find the matrix inversion because it's an O($n^3$) calculation and you also have to store the hessian at every iteration which is also very expensive\n",
    "* So you just do gradient calculations as you don't need a $x^Tx$ calculation\n",
    "\n",
    "\n",
    "* Gaussian elimination is faster and numerically more stable\n",
    "\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain Canonical Variates</h4>\n",
    "\n",
    "* A form of dimensionality reduction in supervised learning that seeks to encode class distinction in the basis vectors\n",
    "\n",
    "1. Compute the between and within class scatter matrices A, and B.\n",
    "2. Compute the Cholesky factor $\\tilde B$ of B.\n",
    "3. Compute the L principal eigenvectors [$e_1 , . . . , e_L$ ] of $\\tilde B^{-T} A \\tilde B^{−1}$.\n",
    "4. Return W = [$e_1 , . . . , e_L$] as the projection matrix.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain the concept of line search optimization and show that for a line going through the point $w_k$ and direction $p_k$,\n",
    "\n",
    "$w=w_k + \\lambda p_k$\n",
    "<br>\n",
    "the optimal point on the line to minimize the squared error E(w) is given when:\n",
    "<br><br>\n",
    "$$\\lambda = \\frac{(b-Ap_k)^Tp_k}{p^T_kAp_k}$$</h4>\n",
    "\n",
    "* Line search optimization is when you choose to only change one dimension within the weight vector and optimize along that direction before repeating for other dimensions until convergence is found\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain the meaning of the 'conjugate direction' and why this means that the optimum of E(w) can be found by optimizing along each conjugate direction independently</h4>\n",
    "\n",
    "Ans\n",
    "* This is the idea of moving along one dimension to the find the optimal,then moving along another dimension that is conjugate to the first one. This way the change in the new dimension will not impact the change from the first dimension.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is the difference between L1 and L2 regularization?</h4>\n",
    "\n",
    "L1\n",
    "* Term is: sum of abs values of w\n",
    "* Heavy and small $w_i$ is penalized by the a constant proportional amount\n",
    "* Peanlty can't be differentiated so requires special otpmization routines\n",
    "* But will mean that only significant weights remain\n",
    "* In practice (e.g. deep learning) people don't worry about it being non-differentiable and just proceed with gradient based training as normal\n",
    "\n",
    "L2\n",
    "* Term is: $ w^T w$ or $\\sum_i{w^2_i}$\n",
    "* Penalizes large W more than small ones\n",
    "* Penalty is differentiable\n",
    "* Small weights will still persists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Clustering'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">2. Clustering & Classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain what is meant by nearest neighbour classification for a dataset of N examples with D-dimensional inputs x and discrete class labels c. Explain how to classify a new input x.</h4>\n",
    "\n",
    "* New item x is classified based on the class of it's nearest neighbour in the dataset $x_1 ... x_n$\n",
    "* Distance can be measured using Euclidean squared distance\n",
    "$$d(x,x') = \\sqrt{\\sum_{i=1}^{D}(x_i - x'_i)^2}$$\n",
    "* PCA can be used in cases of a high number of dimensions to improve calculation speed and improve results\n",
    "* It is not clear how to deal with missing data however or incorporate prior beliefs and domain knowledge\n",
    "\n",
    "<h4> What is Mahalanobis distance?</h4>\n",
    "\n",
    "* Where you multiply the distance by the covariance matrix of the input (from all classes) which rescales the input vector and thus large values dominate less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is KNN?</h4>\n",
    "\n",
    "* Extension of NN where you use the class of the K nearest neighbours not just the 1st nearest\n",
    "* We first work out the liklihood model for each class:\n",
    "$$ p(x|c=0) = \\frac{1}{N_{class0}} \\sum_n \\mathcal{N}(x|x^n, \\sigma^2I)$$\n",
    "$$ p(x|c=1) = \\frac{1}{N_{class1}} \\sum_n \\mathcal{N}(x|x^n, \\sigma^2I)$$\n",
    "\n",
    "\n",
    "* What this means is we take the point estimate and put it into the Gaussian formula to come up with a circle around that point\n",
    "* To deal with outliers we create aritifical points where the mean of the class is, and give it a very large variance. That way the outlier's class is not infuenced by whatever is closes and effectively reverts back to the prior\n",
    "\n",
    "To then classify a new data point we use Bayes rule:\n",
    "\n",
    "$$ p(c=0|x^{*}) = \\frac{p(x^* | c = 0)p(c=0)}{p(x^{*}|c=0)p(c=0)+p(x^{*}|c=1)p(c=1)}$$\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> What is Naieve Bayes</h4>\n",
    "\n",
    "<H2>Naieve Bayes</H2>\n",
    "<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Introduction\"><b>From Wikipedia</b></a><br>\n",
    "Naive Bayes is a simple technique for classifying things. It is not a single algorithm but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class that the data belongs to.<br> \n",
    "For example, a fruit may be considered to be an apple if it is 'red', 'round', and about '10 cm' in diameter. A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple, regardless of any possible correlations between the color, roundness, and diameter features. An advantage of naive Bayes is that it only requires a small number of training data to estimate the parameters necessary for classification <br>\n",
    "<br>\n",
    "<br>\n",
    "<h4>The algorithm</h4>\n",
    "The maths behond it is explained very well in the <a href=\"http://scikit-learn.org/stable/modules/naive_bayes.html\">Skikit-learn pages</a>\n",
    "\n",
    "In a nutshell your start with Bayes Theorem:\n",
    "$${\\displaystyle p(Y_{k}\\vert \\mathbf {x} )={\\frac {p(Y_{k})\\ p(\\mathbf {x} \\vert Y_{k})}{p(\\mathbf {x} )}}\\,}$$\n",
    "\n",
    "and reason that:\n",
    "* p(x) can consist of mutiple things .. i.e.  inputs $x_1$,$x_2$,$x_3$\n",
    "* if the inputs $x_1$,$x_2$,$x_3$ are \"naievely\" assumed to be independent of each other (more on this later), so they don't impact each others probability of y, then we can use the multiplicative rule or probability and simplify the top to: \n",
    "$$p(Y)\\prod_{{i=1}}^{n} p(x_{i}\\vert Y_{k})$$\n",
    "* As for the denominator, we can say that's fixed from having analyzed a corpus of data and determined the p of each x. For purposes of classification we can therefore ignore it.\n",
    "\n",
    "* All this results in the simplified classificiation formula:\n",
    "\n",
    "\n",
    "$${\\begin{aligned}p(Y_{k}\\vert x_{1},\\dots ,x_{n})&\\varpropto p(Y_{k})\\prod _{{i=1}}^{n}p(x_{i}\\vert Y_{k})\\,.\\end{aligned}}$$\n",
    "<i>$\\varpropto$ means in proportion to</i>\n",
    "\n",
    "Notes:\n",
    "<br>\n",
    "* The ability to assume independence under a given class is a crucial part of applied Bayes. So the words 'great' and tremendous' are postively correlated in a movie review, but if you took it for granted that the movie review was positive, then the probability of 'great' is unlikely to correlate as strongly with 'tremendous' - the two may be equally likely for instance.\n",
    "\n",
    "* Naieve Bayes is very fast to train, deals with more than two classes, and can deal with missing data\n",
    "* In the case of low counts the method can be overconfident although the use of pseudocounts can help (see literature)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Dimensionality Reduction'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">3. Dimensionality Reduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='PCA'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">PCA</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Good resource: https://www.coursera.org/learn/machine-learning/lecture/ZYIPa/principal-component-analysis-algorithm\n",
    "http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues\n",
    "\n",
    "\n",
    "<h4>Explain the PCA algorithm</h4>\n",
    "\n",
    "<b>Pre-processing:</b>\n",
    "1. If the mean of the data is not 0 to begin with center the data by substracting the mean of each dimension, D\n",
    "2. If the different features have vastly different scales then (e.g. size of house, number of rooms) then normalize, typically done by dividng by the std. deviation\n",
    "\n",
    "<b>Main PCA algorithm:</b>\n",
    "1. Formulate the co-variance matrix, S, as a DxD matrix\n",
    "\n",
    "2. If using Eigen-decomposition approach (theoretical way):\n",
    "    * Calculate the Eigenvectors of S\n",
    "    * B = top M eigenvectors\n",
    "    * Complexity based on eigen-decomposition is O($D^3$)\n",
    "\n",
    "3. If using SVD approach (this works here as S is a positive semi-definite matrix and gives a more stable result):\n",
    "    * the SVD of S gives you $UDV^T$\n",
    "    * We only care about the first M columns of U, which form the basis matrix B.\n",
    "\n",
    "4. Reduced dimensional representations is then $Y = B^T \\hat X$.\n",
    "5. And the approximate reconstructions back again is given by $\\hat X$ ≡ BY + M where M = is the vector of means that you are adding back on. Note it's B not $B^T$ here.\n",
    "6. The error is calculated as the sum of the squares difference between, $\\tilde x$, and x\n",
    "\n",
    "Notes:\n",
    "\n",
    "* B is a D x H dimensional matrix (for every dimension you have a reduced H mapping)\n",
    "* B consists of vectors that are orthogonal to the original data points. But it does not take into account the rotation - the data that is projected back out could fit the same variance as the original but rotated in the dimension space.\n",
    "\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Principal Component Analysis (PCA) is a method to form a lower-dimensional representation of data. For datapoints $x^n,n=1,...N$, define the matrix\n",
    "\n",
    "$$X=[x^1,x2...x^N]$$\n",
    "\n",
    "That is, for datapoints x with dimension D, then X is DxN dimensional. The data is such that the mean is zero.\n",
    "\n",
    "The covariance matrix of the data S, has elements \n",
    "\n",
    "$$S_ij=\\frac{1}{N}\\sum^N_nx^n_ix^n_j$$\n",
    "\n",
    "1. Explain how to write S in terms of matrix multiplication X</h4>\n",
    "<br>\n",
    "S is a co-variance matrix therefore DxD so: $$S=\\frac{1}{N} XX^T$$\n",
    "\n",
    "<hr />\n",
    "\n",
    "<h4>2. PCA is based on the linear model of the data\n",
    "\n",
    "$$x^n\\approx My^n$$\n",
    "\n",
    "where M is a DxH dimensional matrix, and each $y^n$ is a H dimensional vector, with $H<D$. With reference to an orthognal matrix\n",
    "<br>\n",
    "$$R^TR=I$$\n",
    "\n",
    "<br>\n",
    "explain why there is no unique setting in general for M and $y^n$. Use also a diagram to explain the geometric meaning of this result\n",
    "</h4>\n",
    "\n",
    "* PCA uses \n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Datapoints $x^n,n=1,...N$, define the matrix\n",
    "$$X=[x^1,x^2,...x^N]$$\n",
    "\n",
    "That is, for data points x with dimension D, then X is D $\\times$ N dimensional. The data is such that the mean is 0, that is:\n",
    "\n",
    "$$\\sum_{n=1}^{N}x^n=0$$\n",
    "\n",
    "K-dimensional PCA aims to find a representation:\n",
    "\n",
    "$$x^n\\equiv \\sum_{k=1}^{K}y^n_kb^k$$\n",
    "\n",
    "where $b^1,...b^K$ are 'basis' vectors and $y^n_k$ are coeffcients\n",
    "<br>\n",
    "<br>\n",
    "Explain how to efficiently compute the basis vectors and coefficients in order to minimize the squared loss between the approximation and each $x^n$, namely:\n",
    "\n",
    "$$\\sum_{n=1}{N}\\left(x^n-\\sum_{k=1}^{K}y^n_kb^k\\right)^2$$</h4>\n",
    "\n",
    "Ans:\n",
    "* First find the point at which the error function is minimal by differentiating the loss function\n",
    "* This gives $$y^n=\\sum b^nx^n$$\n",
    "\n",
    "<span style=\"color:red\">*** DISCUSS ON FRIDAY ***</span>\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain why PCA is often used as a pre-processing step in machine learning and explain what the geometric meaning of PCA is</h4>\n",
    "\n",
    "http://visionandbeyond.blogspot.co.uk/2014/08/how-to-apply-pca.html\n",
    "\n",
    "* PCA is used as it reduces the data dimensions to something more manageable, and in particular by making the matrix more dense, so the algorithm is more efficient\n",
    "* The geometric meaning of is that PCA1 capture the greatest distance in the dimension space, so if the data as shaped like an oval in a 2d space, it would capture the diameter from one end to the other. PCA2 captures the the distance that is perpendicular to this (so the second greatest distance) and the process continues until principal components count = desired num of dimensions and <=D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain how to write the co-variance matrix S, in terms of the matrix multiplication of X</h4>\n",
    "* As we have assumed the mean is zero we can write: \n",
    "$$S = \\frac{1}{N-1}XX^T$$\n",
    "\n",
    "where N = num of observations\n",
    "<br>\n",
    "(Dummys note: so we are matrix-multiplying X with itself to find the strength of the correlation, and taking the average)\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Question D</h4>\n",
    "\n",
    "* One way of finding the principal eigenvector (the one with the larges value, PCA1) is to take any non-zero vector in the plane, and repeatedly multiply it with the covariance matrix\n",
    "* This process will converge to the principal eigenvector (eigenvector with the largest eigen-\n",
    "value). \n",
    "* This is particularly efficient for the case that S is sparse since each matrix-vector product will be fast\n",
    "\n",
    "See: https://www.youtube.com/watch?v=fKivxsVlycs\n",
    "\n",
    "-----------------\n",
    "\n",
    "<h4> Continuing with the sparse dataset scenario, what would be a technique to perform full PCA (not just the principal eigenvector) efficiently?</h4>\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sparse_PCA\n",
    "\n",
    "*  Using the method described above one could find the princial eigenvector then deflate \n",
    "\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <h4> Explain why the SVD method is related to the eigen decomposition of S and explain the computational complexity of this approach to performing PCA compared to directly computing the eigen-dcomposition of S</h4>\n",
    "* Using the SVD to perform PCA makes much better sense numerically than forming the covariance matrix to begin with, since the formation of $XX^T$ can cause loss of precision\n",
    "\n",
    "* PCA requires calculating the eigenvalues and eigenvectors of the covariance matrix, which is the product $XX^⊤$, where X is the data matrix and when the mean is 0.\n",
    "\n",
    "* Since the covariance matrix is symmetric, the matrix is diagonalizable, and the eigenvectors can be normalized such that they are orthonormal\n",
    "\n",
    "* The SVD formula \n",
    "\n",
    " -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> How do you enforce orthonormality in PCA </h4>\n",
    "\n",
    "* We use Larange multipliers so that the objective is to minimize:\n",
    "$$-trace(SBB^T)+trace (L(B^TB-I))$$\n",
    "* Since the constraint is symmetric, we can assume that L is also symmetric.\n",
    "* Differentiating with respect to B and equating to zero we obtain that at the optimum SB = BL\n",
    "* We need to find matrices B and L that satisfy this equation. One solution is given when L is diagonal in which case this is a form of eigen-equation and the columns of B are the corresponding eigenvectors of S\n",
    "* One solutioon is $(SBB^T) = travel (L)$ where L is a diagonal, and B are the eigenvetors of S\n",
    "-----------------_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Matrix Factorization'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Maxtrix Factorization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>PCA can be considered a form of matrix factorisation. An alternative matrix factorisation method is probabilistic latent semantic analysis (PLSA) (also called non\n",
    "negative matrix factorisation). This takes a positive matrix X whose entries all sum to 1:\n",
    "    \n",
    "$$\\sum_{ij}X_{ij}=1, \\quad 0\\leq X_{ij} \\leq 1$$\n",
    "\n",
    "and forms an approximation based on\n",
    "\n",
    "$$X_ij \\approx  \\sum^H_{k=1}U_{ik}V_{kj}$$\n",
    "\n",
    "for matrices U and V non-negative entries and $\\sum_iU_{ik} = 1 \\quad and \\quad \\sum_kV_{kj}=1$\n",
    "<br><br>\n",
    "1. Explain what are the typical characteristics of the 'eigenfaces'in PCA compared with the 'plsa' faces in Matrix Factorization.\n",
    "<br><br>\n",
    "2. Derive an algorithm to find U and V based on an interpretation of X, U and V in terms of probability distributions.\n",
    "\n",
    "</h4>\n",
    "\n",
    "1. The PSLA faces are more localised and one of them, for example, might be clearly\n",
    "emphasising aspects of the chin. The eigenfaces are more general and emphasise broader\n",
    "aspects of the image. (Note though that overall, PLSA must have a higher reconstruction\n",
    "error since it has more constraints (positive bases).)\n",
    "\n",
    "2.\n",
    "** I am only 20% sure this answer is aanywehre close to being correct **\n",
    "* We can transform X,U and V into probability distributions using $p = \\frac {CountOfElement }{SumOfElement Count}$\n",
    "* Let p = p(X,Y): This is the true probability\n",
    "* Let $\\tilde p$ = p(X,UV) \n",
    "* Let z = p(U) and y = p(V)\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml001.png\" height=\"100\" width=\"300\">\n",
    "\n",
    "Notes:\n",
    "* Line 3 - is keeping track of the p(z|x,y) in the last iteration\n",
    "* Line 4 - is updating p(x|z) using chain rule to match p(x, y) * previous weightings\n",
    "* Line 5 - is doing the same but in the output end, p(y|z)\n",
    "* Loops until the difference between old & new p(z | x,y) is minimal\n",
    "\n",
    "* Now derive z from the conditional probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='AutoEncoders'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Auto Encoders</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>\n",
    "Explain how auto-encoders can be used to find low dimensional representations of data and explain how PCA relates to an Autoencoder.</h4>\n",
    "\n",
    "\n",
    "Ans:\n",
    "\n",
    "* Auto-encoders use neural nets to learn to represent data using. Data is fed into a neural net with one or more hidden layers. The hidden layer with the smallest number of weights effective becomes the lower-level representation of the data. The outputs are then scaled back up to map the output back in the form of the original data. \n",
    "\n",
    "* The loss function then checks the difference between what was generated and the original input.\n",
    "\n",
    "* PCA is equivalent to an Autoencoder with a single hidden layer with a linear trasfer function. In this case PCA is a more efficient way of calculating the optimal.\n",
    "-----------------------\n",
    "\n",
    "We can break an autoencoder into two parts -- an encoder from the input to the bottleneck layer and a decoder from the bottleneck to the reconstruction. Both encoder and decoder can contain multiple layers. Let's write h=f(x) for the encoder part and x'=g(h) for the decoder.   If the decoder is a linear function, then the autoencoder cannot beat PCA. Otherwise it can.  Essentially this is what we showed in the lectures.\n",
    "\n",
    "Remember that f and g can themselves represent multiple layers. Consider an autoencoder x->h1->h2->h3->h4->h5->x' in which h3 is the bottleneck. Then even if (for example) h5->x' is linear, then the overall decoder h3->h4->h5->x' can still be a non-linear function of h3, provided either h3->h4 or h4->h5 is non-linear. Hence this autoencoder could beat PCA even with a linear output layer.\n",
    "\n",
    "\n",
    "<h4>\n",
    "Consider and Auto-encoder with structure x$\\rightarrow$ h $\\rightarrow \\tilde x$, trained to minimize the squared loss:\n",
    "\n",
    "$$\\sum_{n=1}{N}\\left(\\tilde x - x^n \\right)^2$$ \n",
    "with $h^n=f(Ax^n)$ and $\\tilde x^n = Bh^n$ for matrices A,B and a non linear function f.\n",
    "\n",
    "For k-dimensional h, is this non-linear procedure in principle more powerful than K-dimensional PCA, in the sense that it has lower squared loss? Explain fully your answer.\n",
    "</h4>\n",
    "\n",
    "Ans:\n",
    "\n",
    "------------------_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain what is meant by an auto-encoder neural network</h4>\n",
    "\n",
    "* An auto-encoder NN tried to find a lower dimensional representation of data by setting the output to to match the input dimensions, with reduction of dimension in 1 or more hidden layers in between\n",
    "\n",
    "* The hidden layer with the smaller dimensions (bottleneck layer) is the lower dimensional representation of the input data\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Optimization'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">4. Optimization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain the concept of gradient descent optimization for minimizing the least-squared loss E(w) and explain why this is, in general, an inefficient procedure for the problem.</h4>\n",
    "\n",
    "Ans:\n",
    "\n",
    "* Gradient descent is an iterative method that continues until f(x) is 0 or very close to 0\n",
    "* It works by determining the new value of x as: $f(x_k+1)\\approx f(x_k)+(x_{k+1}-x_k)^T \\triangledown f(x_k)$ or new weight = old weigtht + chage in weight * change in f(x)\n",
    "* Simply following the curve, one small step change at a time may take a long time to converge. If the step-change is too great it may overshoot the optimal, of it's too small it will take a long time to converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain gradient descent</h4>\n",
    "\n",
    "* We wish to find an x that minimies f(x), and thre is no closed-form solution to this problen that applies in all cases, hence we need to use an iterative method\n",
    "* We can say that at the minimum, $f(x_k)$ and $f(x_{k+1})$ would give approximately the same result for some small change to x which we call $\\epsilon$  (aka learning rate)\n",
    "\n",
    "* The general formula is $x_{k+1} = x_k - \\epsilon \\triangledown f(x_k)$\n",
    "* Except we write it in the more correct matrix notation:\n",
    "$x_{k+1} = x_k - \\epsilon C^{-1}g$\n",
    "<br><br>\n",
    "\n",
    "* Note 1: The gradient part of this formula tells us how much each change to $\\epsilon$ will increase f(x) by, hence by negating this we go in the opposite direction, until $f(x_{k+1}) \\approx f(x_k)$\n",
    "\n",
    "* Note 2: The C in the matrix notation is a positive definite matrix and means the $\\epsilon$ gets converted into a vector\n",
    "\n",
    "* Note 3: If the learning rate is too small, you may reach the start of the minimum and end up stopping there as it would approximate to 0. So you may need to test out different learning rates at the end once you get to the minimum.\n",
    "\n",
    "* Note 4: If the learning rate is too large it will not converge on the minimum - in fact you could start going uphill due to the fact k was on one side of the gradient and k+1 is on the other\n",
    "\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain convergence rate for convex funtions</h4>\n",
    "\n",
    "* Assuming a convex function with $x_1$ to $x_T$ steps the gradience descent algorithm will take\n",
    "* and there is an optimal finite x^*\n",
    "* Then the gradient has a constant, L, that means the Hessian maximum Eigenvalue is less than or equal to L\n",
    "$$H(x) \\succeq LI$$ ($\\succeq$ means that $H(x_i) \\leq LI $ for every index i)\n",
    "\n",
    "* In this case we can say that the convergence rate is of order O(1/T) where T is the number of iterations\n",
    "* $$f(x_T) - f(x^*) \\leq \\frac{1}{2 \\epsilon T}(x_1-x^*)^2$$\n",
    "\n",
    "(the amount you are above the optimal by will be <=  ...)\n",
    "\n",
    "* In practice the results may be better than this\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Explain Momentum</h4>\n",
    "\n",
    "* Taking a moving average of the update \n",
    "* Reduces zig-zagging behaviour and help push past saddle points (local minima followe by a local maxima)\n",
    "* It is one way of updating the moving average without re-computing everything\n",
    "* $$x_k + \\tilde g_{k+1}$$ \n",
    "\n",
    "* Momentum can increase the speed of convergence since, for smooth objectives, as we get close to the minimum the gradient decreases and standard gradient descent would start to slow down\n",
    "* If the learning rate is too large, standard gradient descent may oscillate, but momentum may reduce oscillations by going in the average direction.\n",
    "* However, the momentum parameter $\\mu$ may need to be reduced with the iteration count to ensure convergence.\n",
    "* Particularly useful when the gradient is noisy. By averaging over previous gradients, the noise ‘averages’ out and the moving average direction can be much less noisy.\n",
    "* Momentum is also useful to avoid saddles (a point where the gradient is zero, but the objective function is not a minimum, such as the function x 3 at the origin) since typically the momentum will carry you over the saddle.\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain Nestorov's accelerated gradient'</h4>\n",
    "\n",
    "* New weights = Prev weights + Previous update - LearningRate*(derivative of \"new weights if you stick to previous update\" w.r.t  old weights)\n",
    "\n",
    "$$x_k = x_k-1 + V_k$$ \n",
    "where $$v_k = v_k-1 - \\epsilon\\frac{\\delta}{\\delta x}f(x_{k-1} + v_{k-1}*dampening factor)$$\n",
    "\n",
    "* So you are in effect moving the previous update in the optimal direction\n",
    "* Nestorov also added a factor to slow down the momentum as the solution approached the minimum so that it would converge. The final equation for v is:\n",
    "where $$v_{k-1} = \\mu v_{k-1} - \\epsilon\\frac{\\delta}{\\delta x}f(x_{k-1} + \\mu_{k-1}v_{k-1}*dampening factor)$$\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='CJ'></a>\n",
    "<h4> Explain Conjugate Gradient Descent</h4>\n",
    "https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf\n",
    "\n",
    "* Conjugate gradient descent is a way of doing gradient descent by optimizing along one dimension at a time\n",
    "* We have a set of weights, x that we wish to update with each iteration until it reaches the optimal\n",
    "$$x_k+1 = x_k + \\alpha_kp_k$$\n",
    "\n",
    "* Imagine an n dimensional problem that is convex such as this quadratic: \n",
    "$$f(x) = \\frac{1}{2}x^T Ax - b^Tx $$\n",
    "\n",
    "\n",
    "Example:\n",
    "<img src=\"../_img/aml_3.jpg\" height=\"100\" width=\"400\">\n",
    "\n",
    "* Note 1: We wish to find the optimal weights such that it minimizes the error, so x represents our NN weights here\n",
    "* Note 2: Within NN optimization, A represents the thing you are multiplying your weights with (either input data or output from the prevous layer)\n",
    "\n",
    "\n",
    "\n",
    "* Conjugate gradient descent says that if you wish to optimize one x dimension at a time, you need to replace x with $P$, such that $P^TAP$  is a diagonal matrix.\n",
    "* If x has 10 dimensions then we would do 10 iterations, and each time a new p vector would be added into P. Each p vector would be orthogonal to all previous p vectors so that it is not impacting previous dimensions\n",
    "* You can imagine this in the bowl as a two vetors that are orthogonal (right-angled) from each other - that way  you can optimize one without worrying about the effect it will have on the other\n",
    "* In a quadratic problem this means that this:\n",
    "$$f(x)=\\frac{1}{2}x^TAx-b^Tx $$\n",
    "becomes this:\n",
    "$$f(x)=\\sum_{i=1}^{n} \\left(\\frac{1}{2} \\alpha_i^2p_i^TAp_i-\\alpha_ib^Tp_i \\right ) $$\n",
    "\n",
    "\n",
    "* We can find each new p using the Polak-Ribière formula: which uses the gradients to find the next conjugate vector, which then allow us to make the update within each iteration:\n",
    "$$x_k+1 = x_k + \\alpha_kp_k$$\n",
    "\n",
    "where each p is a diagonal only for k (so when you move to the next direction it becomes 0's)\n",
    "\n",
    "* Note: In a non quadratic problem no such method exists\n",
    "\n",
    "Finally we get to the following algorithm:\n",
    "\n",
    "1. k = 1\n",
    "2. Choose $x_1$\n",
    "3. $p_1$ = $−g_1$  # pick any gradient\n",
    "4. while $g_k \\neq 0$ do\n",
    "    \n",
    "    * $\\alpha_k$ = argmin $f(x_k + \\alpha_k p_k) $  &nbsp;&nbsp;&nbsp;&nbsp; # Do a line search\n",
    "    * $x{_k+1} := x_k + \\alpha_k p_k$    &nbsp;&nbsp;&nbsp;&nbsp; # Update x based on p\n",
    "    * $\\beta_k := g_{k+1}^Tg_{k+1}/(g^T_kg_k)$  &nbsp;&nbsp;&nbsp;&nbsp; # Find new conjugate direction\n",
    "    * $p{_k+1} =  -g{_k+1} + \\beta_kp_k$     &nbsp;&nbsp;&nbsp;&nbsp; # Update next p\n",
    "    * k = k +1\n",
    "10. end while\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>What is the Taylor series and why is it important?</h4>\n",
    "\n",
    "http://www.mathsisfun.com/algebra/taylor-series.html\n",
    "\n",
    "Ans:\n",
    "\n",
    "1) The Taylor series is the idea that you can rewrite any smooth function (one who's shape can be described by a single formula) into a series of simpler \"generaized\" polynomials . Since (almost) all functions you encounter have a Taylor series, all functions can be thought of as \"generalized\" polynomials!\n",
    "\n",
    "\n",
    "<img src=\"../_img/aml_4.jpg\" height=\"100\" width=\"500\">\n",
    "\n",
    "2) For example we can write a function as a power series with center $x_0$ \n",
    "\n",
    "3) Power series are easy to differentiate and integrate. No more techniques of integration, if one is satisfied with writing an integral as a power series!\n",
    "\n",
    "4) In finding integrals and solving differential equations, one often faces the problem that the solutions can't be \"found\", just because they do not have a name, i.e., they cannot be written down by combining the familiar function names and the familiar mathematical notation. The functions describing the motion of a \"simple\" pendulum are important examples. Power series open the door to explore even functions like these! \n",
    "\n",
    "---------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain Newtons Method</h4>\n",
    "\n",
    "* At a high level Newton's method finds the minimum of a function by drawling a line at the gradient of any point, and moving to the point where this intersects the with the x-axis. At this point it then sets $x_k+1$ to this value and repeats. The result is that f(x) converges on the minimum\n",
    "\n",
    "* f(x+ change) = previous f(x) + (change $*$ gradient) + (half $*$ change$^2 *$ Hessian)\n",
    "\n",
    "-------------_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> For input-output training points $(xn,yn), n = 1; ... ,N$, where each input $x^n$ is a vector\n",
    "and each output yn is a scalar, the squared loss of a linear regression model is\n",
    "\n",
    "$$E(w) = \\frac{1}{N} \\sum^N_{n=1}(y^n-w^Tx^n)^2$$\n",
    "<br><br>\n",
    "1. Compute the gradient and Hessian of this objective function and show that E (w) is convex.</h4>\n",
    "<br><br>\n",
    "\n",
    "$\\frac{\\delta E}{\\delta\\theta_i} = 2\\sum_n(y^n-\\theta^Tx^n)x^n_i $\n",
    "\n",
    "$\\frac{\\delta E}{\\delta\\theta_ij} = 2\\sum_n(x^n)x^n_i = 2 \\sum x^n_jx^n_i   $\n",
    "\n",
    "Or in matrix form $= 2X^TX$\n",
    "<br><br>\n",
    "This will always be > 0 and is therefore convex\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='LargeScale'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">5. Large Scale Machine Learning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> For input-output training points $(xn,yn), n = 1; ... ,N$, where each input $x^n$ is a vector\n",
    "and each output $y^n$ is a scalar, the squared loss of a linear regression model is </h4>\n",
    "\n",
    "$$E(w) = \\frac{1}{N} \\sum^N_{n=1}(y^n-w^Tx^n)^2$$\n",
    "\n",
    "<h4>Explain what Stochastic Gradient Descent is and how it could be used to find the w that minimises E(w)</h4>\n",
    "\n",
    "* In normal ('Batch') gradient descent you analyze all the data before making first W update\n",
    "\n",
    "* In SGD you update W after each single row of data\n",
    "\n",
    "* This means that while you are performing more updates, and may not reach the true optimal, you converge approximately to the optimal faster precisely because you are doing more updates so each new one update gains from the fact lots of other ones have happened before it\"\n",
    "<br>\n",
    "* This is useful in situations where that dataset is too big to store it all in memory and/or it will take a long time to update\n",
    "\n",
    "\n",
    "<h4>In the case that the input vectors are sparse (only a fraction f of the elements\n",
    "of each x n are non-zero), explain what computational savings this has when\n",
    "implementing gradient descent.</h4>\n",
    "\n",
    "<h4>Explain how Conjugate Gradients could be used to find the w that minimises\n",
    "E(w) and what computational savings can be made when the input vectors $x^n$ are sparse.\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='AutoDiff'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Auto Differentiation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Describe Forward Automatic Differentiation (AutoDiff) and give two procedures\n",
    "(one exact and the other an approximation) that compute the gradient of a subroutine\n",
    "f(x) with respect to its arguments x, giving time complexities of the approaches.</h4>\n",
    "\n",
    "https://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/\n",
    "\n",
    "Ans:\n",
    "* AutoDiff takes a function f(x) and calculates the gradient\n",
    "* AutoDiff exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically and accurately to working precision\n",
    "* Forward autodiff, takes the bottoms up approach by calculating the inner differentials first (the ones with respect to independent variables) before moving up the chain.\n",
    "* The complexity of forward autodiff is equiavalent to the original function for which it is calculating the gradient\n",
    "* Reverse autodiff takes the topd down approach, calculating the outer derivatives first and working inwards. \n",
    "* This requires storing all the intermediate calculations in memory as you go along, which may cause problems, unless checkpointing is used in which certain portions would have to reevaluated at the end\n",
    "* The complexity of reverse autodiff is ...?\n",
    "* Forward-mode is efficient for functions taking one input and producing many outputs. Reverse-mode is efficient for functions taking many inputs and producing a single output. (That output would be a “loss function” in machine learning)\n",
    "\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write out the reverse mode differentiation for this:\n",
    "<img src=\"../_img/aml_1.jpg\" height=\"100\" width=\"100\">\n",
    "\n",
    "$$\\frac{df}{dy}=\\frac{\\delta f}{\\delta x}+\\frac{\\delta f}{ \\delta g}\\frac{\\delta g}{\\delta x}$$\n",
    "\n",
    "Notes:\n",
    "1. d = total derivative, $\\delta$ = partial\n",
    "2. Because f is impacted by x in two different ways, the total derivative of f w.r.t x is given by summing boths paths (https://en.wikipedia.org/wiki/Sum_rule_in_differentiation)\n",
    "3. The second path is broken down by the chain rule (https://en.wikipedia.org/wiki/Chain_rule)\n",
    "\n",
    "-----------------\n",
    "\n",
    "<h4> Write out the reverse mode differentiation for this:\n",
    "<img src=\"../_img/aml_2.jpg\" height=\"100\" width=\"300\"></h4>\n",
    "\n",
    "\n",
    "1. $\\frac{df}{dx} = (2x + gh) + (g^2xg) + (2x2gxxg) + (2xxh)$\n",
    "2. Substitute f and g to get to $2x + 8x^7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='NN'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">6. Neural Networks</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### An input-output time-series ($X_t,Y_t$), t = 1...T can be modelled by a recurrent LSTM (Long ShortTerm Memory) network. Explain the essential components of an LSTM network and what difficulties it tries to overcome (compared to standard recurrent networks).\n",
    "\n",
    "Ans:\n",
    "\n",
    "* AN LSTM tried to overcome the limitations of an RNN when it comes to storing long-term dependencies in memory. With a standard RNN this becomes computationally inefficient.\n",
    "* It does this by introducing the concept of a memory gates that can affect the memory state running through the function\n",
    "* The forget gate takes in the current input ($C_t$) and the previous output and  and uses them to decide whic parts of the current state should be reduced (forgotten)\n",
    "* The input gate also takes in the current input ($C_t$) and the previous output and decides whether anything should be added to the memory. This then gets added to the result of the forget step\n",
    "* The output gate then decides whether to activate an output based on the results at this timestep. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Initialization'></a>\n",
    "<h3 style=\"background-color:#616161;color:white\">Initialization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://cs231n.github.io/neural-networks-2/#datapre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Visualization'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">7. Visualization\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Explain SNE and T-SNE</h4>\n",
    "\n",
    "<b>SNE</b>\n",
    "\n",
    "* Stochastic Neighbourhood Embedding was invented by Hinton and Rowels\n",
    "* It represents any high dimensional object, i, as the probability of it being close to every other neighbour,j\n",
    "$$p_{ij} = \\frac{exp(-d^2_ij)}{\\sum_{k \\neq i } exp(-d^2_{ik})}$$\n",
    "* The distance measure can be anything but Hinton proposes Eucliden distance $-(x_i - x_j)^2/(2\\sigma^2_i) $\n",
    "* This should give each point its own Gaussian distribution. Remeber that i and k here represent the dimension and could be large\n",
    "* The next step is to define a probability distribution that is a similar shape but it based on a lower level of dimensions\n",
    "$$q{j|i} = \\frac{exp(-(y_i-y_j)^2)}{\\sum_{j \\neq i} exp(-y_i-y_j)^2)}$$\n",
    "* When determining whether the two probabilities are similar SNE uses KL divergance\n",
    "* However this isn't symmetric - it maintains local structure but is in accurate on global structure\n",
    "* The Gaussian distribution also means that points far away have almost no impact in determining q\n",
    "\n",
    "<b>T-SNE</b>\n",
    "* Uses symmetric loss function when optimizing q\n",
    "* Uses a Students-T distribution for q\n",
    "\n",
    "<img src=\"https://github.com/BadrulAlom/Data-Science-Notes/raw/master/_img/aml/aml002.png\" height=\"100\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='FastestNN'></a>\n",
    "<h2 style=\"background-color:#616161;color:white\">8. Fastest Nearest Neighbours</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
